
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Nothing here\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dante-su.github.io/author/dante/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dante/","section":"authors","summary":"Nothing here","tags":null,"title":"Dante","type":"authors"},{"authors":null,"categories":null,"content":" Table of Contents Overview CCF recommended ranking TsingHua recommended ranking Lists of code category Overview Here I will record the papers I read and present them with a brief introduction and my notes.\nCCF recommended ranking CCF_2022\nTsingHua recommended ranking TH-CPL_2019\nLists of code category CVPR Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ICCV Proceedings of the IEEE/CVF International Conference on Computer Vision ECCV European Conference on Computer Vision SIGGRAPH Proceedings of ACM SIGGRAPH（Asia）/ ACM Transactions on Graphics NeurIPS The Annual Conference on Neural Information Processing System ArXiv ArXiv Others Other Conference/Journal ","date":1712534400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1712534400,"objectID":"94d6b94109d4c3e427433f2f18c4c446","permalink":"https://dante-su.github.io/notes/paper_reading/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/paper_reading/","section":"notes","summary":"Recordings of my paper reading","tags":["Papers"],"title":"📜 Paper reading","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Lists of code category Overview Just a library for some code instances I collect.\nLists of code category Python Python code instances ","date":1695859200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695859200,"objectID":"f5bfef0e33fe956f35000265aa8c89e9","permalink":"https://dante-su.github.io/notes/code_instance/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/notes/code_instance/","section":"notes","summary":"Some code instance to use and modify","tags":["Code"],"title":"🧑‍💻 Code Instance","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Chapters of notes Chapters of notes Math for Computer Graphics Greg Turk, August 2019 GAMES101 Notes for GAMES101 Related papers Related papers of Computer Graphics Useful links Useful links of Computer Graphics ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"9b137460ed9ef433b8d7825468ede77f","permalink":"https://dante-su.github.io/notes/computer_graphics/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/computer_graphics/","section":"notes","summary":"Notes for Computer Graphics","tags":["CG"],"title":"👾 Computer Graphics","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Classes of links Overview This part is used to store the useful links to me, including those for work, those for learning and of course those for entertainment.entertainment.\nClasses of links Learning Links for learning Collection My Collection Others Links for dealing with specific situation when debugging. ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"c10b0367f4a064527fe2402ef4c01dce","permalink":"https://dante-su.github.io/notes/links/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/links/","section":"notes","summary":"Some useful links","tags":["Links"],"title":"🔗 Links","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Lists of code category Overview Updating\nLists of code category Markdown Several markdown’s rule and quick command code Gitbook Gitbook’s installation and usage hugo Notes HTML Notes Messy Notes ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"e9b1243ace61ab43dbf401d3dccea7cf","permalink":"https://dante-su.github.io/notes/others/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/others/","section":"notes","summary":"Some messy notes","tags":["Code"],"title":"🗞️ Others","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Chapters here Overview Python is the the greatest program language in this world( I believe ). Infinite python packages make it be broader used than we could image. However, it also brings us a huge trouble that we could hardly be able to use all of them with only one brain’s memory space, include Mr. Guido van Rossum, who has the honor to be the inventor of Python. So here is the way to help us get a better use of those annoying package and messy command. Notes!\nChapters here Anaconda Some shell command when using Anaconda Pip Some pip commands. Pytorch Pytorch documents Jupyter Intro of Jupyter notebook Installation pip install jupyter notebook Way to use Jupyter notebook from remote server on local device On server conda activate your_env_name pip install jupyter notebook jupyter notebook --generate-config\nNumpy Numpy in Python Installation conda install numpy pip install numpy Usage np.array import numpy as np a = np.array([[1,2,3],[4,5,6]]) cumsum # Obtain the cumulative sum value of whole array print(a.cumsum()) # [ 1 3 6 10 15 21] # Obtain the cumulative sum value along given axis print(a.\nOS OS package in Python os.access() import os if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.F_OK): print \u0026#34;Given file path is exist.\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.R_OK): print \u0026#34;File is accessible to read\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.W_OK): print \u0026#34;File is accessible to write\u0026#34; if os.\nOthers Other useful package. ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"6b16c2b0c26f4860e0ec1639413f8300","permalink":"https://dante-su.github.io/notes/python/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/python/","section":"notes","summary":"Python lib","tags":["Python"],"title":"🐍 Python","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Notes in this part Overview This part is about the Shell command when using UNIX(Linux/MacOS) or Windows. And there are also some useful tools like Docker, WSL and so on.\nNotes in this part Linux Some shell command when using Anaconda Windows Powershell command in Windows Docker Some documents of docker WSL Installation method and usage of WSL on Windows Git Usage and debug experience of ‘Git’ ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"9666556bf87dc548f717fcbd9706f519","permalink":"https://dante-su.github.io/notes/shell/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/shell/","section":"notes","summary":"Shell command's usual usage(include Anaconda)","tags":["Shell"],"title":"🎹 Shell","type":"book"},{"authors":null,"categories":null,"content":"Links for learning\nDocs 计算机图形学与混合现实在线平台 https://games-cn.org/\nFoundational courses of Machine Learning @Google https://developers.google.com/machine-learning/foundational-courses\n深入浅出PyTorch https://datawhalechina.github.io/thorough-pytorch/index.html\nPandas Document https://www.pypandas.cn/docs/getting_started/\nBaidu AI Paddle https://aistudio.baidu.com/aistudio/index\n动手学深度学习 https://zh-v2.d2l.ai/index.html\n爱可可爱生活的知乎 https://www.zhihu.com/people/fly51fly\n台大李宏毅 https://speech.ee.ntu.edu.tw/~hylee/index.php\nhttps://www.youtube.com/watch?v=rTqmWlnwz_0\n苏剑林的博客 https://kexue.fm/\n豆约翰 https://www.jianshu.com/u/8b23f6864f5d\nDIY CPU https://gitee.com/totalcontrol/hustzc\nBULMA: A Modern CSS Framework https://bulma.io/\nthree.js https://threejs.org/\nFlask https://www.w3cschool.cn/flask/\nOpen3D https://www.open3d.org/docs/release/index.html\nProject Based Learning(C,Python,Java,OpenGL et al.) https://github.com/practical-tutorials/project-based-learning\nTools Research CCF deadline https://ccfddl.github.io/\npaperwithcode https://paperswithcode.com/\nconnected papers https://www.connectedpapers.com/\nCool Paper@Su Jianlin https://papers.cool/\npaperyy查重 https://www.paperyy.cn/\n超星大雅查重 http://user.dayainfo.com/show/login\nLLM ChatGPT@OpenAI https://chat.openai.com/\nPoe: a ChatGPT-powered assistant https://poe.com/\nPerplexity.ai https://www.perplexity.ai/\nKimi AI https://kimi.moonshot.cn/\nAI news https://www.unite.ai/\nOthers LaTeX公式编辑器 https://www.latexlive.com/ https://www.latex-tables.com/ https://latex.vimsky.com/\n远景论坛 https://bbs.pcbeta.com/\nv2ray https://github.com/freefq/tutorials\nhttps://github.com/wrfree/free\nJupyterLab，极其强大的下一代notebook！ https://zhuanlan.zhihu.com/p/87403131\nImage Extractor https://extract.pics/\nStable Diffusion web UI https://github.com/AUTOMATIC1111/stable-diffusion-webui\nIntel CPU Docs Search https://www.intel.com/content/www/us/en/search.html\nList of NVIDIA GPU Info https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units#Desktop_GPUs\nDisk Price(US) https://diskprices.com/\nNVIDIA Cuda Toolkit Download https://developer.nvidia.com/cuda-downloads?target_os=Linux\u0026amp;target_arch=x86_64\u0026amp;Distribution=WSL-Ubuntu\u0026amp;target_version=2.0\u0026amp;target_type=deb_local\nAutoDL: GPU Rent https://www.autodl.com/login?url=/home\nCS Authors https://www.csauthors.net/\nKMS 激活 Windows \u0026amp; Office https://blog.angustar.com/archives/activate-windows-and-office-by-kms.html\nMac软件下载 https://www.macvk.com/\nAnydesk for linux https://anydesk.com/en/downloads/linux\nMeshlab https://www.meshlab.net/\nCOLMAP https://colmap.github.io/\nImageMagick https://imagemagick.org/\nEnglish Duolinguo English Test https://englishtest.duolingo.cn/home\n登登多邻国 https://det.91ddedu.com/#/\nSpeak\u0026amp;Improve https://speakandimprove.com/\nWrite\u0026amp;Improve https://writeandimprove.com/\nHow To Pronounce https://www.howtopronounce.com/\nCambridge Dictionary https://dictionary.cambridge.org/dictionary/english-chinese-simplified/\nRsearchers CUHK Dr. Qi Dou https://www.cse.cuhk.edu.hk/~qdou/index.html\nProf. Tien-Tsin WONG https://ttwong12.github.io/myself.html\nHKBU Dr. Jie Chen https://jchenhkg.github.io/\nHuawei Dr. Jiemin Fang https://jaminfong.cn/\nHUST Prof. Xinggang Wang https://xwcv.github.io/\nMPI Dr. Michael J. Black https://ps.is.mpg.de/person/black\nNTU Dr. Ziwei Liu https://liuziwei7.github.io/\nTHU Prof. Yebin Liu https://liuyebin.com/\nUCSB Dr. Lingqi Yan https://sites.cs.ucsb.edu/~lingqi/\nUniversity of Tubingen Prof. Andreas Geiger https://www.cvlibs.net/index.php\n","date":1713398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713398400,"objectID":"05766939cf167c27192e862f7182aeef","permalink":"https://dante-su.github.io/notes/links/learning/","publishdate":"2024-04-18T00:00:00Z","relpermalink":"/notes/links/learning/","section":"notes","summary":"Links for learning\n","tags":["Links"],"title":"Learning","type":"book"},{"authors":null,"categories":null,"content":"Some shell command when using Anaconda\nTable of Contents Basic command Clear the screen Permissions Copy Move Pathway Folder Search file kill touch Apt Install new package Update dict Update installed package NVIDIA GPU CUDA version GPU status GPU driver System info CPU Memory Storage Network interface controller/card Kernel Ubuntu version Offline program screen tumx Downloads \u0026amp; Upload wget curl scp Compression zip Execution .bin cmake nano .sh Basic command Clear the screen clear\nproblem When terminals database is inaccessible happened.\nAdd xport TERMINFO=/usr/share/terminfo to .bashrc\nPermissions Give read, write, and execute permissions for everyone chmod -R 777 \u0026lt;dir\u0026gt;/\u0026lt;folder_name\u0026gt;\nCopy cp \u0026lt;dir\u0026gt;/file_name\u0026gt; \u0026lt;dir\u0026gt;/\u0026lt;new_name\u0026gt; cp -r \u0026lt;dir\u0026gt;/* \u0026lt;dir\u0026gt;\nMove mv \u0026lt;dir\u0026gt;/\u0026lt;file_name\u0026gt; \u0026lt;dir\u0026gt;/\u0026lt;new_name\u0026gt;\nIt also could be used to change the name of file when two \u0026lt;dir\u0026gt; are same.\nPathway pwd\nFolder Create folder mkdir \u0026lt;dir\u0026gt;/\u0026lt;name\u0026gt;\ne.g. mkdir /home/user/new_folder\nCheck content of folder ls ls \u0026lt;dir\u0026gt;\nFiles count ls -l | grep \u0026#34;^-\u0026#34; | wc -l (Count files number in this path, NOT containing subpath) ls -lR| grep \u0026#34;^-\u0026#34; | wc -l (Count files number in this path, containing subpath) ls -lR | grep \u0026#34;^d\u0026#34; | wc -l (Count folders number in this path, containing subpath)\nSearch file locate \u0026lt;name\u0026gt; find \u0026lt;name\u0026gt;\nkill kill \u0026lt;pid\u0026gt; kill -9 \u0026lt;pid\u0026gt; (-9 stands for mandatory) killall \u0026lt;program_name\u0026gt; pkill \u0026lt;program_name\u0026gt; xkill (Available on graphical interface)\ntouch touch \u0026lt;file_name\u0026gt;\nCreate a new file(Do nothing if the file already exists)\nApt Please be kindly notified that apt-get could be short to apt when using Install new package sudo apt-get install \u0026lt;package_name\u0026gt;\nUpdate dict sudo apt-get update\nUpdate installed package sudo apt-get upgrade sudo apt-get upgrade --only-upgrade \u0026lt;package_name\u0026gt;\nNVIDIA GPU CUDA version nvcc -V nvcc --version\nGPU status nvidia-smi watch -n 1 -d nvidia-smi gpustat (install it with conda/pip install gpustat) gpustat -i nvtop\nGPU driver ubuntu-drivers devices glxinfo | grep rendering sudo apt search nvidia-driver | grep nvidia-driver\nSystem info CPU Whole info cat /proc/cpuinfo\nCPU model cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c\nCore number cat /proc/cpuinfo | grep physical | uniq -c\nBit width (32/64) getconf LONG_BIT\nMemory Whole info cat /proc/meminfo\nShort info free -h\nDynamic info top or htop\nProcess status ps \u0026lt;option\u0026gt;\n\u0026lt;option\u0026gt; could be one of below:\n-A (List all process) -w (Wider list) -au (List with more details) -aux (List all processes of all users) -ef (List of all process with terminal type info) -u root (List the processes run by root) -ef | grep \u0026lt;key_word\u0026gt; (List of processes with given key word)\nStorage Whole info df -h\nInfo of current device df -h \u0026lt;dir\u0026gt;\ne.g. df -h ./\nAllocated space du -sh \u0026lt;dir\u0026gt;\nAll folder’s allocated space du -sh \u0026lt;dir\u0026gt;/*\nNetwork interface controller/card dmesg | grep -i eth\nKernel uname -a\nUbuntu version lsb_release -a\nOffline program screen Installation apt install screen\nCreate a new screen screen -S \u0026lt;name\u0026gt;\nCheck all screen screen -ls\nMake screen offline screen -d \u0026lt;name\u0026gt;\nRecover screen screen -r \u0026lt;name\u0026gt;\nBack to terminal ctrl+A+D\nDelete screen screen -X -S \u0026lt;name\u0026gt; quit screen kill \u0026lt;name\u0026gt; screen kill \u0026lt;id\u0026gt;\ntumx Zhihu Link\nDownloads \u0026amp; Upload wget wget [option] [url]\n[option] could be blanck\nChange file name wget -O \u0026lt;new_name\u0026gt; \u0026lt;url\u0026gt;\nChange file path wget -P \u0026lt;new_path\u0026gt; \u0026lt;url\u0026gt;\nContinute downloading after break wget -c \u0026lt;url\u0026gt;\nIncrease attempts wget -t \u0026lt;num\u0026gt; \u0026lt;url\u0026gt;\nThe default \u0026lt;num\u0026gt; is 40\nuse ftp wget --ftp-user=\u0026lt;username\u0026gt; --ftp-password=\u0026lt;password\u0026gt; \u0026lt;url\u0026gt;\nSimulate browser wget -U \u0026#39;\u0026lt;browser_name\u0026gt;\u0026#39; \u0026lt;url\u0026gt; \u0026lt;browser\u0026gt; could be one of {Mozilla/5.0 (Windows NT 10.0; Win64; x64), AppleWebKit/537.36 (KHTML, like Gecko), Chrome/81.0.4044.43, Safari/537.36}\nDownloads on background wget -b \u0026lt;url\u0026gt;\nCheck download log tail -f wget-log\nmulti-files download vim downloads.txt wget -i downloads.txt\ncurl This command could also be used on Windows/MacOS curl -o \u0026lt;name\u0026gt; \u0026lt;url\u0026gt;\nContinute downloading after break curl -C - -o \u0026lt;name\u0026gt; \u0026lt;url\u0026gt;\nIncrease attempts curl --retry 3 -o \u0026lt;name\u0026gt; \u0026lt;url\u0026gt;\nscp Download files from server to local scp username@servername:/remote_path/filename ~/local_destination\nUpload files from local to server scp ~/local_path/local_filename username@servername:/remote_path\nDownload whole directory from server to local scp -r username@servername:/remote_path/remote_dir/ ~/local_destination\nUpload whole directory from local to server scp -r ~/local_dir username@servername:/remote_path/remote_dir\nUse scp -P PortId ... instead if you need to specify a port to connect to the server Compression zip unzip [-cflptuvz][-agCjLMnoqsVX][-P \u0026lt;password\u0026gt;][.zip][file_name][-d \u0026lt;dir\u0026gt;][-x \u0026lt;file\u0026gt;]\nunzip [-Z]\nExample unzip test.zip unzip -n test.zip -d /tmp unzip -o test.zip -d tmp/\nDetailed info -c 将解压缩的结果显示到屏幕上，并对字符做适当的转换。\n-f 更新现有的文件。\n-l 显示压缩文件内所包含的文件。\n-p 与-c参数类似，会将解压缩的结果显示到屏幕上，但不会执行任何的转换。\n-t 检查压缩文件是否正确。\n-u 与-f参数类似，但是除了更新现有的文件外，也会将压缩文件中的其他文件解压缩到目录中。\n-v 执行时显示详细的信息。\n-z 仅显示压缩文件的备注文字。\n-a 对文本文件进行必要的字符转换。\n-b 不要对文本文件进行字符转换。\n-C 压缩文件中的文件名称区分 …","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"988519889a49102d182f970721583247","permalink":"https://dante-su.github.io/notes/shell/linux/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/shell/linux/","section":"notes","summary":"Some shell command when using Anaconda\n","tags":["Linux"],"title":"Linux","type":"book"},{"authors":null,"categories":null,"content":"Some shell command when using Anaconda\nTable of Contents Installation Usage Check installed package Check virtual environment Update conda Create env Remove env Activate/Deactivate env Install package Remove package Clone env Clean conda Remove package Usage of environment.yaml Usage of requirements.txt Debug examples NoWritableEnvsDirError Installation Please search it on official website Usage Check installed package conda list\nCheck virtual environment conda env list or conda info -e\nUpdate conda conda update conda\nCreate env conda create -n \u0026lt;env_name\u0026gt; python=3.x\nRemove env conda remove -n \u0026lt;env_name\u0026gt; --all\nActivate/Deactivate env For Linux/MacOS source activate \u0026lt;env_name\u0026gt;\nsource deactivate \u0026lt;env_name\u0026gt;\nFor Windows/Linux/MacOS conda activate \u0026lt;env_name\u0026gt;\nconda deactivate \u0026lt;env_name\u0026gt;\nInstall package conda install \u0026lt;package_name\u0026gt;=\u0026lt;version\u0026gt;\ne.g. conda install numpy=1.22.0\nRemove package conda uninstall \u0026lt;package_name\u0026gt;\nClone env conda create -n \u0026lt;new_env\u0026gt; --clone \u0026lt;old_env\u0026gt;\nClean conda conda clean --all\nRemove package conda remove -n \u0026lt;env_name\u0026gt; \u0026lt;package_name\u0026gt;\nUsage of environment.yaml Export env into yaml file conda env export \u0026gt; environment.yaml\nCreate new env from yaml file conda env create -f environment.yaml\nUsage of requirements.txt conda install --yes --file requirements.txt\nDebug examples NoWritableEnvsDirError NoWritableEnvsDirError: No writeable envs directories configured. - /home/\u0026lt;username\u0026gt;/.conda/envs - /home/\u0026lt;username\u0026gt;/anaconda3/envs Find the root path of ‘.conda’ file and use ‘cd’ enter that path and run the below commmand.\nsudo chmod a+w .conda\nor enter the path of ‘anaconda’ folder and run the below command.\nsudo chown -R \u0026lt;username\u0026gt; anaconda\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"bfdd1c625cacbc36fd7e239565762b51","permalink":"https://dante-su.github.io/notes/python/anaconda/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/python/anaconda/","section":"notes","summary":"Some shell command when using Anaconda\n","tags":["Anaconda"],"title":"Anaconda","type":"book"},{"authors":null,"categories":null,"content":"Several markdown’s rule and quick command code\nCode Highlight Use the below code in markdown to highlight the emphasizing code\n```shell code is set here ``` And for different kind of code languages, shell should be substituted by specific word listed below.\nKey of corresponding Code Language language key C c ActionScript actionscript Apache apache AppleScript applescript AsciiDoc asciidoc AspectJ asciidoc AutoHotkey autohotkey AVR Assembler avrasm Axapta axapta Bash bash BrainFuck brainfuck Cap’n Proto capnproto Clojure REPL clojure Clojure clojure CMake cmake CoffeeScript coffeescript C++ cpp C# cs CSS css D d Dart d Delphi delphi Diff diff Django django DOS.bat dos Dust dust Elixir elixir ERB(Embedded Ruby) erb Erlang REPL erlang-repl Erlang erlang FIX fix F# fsharp G-code(ISO 6983) gcode Gherkin gherkin GLSL glsl Go go Gradle gradle Groovy groovy Haml haml Handlebars handlebars Haskell haskell Haxe haxe HTML html HTTP http Ini file ini Java java JavaScript javascript JSON json Lasso lasso Less less Lisp lisp LiveCode livecodeserver LiveScript livescript Lua lua Makefile makefile Markdown markdown Mathematica mathematica Matlab matlab MEL (Maya Embedded Language) mel Mercury mercury Mizar mizar Monkey monkey Nginx nginx Nimrod nimrod Nix nix NSIS nsis Objective C objectivec OCaml ocaml Oxygene oxygene Parser 3 parser3 Perl perl PHP php PowerShell powershell Processing processing Python’s profiler output profile Protocol Buffers protobuf Puppet puppet Python python Q q R r RenderMan RIB rib Roboconf roboconf RenderMan RSL rsl Ruby ruby Oracle Rules Language ruleslanguage Rust rust Scala scala Scheme scheme Scilab scilab SCSS scss Smali smali SmallTalk smalltalk SML sml SQL sql Stata stata STEP Part21(ISO 10303-21) step21 Stylus stylus Swift swift Tcl tcl Tex tex text text/plain Thrift thrift Twig twig TypeScript typescript Vala vala VB.NET vbnet VBScript in HTML vbscript-html VBScript vbscript Verilog verilog VHDL vhdl Vim Script vim Intel x86 Assembly x86asm XL xl XML xml YAML yml Links \u0026lt;span id=\u0026#34;jump\u0026#34;\u0026gt;address\u0026lt;/span\u0026gt; or\n[links](#jump) Maths symbols and functions Tag of functions To name the functions with tag like below, we could us \\tag{1.1} or \\begin{equation} \u0026amp; \\end{equation}\n$$ x = y \\tag{1.1} $$ Example:\n$$ x = y \\tag{1.1} $$\n$$ \\begin{equation} x = y \\end{equation} $$ Example:\n$$ \\begin{equation} x = y \\end{equation} $$\n(As this website is build by hugo and the style file has not listed this rule, so the effect couldn’t be show well.)\nTable | Head_1 | Head_2 | Head_3 | | :- | :-: | -: | | Content_1 | Content_2 | Content_3 | Example:\nHead_1 Head_2 Head_3 Content_1 Content_2 Content_3 Line break within a cell With markdown language | Head_1 | Head_2 | | :-: | :-: | | Content_1 | Content_2 \u0026lt;br\u0026gt; Content_3 | Example:\nHead_1 Head_2 Content_1 Content_2 Content_3 With HTML language \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Head_1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_2\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td rowspan=\u0026#34;2\u0026#34;\u0026gt;Content_1\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Content_2-1\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Content_2-2\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; Example:\nHead_1 Head_2 Content_1 Content_2-1 Content_2-2 Special usage of HTML Change alignment \u0026lt;table\u0026gt; \u0026lt;tr align=\u0026#34;right\u0026#34;\u0026gt; \u0026lt;th\u0026gt;Head_1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_2\u0026lt;/th\u0026gt; \u0026lt;th align=\u0026#34;left\u0026#34;\u0026gt;Head_3\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td align=\u0026#34;right\u0026#34;\u0026gt;Content_1\u0026lt;/td\u0026gt; \u0026lt;td align=\u0026#34;center\u0026#34;\u0026gt;Content_2\u0026lt;/td\u0026gt; \u0026lt;td align=\u0026#34;left\u0026#34;\u0026gt;Content_3\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; Example:\nHead_1 Head_2 Head_3 Content_1 Content_2 Content_3 Table’s header \u0026lt;table\u0026gt; \u0026lt;caption\u0026gt; Header \u0026lt;/caption\u0026gt; \u0026lt;/table\u0026gt; Example:\nHeader Multipie columns within one grid \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Head_1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_2\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_3\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Content_1\u0026lt;/td\u0026gt; \u0026lt;td colspan=\u0026#34;2\u0026#34;\u0026gt;Content_2\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; Example:\nHead_1 Head_2 Head_3 Content_1 Content_2 ","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"fab9b605aac7aed8b2c5b792d4d1e104","permalink":"https://dante-su.github.io/notes/others/markdown/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/markdown/","section":"notes","summary":"Several markdown’s rule and quick command code\n","tags":["markdown"],"title":"Markdown","type":"book"},{"authors":null,"categories":null,"content":"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\n2024 2023 CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion [ paper | code ]\nKeywords: multi-modality, image fusion, dual branch feature decomposition\nAim: Render fused images that maintain the merits of different modalities, e.g., functional highlight and detailed textures.\nContribution:\nWe propose a dual-branch Transformer-CNN framework for extracting and fusing global and local features, which better reflects the distinct modality-specific and modality-shared features. We refine the CNN and Transformer blocks for a better adaptation to the MMIF task. Specifically, we are the first to utilize the INN blocks for lossless information transmission and the LT blocks for trading-off fusion quality and computational cost. We propose a correlation-driven decomposition loss function to enforce the modality shared/specific feature decomposition, which makes the cross-modality base features correlated while decorrelates the detailed high-frequency features in different modalities. Our method achieves leading image fusion performance for both IVF and MIF. We also present a unified measurement benchmark to justify how the IVF fusion im- ages facilitate downstream MM object detection and semantic segmentation tasks. Motivation: Our assumption is that, in the MMIF task, the input features of the two modalities are correlated at low frequencies, representing the modality-shared information, while the high-frequency feature is irrelevant and represents the unique characteristics of the respective modalities.\nArchitecture:\nOur CDDFuse contains four modules, i.e., a dual-branch encoder for feature extraction and decomposition, a decoder for reconstructing original images (in training stage I) or generating fusion images (in training stage II), and the base/detail fusion layer to fuse the different frequency features, respectively. Within the dual-branch encoder, Base Transformer Encoder focus low-frequency global cross-modality information while the Detail CNN Encoder focus on high-frequency local inner-modality information. And a correlation-driven decomposition loss function is designed to reduce the local similarity of different modality, enlarge the global similarity of different modality.\nComparison models: DIDFuse@IJCAI\u0026#39;20, Sdnet@IJCV\u0026#39;21, U2fusion@TPAMI\u0026#39;22, Rfnet@CVPR\u0026#39;22, TarD@CVPR\u0026#39;22, DeFusion@ECCV\u0026#39;22, Reconet@ECCV\u0026#39;22\n2022 2021 D-NeRF: Neural Radiance Fields for Dynamic Scenes [ homepage | paper | code ]\nKeywords: NeRF, dynamic scene\nAim: Extend neural radiance fields to a dynamic domain, allowing to reconstruct and render novel images of objects under rigid and non-rigid motions from a single camera moving around the scene.\nContribution:\nProposed a new method: D-NeRF, which is the first approach able to generate a neural implicit representation for non-rigid and time-varying scenes, trained solely on monocular data without the need of 3D ground-truth supervision nor a multi-view camera setting. Sufficient experiments were done to demonstrate the effectiveness of proposed approach on scenes with objects under rigid, articulated and non-rigid motions. Motivation: Considering time as an additional input to the system, so we could split the learning process in two main stages: one that encodes the scene into a canon- ical space and another that maps this canonical representation into the deformed scene at a particular time.\nArchitecture:\nD-NeRF consists of two main neural network modules, Canonical Network and Deformation Network, which parameterize the mappings $Ψ_t$(from point’s position in time-varying scene to point’s position in canonical scene), $Ψ_x$(from point’s position \u0026amp; viewing direction to emitted color \u0026amp; volume density).\nComparison models: NeRF@ECCV\u0026#39;20, T-NeRF(Time-conditioned NeRF)@This paper\n","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711497600,"objectID":"b783698d6808787422481fe429d923ef","permalink":"https://dante-su.github.io/notes/paper_reading/cvpr/","publishdate":"2024-03-27T00:00:00Z","relpermalink":"/notes/paper_reading/cvpr/","section":"notes","summary":"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\n","tags":["cvpr","paper"],"title":"CVPR","type":"book"},{"authors":null,"categories":null,"content":"Greg Turk, August 2019\nTwenty-two years ago, I wrote an essay about what math is important for computer graphics. That document is now fairly dated, and I have decided that it is time to re-visit this question. I am writing this essay in part for college students who want to know what courses may be relevant to the study of computer graphics. For this reason, I will remark on the departments that are likely to offer courses in a given topic. Hopefully it is obvious that you do not need to be a college student to read this essay!\nComputer graphics draws upon many different areas of mathematics for tools that help accomplish various computational tasks. For as long as you want to pursue computer graphics, you should also plan to continue to learn more mathematical techniques. There are very few corners of computer graphics that do not make use of some form of mathematics.\nThe most important point that I want to convey in this essay is the following. The mathematical topics that are often the most useful to graphics are so-called Numerical Methods. These are the tools that take abstract mathematical concepts (differentiation, integration, matrix inversion, etc.) and turn them into concrete algorithms that we can use to find numerical results to the problem at hand. When you first learn in calculus class how to differentiate and integrate, you start by doing this symbolically. (For example, the derivative of the sine function is cosine.) In graphics, we need to be able to translate the symbolic answer to a given problem into a numerical technique that can be implemented on the computer. For this reason, it is most often the applied mathematics courses (not those in pure mathematics)that are the most relevant to graphics.\nThe numerical methods that are useful for graphics are frequently the same tools that various engineers use. This means that sometimes the most useful courses for graphics may not be in the math department. They may instead be found in other departments such as electrical engineering or mechanical engineering.\nIn this essay I am going to refer the four core areas of computer graphics. These areas are:\nModeling - creating 3D shape descriptions of objects Animation - making objects move Image Synthesis, also called Rendering - making pictures from 3D shapes Image and Video Manipulation I am going to visit the mathematics useful to graphics in an order that (approximately) lines up with the order of the four topics listed above. Note that modeling and animation often make use of similar mathematics. The same is true of the other pair — image synthesis and image/video manipulation often use similar math tools. Before I visit any of these topics, however, I am going to start with the math needed for a first course in graphics.\nMathematical Basics: Linear Algebra and Trigonometry The most important topics for starting out in graphics are Linear Algebra and Trigonometry. We usually describe the location of a 3D graphics object according to its x, y and z coordinates. We can then apply the following operations on a 3D object: translate (move), scale (change size), and rotate. Translation and scale are accomplished using addition and multiplication, respectively. Rotation is done using sine and cosine, hence the need for trigonometry. The x, y and z coordinates of an object can be conveniently represented as a 3D vector, and the translate, scale and rotate operations can be described as multiplication by a matrix (of size 3x3 or 4x4). This is one of the reasons that a background in linear algebra is important for starting in graphics. Several other concepts from linear algebra also are useful, including matrix inversion, dot product, and cross product.\nMultivariable Calculus Many of the more advanced topics in computer graphics make use of the tools of Multivariable Calculus. These topics are usually saved for a second or third course in calculus. Many of the representations that are used in computer graphics are functions of multiple variables, and thus require tools to reason about derivatives and integrals of such functions. If you want to study computer graphics beyond a first course in the area, I strongly recommend taking the full sequence of calculus classes that your school offers.\nDifferential Geometry Differential Geometry is the measurement of properties of curves and surfaces, and these techniques are very important for modeling in graphics. Common graphics-related tasks that fall under this domain include determining tangents, measuring curvature, evaluating lengths and areas, and finding shortest paths. Often differential geometry techniques are combined with optimization methods (more on this below). Fortunately, many math departments offer an undergraduate course in differential geometry.\nComputational Geometry Computational Geometry is the study of algorithms that efficiently and robustly solve geometric problems. Some common problems in this area include find convex hulls, finding …","date":1695859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695859200,"objectID":"51efd94295384cf111b8730dc22ee835","permalink":"https://dante-su.github.io/notes/computer_graphics/math/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/notes/computer_graphics/math/","section":"notes","summary":"Greg Turk, August 2019\n","tags":["Math","Computer Graphics"],"title":"Math for Computer Graphics","type":"book"},{"authors":null,"categories":null,"content":"Python code instances\nimage format transfermation common import cv2 import os import glob def change_img_format(): # iterations path = input(r\u0026#34;Input the path of image to be processed(eg: D:\\picture\\1.jpg):\u0026#34;) print(\u0026#39;Path of image here is : \u0026#39;,path) path_rewrite = input(r\u0026#34;Input the path of restoring the image(eg: D:\\picture):\u0026#34;) img_format = input(r\u0026#34;Input the format you want(eg: jpg):\u0026#34;) for i in glob.glob(path): print(\u0026#39;I here is : \u0026#39;, i) im = cv2.imread(i) new_path = os.path.join(path_rewrite,\u0026#39;new_name\u0026#39;+\u0026#39;.\u0026#39;+img_format) cv2.imwrite(new_path,im) if __name__ == \u0026#39;__main__\u0026#39;: change_img_format() 针对 ico （图标）文件 \u0026#39;\u0026#39;\u0026#39; 常用图标大小： [ (256, 256), (128, 128), (64, 64), (48, 48), (32, 32), (24, 24), (16, 16) ] \u0026#39;\u0026#39;\u0026#39; from PIL import Image def make_ico_file(src_image_file, dist_ico_file, size): size = [int(size), int(size)] image = Image.open(src_image_file) image_cropped = image.crop((0, 0, 256, 256)) image_cropped.save(dist_ico_file, sizes=size) if __name__ == \u0026#39;__main__\u0026#39;: make_ico_file(input(r\u0026#34;Input the path of the image(eg: D:\\picture\\1.jpg):\u0026#34;), input(r\u0026#39;Input the name of icon(eg: favicon):\u0026#39;), input(r\u0026#39;Input the same of icon(eg: 256):\u0026#39;)) image Portrait Matting from rembg import remove from PIL import Image in_path = \u0026#39;example.jpg\u0026#39; out_path = \u0026#39;output.jpg\u0026#39; image_in = Image.open(in_path) image_out = remove(image_in) image_out.save(out_path) image resize import cv2 import os import glob def img_resize(): # iterations path = input(r\u0026#34;Input the path of image to be processed(eg: D:\\picture\\1.jpg):\u0026#34;) print(\u0026#39;Path of image here is : \u0026#39;,path) path_rewrite = input(r\u0026#34;Input the path of restoring the image(eg: D:\\picture):\u0026#34;) for i in glob.glob(path): print(\u0026#39;I here is : \u0026#39;, i) im1 = cv2.imread(i) # print(\u0026#39;The original image data are: \u0026#39;, im1) im2 = cv2.resize(im1,(256,256)) # (256,256)是缩放后的像素数 # print(\u0026#39;The resized image data are: \u0026#39;, im2) cv2.imwrite(os.path.join(path_rewrite,\u0026#39;resized_\u0026#39; + os.path.basename(i)),im2) if __name__ == \u0026#39;__main__\u0026#39;: img_resize() point cloud visualizer import open3d as o3d import numpy as np raw_point = np.arange(3000).reshape(3,-1) #创建窗口对象 vis = o3d.visualization.Visualizer() #设置窗口标题 vis.create_window(window_name=\u0026#34;example\u0026#34;) #设置点云大小 vis.get_render_option().point_size = 1 #设置颜色背景为黑色 opt = vis.get_render_option() opt.background_color = np.asarray([0, 0, 0]) #创建点云对象 pcd=o3d.open3d.geometry.PointCloud() #将点云数据转换为Open3d可以直接使用的数据类型 pcd.points= o3d.open3d.utility.Vector3dVector(raw_point) #设置点的颜色为白色 pcd.paint_uniform_color([1,1,1]) #将点云加入到窗口中 vis.add_geometry(pcd) vis.run() vis.destroy_window() meshlab ply2obj 使用meshlab 版本应该在2020.12之前（此处用2020.2），新建ply2obj.bat并将其放置在meshlabserver.exe同级的文件夹内，按照下述文字修改值，双击运行即可\n@echo off set input_path=D:\\inputFolder set output_path=D:\\outputFolder dir %input_path%\\*.ply /b/od\u0026gt;%input_path%\\name.txt for /F %%i in (%input_path%\\name.txt) do ( meshlabserver -i %input_path%\\%%i -o %output_path%\\%%~ni.obj -m vc vn fn) rem 上面第二行 -m 后的参数说明（参数根据需要自行修改）vc 顶点颜色，vf 顶点标志，vq 顶点质量，vn 顶点法线 vt 顶点纹理坐标，vr 顶点半径，fc 面色，ff 面标志，fq 面部质量，fn 面部法线，wc 楔形颜色，wn 楔形法线，wt 楔形纹理，mp 多边形网格信息 obj2ply 同上\n@echo off set input_path=D:\\inputFolder set output_path=D:\\outputFolder dir %input_path%\\*.obj /b/od\u0026gt;%input_path%\\name.txt for /F %%i in (%input_path%\\name.txt) do ( meshlabserver -i %input_path%\\%%i -o %output_path%\\%%~ni.ply -m vc vn fn) rem 上面第二行 -m 后的参数说明（参数根据需要自行修改）vc 顶点颜色，vf 顶点标志，vq 顶点质量，vn 顶点法线 vt 顶点纹理坐标，vr 顶点半径，fc 面色，ff 面标志，fq 面部质量，fn 面部法线，wc 楔形颜色，wn 楔形法线，wt 楔形纹理，mp 多边形网格信息 PyTorch train.py import time import click from datetime import datetime import torch # from torch import nn from torch.utils.data import DataLoader # from torch.utils.tensorboard import SummaryWriter # from sklearn.metrics import confusion_matrix from utils.loss import * from utils.model import * from utils.loader import * from utils.others import * def train(gpu_set, epoch, learning_rate, data_path, batch_size, loss, weight_decay=\u0026#39;0.00001\u0026#39;, model_name = \u0026#39;dp_cnn\u0026#39;, time_now = \u0026#39;fake time\u0026#39;): # Load train and val data print(\u0026#39;Loading data...\u0026#39;) trainset, valset = load_train_data(data_path) # Get and print useful settings print(\u0026#39;Getting settings...\u0026#39;) train_data_size,val_data_size,n_classes,input_lenghth = get_setting(trainset, valset) # Using DataLoader to load data print(\u0026#39;Setting dataloader...\u0026#39;) train_dataloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True ) val_dataloader = DataLoader(dataset=valset, batch_size=batch_size, shuffle=True ) # Set pytorch device print(\u0026#39;Setting device...\u0026#39;) device = get_device_name(gpu_set) # Create the model print(\u0026#39;Creating model network...\u0026#39;) model = model_set(model_name,n_classes, batch_size,input_lenghth).to(device) # Creat loss function print(\u0026#39;Creating loss function...\u0026#39;) loss_fn = loss_set(loss,device) # create optimizer print(\u0026#39;Creating optimizer...\u0026#39;) # optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False) # set some sets total_train_step = 0 # record training\u0026#39;s number # …","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"8fcc841d388c336609360020d90907b1","permalink":"https://dante-su.github.io/notes/code_instance/python/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/code_instance/python/","section":"notes","summary":"Python code instances\n","tags":["example"],"title":"Python","type":"book"},{"authors":null,"categories":null,"content":"My Collection\nDaily Life 知乎 https://www.zhihu.com/\nBilibili https://www.bilibili.com/\nInfo HK GOV holiday https://www.gov.hk/tc/about/abouthk/holiday/\nHK Visa Online Application Status Enquiry https://www.gov.hk/en/residents/immigration/nonpermanent/appstatusenq.htm\nHK Visa Extension Online Application https://www.gov.hk/sc/residents/immigration/nonpermanent/applyextensionstay/othernpr.htm\nPolyU PolyU account https://adfs.polyu.edu.hk/adfs/ls/\nPolyU ELC Booking System https://elc.polyu.edu.hk/booking/main.php\nPolyU Payroll https://www.polyu.edu.hk/fo/staff/full-time-staff/payroll/\nPolyU Leave Online Application https://www40.polyu.edu.hk/hrchris/\nRecruit IBM https://www.ibm.com/cn-zh/employment/internship/\nMSRA https://www.msra.cn/zh-cn/jobs\nEntertainment 低端影视 https://ddrk.me/ https://ddys.love https://ddys.pro/ https://ddys.mov/\n美剧7 https://www.meiju7.cc/\n韩剧看看 https://www.hanjukankan.com/\n爱壹帆影视 https://www.aiyifan.tv/drama\nUntitled http://transition.vipray.cn/\nOthers 新加坡工作指南 https://www.965work.in/archives/work-guide-for-singapore/\n申请苏黎世联邦理工学院生物学博士需要做哪些准备？ https://www.zhihu.com/question/532997474/answer/2549675321\n一篇CVPR论文掀起业界研究热潮，这位90后却将代码开源，促进知识蒸馏研究 | 专访 https://zhuanlan.zhihu.com/p/407941252\nWriting a SIGGRAPH paper (for fun) https://www.mattkeeter.com/projects/siggraph/\n小霸王 模拟器 https://www.yikm.net/\n中国历史时间轴 https://www.lishiju.net/timeline.html\n","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"c2a757c1d745cf66f231f331237019ee","permalink":"https://dante-su.github.io/notes/links/collection/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/links/collection/","section":"notes","summary":"My Collection\n","tags":["Links"],"title":"Collection","type":"book"},{"authors":null,"categories":null,"content":"Proceedings of the IEEE/CVF International Conference on Computer Vision\n2023 Task-Oriented Multi-Modal Mutual Leaning for Vision-Language Models [ paper ]\nKeywords: **\nAim:\nContribution:\nMotivation:\nArchitecture:\nComparison models:\n","date":1711324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711324800,"objectID":"99afdbae7cf688a2fd21c485e0549bf5","permalink":"https://dante-su.github.io/notes/paper_reading/iccv/","publishdate":"2024-03-25T00:00:00Z","relpermalink":"/notes/paper_reading/iccv/","section":"notes","summary":"Proceedings of the IEEE/CVF International Conference on Computer Vision\n","tags":["iccv","paper"],"title":"ICCV","type":"book"},{"authors":null,"categories":null,"content":"Gitbook’s installation and usage\nInstallation Nodejs 因为Gitbook依赖Nodejs，所以首先要安装Nodejs，而且因为gitbook后来很久未更新，所以对新版的nodejs兼容性不好，容易出bug，建议最多使用到第10版的nodejs\nMac\n从 https://nodejs.org/en/ 下载并安装 Nodejs ，安装完后可通过终端命令 node -v 检验是否安装成功。\n后面可能报错，所以可以直接通过 brew 命令下载低版本的 nodejs：\nbrew install node@10 echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/node@10/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc\nCheck installation status\nnode -v npm -v\n如果上述方法不可以继续使用，请点击此处\npwd cd source .bash_profile\nLinux\nUnder building…\nWindows\nUnder building…\nGitbook npm install gitbook-cli -g\ngitbook -V\nUsage Initialize a new book gitbook init\nBuild gitbook build\n若只执行gitbook build，会生成_book目录，但不能预览。\n在这个目录中，对于每一个 markdown 文件都生成了一个相应的 html 文件，同时在 _book/gitbook 文件夹中存放了一些主题、字体、样式与图像等文件\nPreview gitbook serve ./{book_name} 最后一个参数指定输出静态网站内容的目录，可省略，默认会在当前目录下新建一个子目录_book\n(base) dantesu@DanteSudeMacBook-Pro gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 14 explicitly listed info: loading plugin \u0026#34;splitter\u0026#34;... OK info: loading plugin \u0026#34;expandable-chapters-small\u0026#34;... OK info: loading plugin \u0026#34;anchors\u0026#34;... OK info: loading plugin \u0026#34;github\u0026#34;... OK info: loading plugin \u0026#34;github-buttons\u0026#34;... OK info: loading plugin \u0026#34;sharing-plus\u0026#34;... OK info: loading plugin \u0026#34;anchor-navigation-ex\u0026#34;... OK info: loading plugin \u0026#34;favicon\u0026#34;... OK info: loading plugin \u0026#34;livereload\u0026#34;... OK info: loading plugin \u0026#34;highlight\u0026#34;... OK info: loading plugin \u0026#34;search\u0026#34;... OK info: loading plugin \u0026#34;lunr\u0026#34;... OK info: loading plugin \u0026#34;fontsettings\u0026#34;... OK info: loading plugin \u0026#34;theme-default\u0026#34;... OK info: found 10 pages info: found 2 asset files info: \u0026gt;\u0026gt; generation finished with success in 1.1s ! Starting server ... Serving book on http://localhost:4000 Styles gitbook install\n更新样式中的插件后需要使用此命令来安装新的插件，否则会报错，比如：\n(base) dantesu@DanteSudeMBP gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 16 explicitly listed Error: Couldn\u0026#39;t locate plugins \u0026#34;page-footer-ex\u0026#34;, Run \u0026#39;gitbook install\u0026#39; to install plugins from registry. Style example 以下是我暂时在使用的样式\n{ \u0026#34;title\u0026#34;: \u0026#34;DanteSU\u0026#39;s House\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;DanteSU\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;All I know is here\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;zh-hans\u0026#34;, \u0026#34;gitbook\u0026#34;: \u0026#34;3.2.3\u0026#34;, \u0026#34;styles\u0026#34;: { \u0026#34;website\u0026#34;: \u0026#34;./styles/website.css\u0026#34; }, \u0026#34;structure\u0026#34;: { \u0026#34;readme\u0026#34;: \u0026#34;README.md\u0026#34; }, \u0026#34;links\u0026#34;: { \u0026#34;sidebar\u0026#34;: { \u0026#34;但丁世界（在建）\u0026#34;: \u0026#34;https://dante-su.github.io/\u0026#34; } }, \u0026#34;plugins\u0026#34;: [ \u0026#34;-sharing\u0026#34;, \u0026#34;splitter\u0026#34;, \u0026#34;expandable-chapters-small\u0026#34;, \u0026#34;anchors\u0026#34;, \u0026#34;github\u0026#34;, \u0026#34;github-buttons\u0026#34;, \u0026#34;sharing-plus\u0026#34;, \u0026#34;anchor-navigation-ex\u0026#34;, \u0026#34;favicon\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;github\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/Dante-Su\u0026#34; }, \u0026#34;sharing\u0026#34;: { \u0026#34;douban\u0026#34;: false, \u0026#34;facebook\u0026#34;: false, \u0026#34;google\u0026#34;: false, \u0026#34;hatenaBookmark\u0026#34;: false, \u0026#34;instapaper\u0026#34;: false, \u0026#34;line\u0026#34;: false, \u0026#34;linkedin\u0026#34;: false, \u0026#34;messenger\u0026#34;: false, \u0026#34;pocket\u0026#34;: false, \u0026#34;qq\u0026#34;: false, \u0026#34;qzone\u0026#34;: false, \u0026#34;stumbleupon\u0026#34;: false, \u0026#34;twitter\u0026#34;: false, \u0026#34;viber\u0026#34;: false, \u0026#34;vk\u0026#34;: false, \u0026#34;weibo\u0026#34;: false, \u0026#34;whatsapp\u0026#34;: false, \u0026#34;all\u0026#34;: [ \u0026#34;google\u0026#34;, \u0026#34;facebook\u0026#34;, \u0026#34;weibo\u0026#34;, \u0026#34;twitter\u0026#34;, \u0026#34;qq\u0026#34;, \u0026#34;qzone\u0026#34;, \u0026#34;linkedin\u0026#34;, \u0026#34;pocket\u0026#34; ] }, \u0026#34;anchor-navigation-ex\u0026#34;: { \u0026#34;showLevel\u0026#34;: false }, \u0026#34;favicon\u0026#34;:{ \u0026#34;shortcut\u0026#34;: \u0026#34;./source/images/favicon.jpg\u0026#34;, \u0026#34;bookmark\u0026#34;: \u0026#34;./source/images/favicon.jpg\u0026#34;, \u0026#34;appleTouch\u0026#34;: \u0026#34;./source/images/apple-touch-icon.jpg\u0026#34;, \u0026#34;appleTouchMore\u0026#34;: { \u0026#34;120x120\u0026#34;: \u0026#34;./source/images/apple-touch-icon.jpg\u0026#34;, \u0026#34;180x180\u0026#34;: \u0026#34;./source/images/apple-touch-icon.jpg\u0026#34; } } } } Style website https://www.npmjs.com/search?q=gitbook-plugin-theme\u0026amp;ranking=quality\nDeploy with Github Page Updating\n","date":1695859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695859200,"objectID":"e339be0ee66c7ceb5bac85c0be6541e9","permalink":"https://dante-su.github.io/notes/others/gitbook/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/notes/others/gitbook/","section":"notes","summary":"Gitbook’s installation and usage\n","tags":["gitbook","html"],"title":"Gitbook","type":"book"},{"authors":null,"categories":null,"content":"Notes for GAMES101\nOverview GAMES is short for ‘Graphics And Mixed Environment Symposium’, which is a study platium designed for sharing knowledge about ‘Computer Graphics’ for those who haven’t or won’t have been enrolled in related course but have ambition and interest to learn it by themselves.\nAnd GAMES101 is one of them, at the same time, the basicest one. It’s taught by Dr. Lingqi YAN, an Assist. Prof. of UCSB.\nUpdating soon.","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"0b6be1bd42699716f811a9ed64bfc3aa","permalink":"https://dante-su.github.io/notes/computer_graphics/games101/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/computer_graphics/games101/","section":"notes","summary":"Notes for GAMES101\n","tags":["GAMES101"],"title":"GAMES101","type":"book"},{"authors":null,"categories":null,"content":"Some pip commands.\nUsage Install package pip install \u0026lt;package_name\u0026gt;\npip install \u0026lt;package_name\u0026gt;==\u0026lt;version\u0026gt;\nrequirements.txt Create a requirements.txt pip freeze \u0026gt; requirements.txt\nInstall packages from requirements.txt pip install -r requirements.txt\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"9bf9f19235b021fd6ca3b18d3cc8185c","permalink":"https://dante-su.github.io/notes/python/pip/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/python/pip/","section":"notes","summary":"Some pip commands.\n","tags":["Pip"],"title":"Pip","type":"book"},{"authors":null,"categories":null,"content":"Powershell command in Windows\nTable of Contents Clear the screen Info Files in current folder Current pathway Change path GPU status Memory chip Install anaconda on Powershell Clear the screen cls\nInfo Files in current folder dir\nCurrent pathway chdir\nChange path cd \u0026lt;dir\u0026gt;\nGPU status cd C:\\Program Files\\NVIDIA Corporation\\NVSMI nvidia-smi\nMemory chip wmic memorychip get /value\nInstall anaconda on Powershell","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"ec599c625f8528e2dc358fd51a81502f","permalink":"https://dante-su.github.io/notes/shell/windows/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/shell/windows/","section":"notes","summary":"Powershell command in Windows\n","tags":["Windows","Powershell"],"title":"Windows","type":"book"},{"authors":null,"categories":null,"content":"European Conference on Computer Vision\n2022 2020 NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis [ homepage | paper | code-TensorFlow | code-PyTorch ]\nKeywords: NeRF, image synthesis, volume rendering\nAim: Propose Neural Radiance Field to synthesize novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views and MLP.\nContribution:\nAn approach for representing continuous scenes with complex geometry and materials as 5D neural radiance fields, parameterized as basic MLP networks. A differentiable rendering procedure based on classical volume rendering techniques, which we use to optimize these representations from standard RGB images. This includes a hierarchical sampling strategy to allocate the MLP’s capacity towards space with visible scene content. A positional encoding to map each input 5D coordinate into a higher dimensional space, which enables us to successfully optimize neural radiance fields to represent high-frequency scene content. Motivation: Using MLPs to represent objects and scenes as continuous functions is of many benefits. As volume rendering is naturally differentiable, if only using MLPs to memorize and calculate the color and volume density of emitted radiance, the architecture of MLP won’t be too complex, so the performance would be superior.\nArchitecture:\nNeRF takes x-y-z location in Cartesian coordinates of queried points and viewing direction as input. After passing a pure MLP, NeRF output the color of $RGB\\alpha$ and its volume density. And then, classical volume rendering techniques will be applied to accumulate those colors and densities into a 2D image.\nComparison models: LLFF@SIGGRAPH\u0026#39;19, SRN@NeurIPS\u0026#39;19, NV@SIGGRAPH\u0026#39;19\n","date":1714003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714003200,"objectID":"22257c0f062ca56b494e92060aa87490","permalink":"https://dante-su.github.io/notes/paper_reading/eccv/","publishdate":"2024-04-25T00:00:00Z","relpermalink":"/notes/paper_reading/eccv/","section":"notes","summary":"European Conference on Computer Vision\n","tags":["eccv","paper"],"title":"ECCV","type":"book"},{"authors":null,"categories":null,"content":"Links for dealing with specific situation when debugging.\nMirror 清华源 https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/\nhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/\nAccepted Paper List MICCAI 2021 https://miccai2021.org/openaccess/paperlinks/index.html\nMICCAI 2022 https://conferences.miccai.org/2022/papers/\nMICCAI 2023 https://conferences.miccai.org/2023/papers/\nNeurIPS‘2023 Accepted Paper List@PaperDigest https://www.paperdigest.org/data/neurips-2023-full.html\nCVPR 2023 https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers\nCVPR 2023 最全整理@极市 https://www.cvmart.net/community/detail/7422#3DReconstruction\nMedcial Image Analysis batchgenerators by MIC@DKFZ (Data augmentation for 2D/3D image classification/segmentation) https://github.com/MIC-DKFZ/batchgenerators\nCardiac Imaging https://www.creatis.insa-lyon.fr/~bernard/research.html\nUltrasound, General@Embodi3D https://www.embodi3d.com/files/category/58-ultrasound-general/\nFetal, Pregnant Women and Infants Numerical Models http://femonum.telecom-paristech.fr/projects.html\nAwesome-Ultrasound-Standard-Plane-Detection https://github.com/Yulv-git/Awesome-Ultrasound-Standard-Plane-Detection\nDeep Learning 使用Pytorch框架自己制作做数据集进行图像分类 https://blog.csdn.net/zwy_697198/article/details/123561769 https://blog.csdn.net/zwy_697198/article/details/123587399 https://blog.csdn.net/zwy_697198/article/details/123584396\n一文弄懂pytorch搭建网络流程+多分类评价指标 https://cloud.tencent.com/developer/article/1825669\nPytorch 构建简单Neural Networks https://blog.csdn.net/weixin_42888638/article/details/121679700\npytorch 加载大数据集 内存不够 的处理方式 https://blog.csdn.net/cjs8348797/article/details/115708811\nhttps://www.cnblogs.com/aminor/p/14336767.html\nhttps://www.zhihu.com/question/386743819/answer/1989311050\nhttps://www.cnblogs.com/xiaosongshine/p/10750908.html\nAdaptivePooling与Max/AvgPooling相互转换 https://www.cnblogs.com/xiaosongshine/p/10750908.html\nPython中生成并绘制混淆矩阵 https://blog.csdn.net/kane7csdn/article/details/83756583\nPytorch 完整的模型训练套路 https://blog.csdn.net/weixin_45468845/article/details/122971739\nhttps://zhuanlan.zhihu.com/p/464796719\nhttps://blog.csdn.net/FUTEROX/article/details/122724634\npytorch中根据神经网络结构确定输入图片尺寸/根据图片尺寸修改神经网络结构 https://blog.csdn.net/weixin_43423455/article/details/99096580\ntorch.nn.AdaptiveAvgPool1d(N)函数解读 https://blog.csdn.net/qq_40178291/article/details/102699493\ntorch.view()详解及-1参数是什么意思 https://www.cnblogs.com/MartinLwx/p/10543604.html\nPytorch常用的交叉熵损失函数CrossEntropyLoss()详解 https://zhuanlan.zhihu.com/p/98785902\nPyTorch 多分类损失函数 https://blog.csdn.net/jacke121/article/details/104665912/\npytorch的各种loss https://blog.csdn.net/qq_22764813/article/details/104867431\nPyTorch Bert文本分类 https://blog.csdn.net/weixin_44912902/article/details/123886825\n二分类问题：基于BERT的文本分类实践！附完整代码 https://blog.csdn.net/Datawhale/article/details/104871803?spm=1001.2101.3001.6650.3\u0026amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-104871803-blog-123886825.pc_relevant_default\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-104871803-blog-123886825.pc_relevant_default\u0026amp;utm_relevant_index=6\nBERT-使用tf生成pytorch_model.bin https://www.freesion.com/article/9725381185/\nPyTorch之nn.ReLU与F.ReLU的区别 https://blog.csdn.net/u011501388/article/details/86602275\nPytorch入门教程（十）：ResNet图片分类实战 https://blog.csdn.net/weixin_43472830/article/details/95871258?spm=1001.2101.3001.6650.3\u0026amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-95871258-blog-107028785.pc_relevant_default\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-95871258-blog-107028785.pc_relevant_default\u0026amp;utm_relevant_index=5\npytorch版yolov3训练自己数据集 https://www.cnblogs.com/pprp/p/10863496.html\nhttps://github.com/BobLiu20/YOLOv3_PyTorch\nhttps://github.com/cxjaicj/keras-yolo3\nhttps://github.com/pprp/yolov3.keras\nImportError:无法从“tensorflow”导入名称“Session” https://www.cnpython.com/qa/1297701\nAdam优化算法详细解析 https://blog.csdn.net/luoxuexiong/article/details/90412213\nhttps://www.cnblogs.com/wuchengze/p/13610500.html\n理解语言的 Transformer 模型 https://tensorflow.google.cn/tutorials/text/transformer\nCLIP解读-博客园 https://www.cnblogs.com/lxmj/p/15945772.html\n使用Pytorch框架自己制作做数据集进行图像分类（一） https://blog.csdn.net/zwy_697198/article/details/123561769\n使用Pytorch框架自己制作做数据集进行图像分类（二） https://blog.csdn.net/zwy_697198/article/details/123587399\n使用Pytorch框架自己制作做数据集进行图像分类（三） https://blog.csdn.net/zwy_697198/article/details/123584396\nPytorch 运行错误 ValueError: too many dimensions ‘str’ 解决方案 https://www.cnblogs.com/ZhangHT97/p/13497169.html\n一文弄懂pytorch搭建网络流程+多分类评价指标 https://cloud.tencent.com/developer/article/1825669\nPytorch 创建Tensor https://blog.csdn.net/weicao1990/article/details/93495523\npapers Vision Transformer 必读系列之图像分类综述(一)：概述 https://zhuanlan.zhihu.com/p/459828118\n面向多场景低资源加密流量分类的加密流量预训练技术 https://zhuanlan.zhihu.com/p/483285843\n跨模态检索 Iterative Matching with Recurrent Attention Memory for Cross-Modal Image-Text Retrieval …","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"029b0762cd79953e0d48cf025045c3f0","permalink":"https://dante-su.github.io/notes/links/others/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/links/others/","section":"notes","summary":"Links for dealing with specific situation when debugging.\n","tags":["Links"],"title":"Others","type":"book"},{"authors":null,"categories":null,"content":"Pytorch documents\nInstallation See more at Pytorch official website: link\nAn instance For CUDA 11.3\nconda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -c conda-forge If you are at Mainland of China, you may need TsingHua’s source\nAddress\nhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/\nhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/\ncommand\nconda install cudatoolkit=11.3 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/ conda install pytorch torchvision torchaudio -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ Be patient here to ensure the version of Pytorch to install is GPU. Check the status of installation Type python in command/bash.\nAnd input the command below.\nimport torch torch.cuda.is_available() torch.cuda.get_device_name() torch.__version__ torch.cuda.device_count() Usage torch.cuda.empty_cache() As there is cache in Pytorch, even when a tensor is set free, the thread won’t give the occupied GPU memory back to GPU but wait for next tensor to occupy this part of GPU memory, which could apparently affect the efficiency of GPU memory’s allocation.\nAs an example, it could be add like the below code instance.\nfor i, data in enumerate(data_loader): torch.cuda.empty_cache() img_meta = data[\u0026#39;img_meta\u0026#39;][0].data[0] img_name = img_meta[0][\u0026#39;filename\u0026#39;].split(\u0026#39;/\u0026#39;)[-1] with torch.no_grad(): result = model(return_loss=False, rescale=not show, **data) torch.flatten 展平一个连续范围的维度，输出类型为Tensor\nt = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]]) #当开始维度为0，最后维度为-1，展开为一维 torch.flatten(t) # output = tensor([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) #当开始维度为0，最后维度为-1，展开为3x4，也就是说第一维度不变，后面的压缩 torch.flatten(t, start_dim=1) # tensor([[ 1, 2, 3, 4], # [ 5, 6, 7, 8], # [ 9, 10, 11, 12]]) #下面的和上面进行对比应该就能看出是，当锁定最后的维度的时候 #前面的就会合并 torch.flatten(t, start_dim=0, end_dim=1) # tensor([[ 1, 2], # [ 3, 4], # [ 5, 6], # [ 7, 8], # [ 9, 10], # [11, 12]]) start_dim: first dim to flatten (default = 1).\nend_dim: last dim to flatten (default = -1).\n如无指定，该展平层会将除了第0维度（一般是batch_size）以外的所有维度展开成一维矩阵\ntorch.grad # 清除以前的梯度 x.grad.data.zero_() torch.matmul tensor的矩阵乘法\ne.g.\nimport torch print(torch.matmul(torch.ones(3,4), torch.ones(4,2)).shape) torch.size([3,2])\ntensor维度不同时， 维度多出来的看作batch，其余再相乘 import torch print(torch.matmul(torch.ones(5,3,4), torch.ones(4,2)).shape) torch.size([5,3,2])\n根据broadcast原则，首位不同时，应该将少的broadcast成多的 import torch print(torch.matmul(torch.ones(2,5,3), torch.ones(1,3,4)).shape) torch.size([2,5,4])\n维度不同+提出batch后首位仍不同 import torch print(torch.matmul(torch.ones(2,1,3,4), torch.ones(5,4,2)).shape) torch.size([2,5,3,2])\ntorch.nn.Flatten 一般用于network的定义\ntorch.nn.module.apply 将一个函数fn递归地应用到模块自身以及该模块的每一个子模块(即在函数.children()中返回的子模块).该方法通常用来初始化一个模型中的参数(另见torch-nn-init部分的内容).\nnet = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): print(m) if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights); torch.nn.module.parameters import torch import torch.nn as nn class mymodule(nn.Module): def __init__(self): super(mymodule,self).__init__() self.linear=nn.Linear(2,3) self.relu=nn.ReLU() def forward(self,x): x=self.linear(x) x=self.relu(x) return x model=mymodule() print(\u0026#34;模型参数：\u0026#34;,list((model.parameters()))) for param in model.parameters(): print(\u0026#34;参数类型：\u0026#34;,type(param),\u0026#34;参数大小：\u0026#34;,param.size()) torch.numel 显示tensor中元素的个数\nimport torch a = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) print(a.numel()) # 6 torch.set_printoptions import torch torch.set_printoptions(profile=\u0026#34;full\u0026#34;) torch.shape import torch a = torch.rand(3,4) print(\u0026#39;a.shape = \u0026#39;, a.shape) print(\u0026#39;a.shape[0] = \u0026#39;, a.shape[0]) torch.tensor.flatten Equal to torch.flatten\nOthers Print nn.Module For a network as a class of nn.Module as below,\nimport torch from torch import nn class testModel(nn.Module): def __init__(self): super(testModel,self).__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, bias=False) self.relu1 = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, bias=False) self.relu2 = nn.ReLU(inplace=True) self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, bias=False) def forward(self, x): out = self.conv1(x) out = self.relu1(out) out = self.conv2(out) out = self.relu2(out) out = self.conv3(out) return out To print it out to check the structure of network, we could use code like below,\nmodel = testModel() print(model) Result will be:\ntestModel( (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), bias=False) (relu1): ReLU(inplace=True) (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), bias=False) (relu2): ReLU(inplace=True) (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False) ) Or using torch-summary to check, like below\npin install torch-summary\nfrom torchsummary import summary model = testModel() summary(model, (3, 224, 224)) Result will be: …","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"0f3c42271133bb745150a332e1acf0fa","permalink":"https://dante-su.github.io/notes/python/pytorch/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/python/pytorch/","section":"notes","summary":"Pytorch documents\n","tags":["Pytorch","python"],"title":"Pytorch","type":"book"},{"authors":null,"categories":null,"content":"Some documents of docker\nTable of Contents Updating Bugs record Opencv ImportError Updating Bugs record Opencv ImportError ImportError: libGL.so.1: cannot open shared object file: No such file or directory If you install opencv by pip install opencv-python before, you could use the below method.\npip uninstall opencv-python\npip install opencv-python-headless\n","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"506892610f251070d8f0894a92eff1da","permalink":"https://dante-su.github.io/notes/shell/docker/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/shell/docker/","section":"notes","summary":"Some documents of docker\n","tags":["Docker"],"title":"Docker","type":"book"},{"authors":null,"categories":null,"content":"Notes\nUsage Static forwarding in LAN hugo server --bind 192.168.1.107 --baseURL http://192.168.1.107/\nLinks hugo主题文档 https://www.cnblogs.com/brady-wang/p/13830156.html\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"53101f60ef55f0ca67350a7a83a0f14a","permalink":"https://dante-su.github.io/notes/others/hugo/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/hugo/","section":"notes","summary":"Notes\n","tags":["hugo","html"],"title":"hugo","type":"book"},{"authors":null,"categories":null,"content":"Related papers of Computer Graphics\n3DV Detailed Human Avatars from Monocular Video From: 3DV\u0026#39;2018\npaper | code\nWACV SMPLpix: Neural Avatars from 3D Human Models From: WACV\u0026#39;2021\nhomepage | paper | code\nICCV Tex2shape From: ICCV\u0026#39;2019\nhomepage | paper | code\nBackground Generate 3D human body model with details of garment from an RGB image(without depth information)\nMotivation Regression from image pixels directly to 3D mesh displacements is not so good:\nIgnoring the rich illumination and shading information contained in RGB values inputs and outputs are not aligned Novelity propose to regress shape as UV-space displacement and normal map turn a hard full-body shape reconstruction problem into an easier 3D pose-independent image-to-image translation problem Cons the photo must taken from the front pose is strictly to A pose Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis From: ICCV\u0026#39;2019\nhomepage | paper | code | dataset\nThe Power of Points for Modeling Humans in Clothing From: ICCV\u0026#39;2021\nhomepage | paper | code | dataset\nECCV Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image From: ECCV\u0026#39;2016\npaper or paper | code\nBodynet: Volumetric inference of 3D human bodyshapes From: ECCV\u0026#39;2018\nhomepage | paper | code\nCVPR Video Based Reconstruction of 3D People Models From: CVPR\u0026#39;2018\nhomepage | paper | code | dataset\nLearning to reconstruct people in clothing from a single RGB camera From: CVPR\u0026#39;2019\npaper | code\nIntro Max Planck Institute for Informatics, Germany\nOctopus, a learning-based model to infer the personalized 3D shape of people from a few frames (1-8) of a monocular video in which the person is moving with a reconstruction accuracy of 4 to 5mm\nHuman Representation While D here is free-form deformations\nDataset 163 scans from renderpeople.com 54 from axyzdesign.com 1826 scans from Twindom generate synthetic 3D data by non-rigidly registering SMPL+D to each of the scans Method Function4D: Real-time Human Volumetric Capture from Very Sparse Consumer RGBD Sensors From: CVPR\u0026#39;2021\nhomepage | paper | dataset\nHigh-Fidelity Human Avatars from a Single RGB Camera From: CVPR\u0026#39;2022\nhomepage | paper | code | dataset\nIntro A coarse-to-fine framework to reconstruct a personalized high-fidelity human avatar from a monocular video\nA single RGB camera A single video 300 frames A single person Rotate with A-pose relieve the misalignment caused by changed pose and shape in different frames Methods SIGGRAPH PoseVocab: Learning Joint-structured Pose Embeddings for Human Avatar Modeling From: SOGGRAPH\u0026#39;2023 (Conference Track)\nhomepage | paper | code\nICML GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models From: ICML\u0026#39;2022\nhomepage | paper | code\n","date":1702857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702857600,"objectID":"9b15843b5bbe26fbb6728e8dd9c01068","permalink":"https://dante-su.github.io/notes/computer_graphics/papers/","publishdate":"2023-12-18T00:00:00Z","relpermalink":"/notes/computer_graphics/papers/","section":"notes","summary":"Related papers of Computer Graphics\n","tags":["Computer Graphics"],"title":"Related papers","type":"book"},{"authors":null,"categories":null,"content":"Intro of Jupyter notebook\nInstallation pip install jupyter notebook\nWay to use Jupyter notebook from remote server on local device On server conda activate your_env_name\npip install jupyter notebook\njupyter notebook --generate-config\nipython\nfrom notebook.auth import passwd\npasswd()\nThen input the password you like and verify it by secondary input. After that, it will generate a hash file named ‘jupyter_notebook_config.json’. Open it and copy the hash code to your clipboard.\nnano ~/.jupyter/jupyter_notebook_config.py\n(If ’nano’ does NOT exist, use ‘vim’ instead)\nAdd the following codes to the end of just opened ‘jupyter_notebook_config.py’ and be aware to substitute the ‘password’ with your generated one in your clipboard.\nc.NotebookApp.ip = \u0026#39;*\u0026#39; # 允许访问此服务器的 IP，星号表示任意 IP c.NotebookApp.password = \u0026#39;argon2:$argon2id$v=19$m=10240,t=10,p=8$QplvWXtYUtp4TlXS1T1urQ$xulqNxrIqlJmCPrBHd7nGA\u0026#39; # 之前生成的密码 hash 字串, 粘贴进去 c.NotebookApp.open_browser = False # 运行时不打开本机浏览器 c.NotebookApp.port = 8890 # 使用的端口，随意设置，但是要记得你设定的这个端口 c.NotebookApp.enable_mathjax = True # 启用 MathJax c.NotebookApp.allow_remote_access = True #允许远程访问 c.NotebookApp.allow_root = True After above all done, remember the port you set, input the below command to terminal and run. (It could also run in a window generating by ‘screen’ command)\njupyter notebook\nOn local device ssh -L \u0026lt;local_port\u0026gt;:localhost:\u0026lt;remote_port\u0026gt; user_name@server_ip -p server_port\n(\u0026lt;local_port\u0026gt; and \u0026lt;remote_port\u0026gt; could be set as you wish, e.g. 8890 as a default choice)\njupyter notebook\nThen open the browser and open localhost:\u0026lt;local_port\u0026gt;, e.g. localhost:8890. Input the password you set and you could use jupyter notebook from remote server on your local device.\n","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"6abed0fb078999af7823f5285130e2c6","permalink":"https://dante-su.github.io/notes/python/jupyter/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/python/jupyter/","section":"notes","summary":"Intro of Jupyter notebook\nInstallation pip install jupyter notebook\nWay to use Jupyter notebook from remote server on local device On server conda activate your_env_name\npip install jupyter notebook\njupyter notebook --generate-config","tags":["Python","jupyter"],"title":"Jupyter","type":"book"},{"authors":null,"categories":null,"content":"Notes\nJekyll Links HTML、JS与PHP之间的数据传输 https://juejin.cn/post/6844903684195762184\nhtml页面的数据利用js或者Ajax传输到后台java、php https://blog.csdn.net/tangsl388/article/details/49174083\n如何用Html，在图片上放按钮 https://zhidao.baidu.com/question/1758081969339588748.html\nFEX https://fex-team.github.io/\nThe Minimal Light Theme of Jekyll https://github.com/yaoyao-liu/minimal-light\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"f2aef9a0ec7751f486919c2346d3ec4a","permalink":"https://dante-su.github.io/notes/others/html/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/html/","section":"notes","summary":"Notes\n","tags":["html"],"title":"HTML","type":"book"},{"authors":null,"categories":null,"content":"Proceedings of ACM SIGGRAPH（Asia）/ ACM Transactions on Graphics\n2023","date":1711324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711324800,"objectID":"f78c8ca89e2aae72386295f0836de637","permalink":"https://dante-su.github.io/notes/paper_reading/siggraph/","publishdate":"2024-03-25T00:00:00Z","relpermalink":"/notes/paper_reading/siggraph/","section":"notes","summary":"Proceedings of ACM SIGGRAPH（Asia）/ ACM Transactions on Graphics\n","tags":["siggraph","paper"],"title":"SIGGRAPH","type":"book"},{"authors":null,"categories":null,"content":"Useful links of Computer Graphics\nInfo Related Links SIGGRAPH 2021 https://www.neuralrender.com\n神经渲染进展 SIGGRAPH 2021 Course https://www.bilibili.com/video/BV1dA4y1Q7Wf?spm_id_from=333.337.search-card.all.click\nInstant Neural Graphics Primitives https://github.com/NVlabs/instant-ngp\n物理仿真中的符号距离场（SDF） https://zhuanlan.zhihu.com/p/390625164\n【译】Signed Distance Fields(有符号的距离场) https://zhuanlan.zhihu.com/p/357606643\n视网膜Retina技术 https://www.cnblogs.com/constantince/p/15475408.html\n三维重建：基于RGB-D相机的三维重建总览(静态\u0026amp;动态) https://yongqi.blog.csdn.net/article/details/124893084?spm=1001.2101.3001.6650.14\u0026amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-14-124893084-blog-122227671.pc_relevant_antiscanv3\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-14-124893084-blog-122227671.pc_relevant_antiscanv3\n基于SfM(Structure from motion)的三维重建详解 https://zhuanlan.zhihu.com/p/29845703\nTaoYU Function4D http://www.liuyebin.com/Function4D/Function4D.html\n基于slam的三维重建_基于图像的三维模型重建——基础介绍 https://blog.csdn.net/weixin_32236415/article/details/112173089\nSLAM和三维重建有什么区别？ https://www.zhihu.com/question/64011093\nSLAM系列(一)：入门介绍 https://www.jianshu.com/p/a9579f469f84\nRigNet神经网络模型自动绑定骨骼 https://blog.csdn.net/u012863565/article/details/121585109\n操纵加鲁鲁兽的机会：SIGGRAPH论文提出RigNet帮动画师做骨架绑定 https://baijiahao.baidu.com/s?id=1666380413991389665\u0026amp;wfr=spider\u0026amp;for=pc\nCode for neuralbody https://github.com/zju3dv/neuralbody\nCode for humannerf https://github.com/chungyiweng/humannerf\nCode for easymocap https://github.com/zju3dv/EasyMocap\n啥是KinectFusion https://zhuanlan.zhihu.com/p/39021659\n啥是DynamicFusion https://zhuanlan.zhihu.com/p/39252239\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"b30f039c94c36498936fd1ecf4d9c23a","permalink":"https://dante-su.github.io/notes/computer_graphics/useful_links/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/computer_graphics/useful_links/","section":"notes","summary":"Useful links of Computer Graphics\n","tags":["links"],"title":"Useful links","type":"book"},{"authors":null,"categories":null,"content":"Installation method and usage of WSL on Windows\nTable of Contents Installation Usage See the installed Linux distribution See the available versions to install Install multipie Linux distribution Import the distribution Export the distribution Remove the distribution Change default Linux distribution Shut down all the distributions Shut down specific distribution Update wsl Check the status of wsl Check the version of wsl Check IP address Open help menu Start up from /home/user Exit the running wsl Open VS Code via WSL Adjust wsl version Mount the disk Unmount the disk Map USB device from Windows to Linux Installation on windows Installation on Liunx Usage Install multipie wsl distributions Install cuda in wsl Installation Mircosoft official document\nwsl --install\nUsage See the installed Linux distribution wsl --list --verbose or wsl -l -v\nSee the available versions to install wsl --list --online or wsl -l -v\nInstall multipie Linux distribution wsl --install -d \u0026lt;distribution_name\u0026gt;\nImport the distribution wsl --import \u0026lt;distribution_name\u0026gt; \u0026lt;install_location\u0026gt; \u0026lt;file_name\u0026gt;\nExport the distribution wsl --export \u0026lt;distribution_name\u0026gt; \u0026lt;file_name\u0026gt;\nRemove the distribution wsl --unregister \u0026lt;distribution_name\u0026gt;\nChange default Linux distribution wsl --set-default \u0026lt;distribution_name\u0026gt;\nShut down all the distributions wsl --shutdown\nShut down specific distribution wsl --terminate \u0026lt;distribution_name\u0026gt;\nUpdate wsl wsl --update\nCheck the status of wsl wsl --status\nCheck the version of wsl wsl --version\nCheck IP address The address of Linux\nwsl hostname -i\nThe address of Windows\ncat /etc/resolv.conf\nOpen help menu wsl --help\nStart up from /home/user wsl ~\nExit the running wsl Press Ctrl+A+D at the same time\nOpen VS Code via WSL code .\nAdjust wsl version wsl --set-version \u0026lt;distribution_name\u0026gt; \u0026lt;version_number\u0026gt;\n\u0026lt;version_number\u0026gt; here is 1 or 2\nMount the disk wsl --mount \u0026lt;disk_path\u0026gt;\nUnmount the disk wsl --unmount \u0026lt;disk_path\u0026gt;\nMap USB device from Windows to Linux Mircosoft Document\nCSDN link\nInstallation on windows Open usbipd-win and download the up-to-date released .msi file Install the downloaded file Installation on Liunx sudo apt install linux-tools-generic hwdata\nsudo update-alternatives --install /usr/local/bin/usbip usbip /usr/lib/linux-tools/*-generic/usbip 20\nUsage Open PowerShell and type in usbipd wsl list to check all the connected USB device Find the busid of needed device and type usbipd wsl attach --busid \u0026lt;busid\u0026gt; in PowerShell Open WSL and type in lsusb to check if the need device has connected to the wsl or not When we need to disconnect the needed device from wsl, type usbipd wsl detach --busid \u0026lt;busid\u0026gt; Install multipie wsl distributions Install wsl2 with wsl --install Open ubuntu wsl2 images and download an image of needed version Open PowerShell and type in wsl --import \u0026lt;Distribution Name\u0026gt; \u0026lt;Installation Folder\u0026gt; \u0026lt;Ubuntu WSL2 Image Tarball path\u0026gt; Type wsl -l -v to check if the installation is successful or not Use wsl -d \u0026lt;distribution_name\u0026gt; to login the distribution we just installed Type in NEW_USER=\u0026lt;USERNAME\u0026gt; to create a new account Input useradd -m -G sudo -s /bin/bash \u0026#34;$NEW_USER\u0026#34; + passwd \u0026#34;$NEW_USER\u0026#34; and set a password for our new account Input the code below to set our new user as the default one tee /etc/wsl.conf \u0026lt;\u0026lt;_EOF [user] default=${NEW_USER} _EOF Press Ctrl + A + D at the same time to exit the distribution Input wsl --terminate \u0026lt;distribution_name and wsl -d \u0026lt;distribution_name\u0026gt; to restart the installed distribution And find that we succeed in creating a new distribution Install cuda in wsl NVIDIA Documents\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.2.2/local_installers/cuda-repo-wsl-ubuntu-12-2-local_12.2.2-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-2-local_12.2.2-1_amd64.deb\nsudo cp /var/cuda-repo-wsl-ubuntu-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/\nsudo apt-get update\nsudo apt-get -y install cuda\nsudo ln -s /usr/lib/wsl/lib/libcuda.so.1 /usr/local/cuda/lib64/libcuda.so\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"b88825683d8fe137cf717a115aa8509f","permalink":"https://dante-su.github.io/notes/shell/wsl/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/shell/wsl/","section":"notes","summary":"Installation method and usage of WSL on Windows\n","tags":["Windows","wsl"],"title":"WSL","type":"book"},{"authors":null,"categories":null,"content":"Usage and debug experience of ‘Git’\nTable of Contents Installation Usage Clone push pull .gitignore Installation Usage Clone git clone \u0026lt;repo_address\u0026gt;\npush cd path/to/repo\ngit add .\ngit commit -m \u0026#39;\u0026lt;update_info\u0026gt;\u0026#39;\ngit push\npull cd path/to/repo\ngit push\n.gitignore cd path/to/repo touch .gitignore git rm --cached \u0026lt;file_name\u0026gt; # For those already in repo Example:\nFor repo used on Mac system, there is always a srange file called .DS_Store added. So we could add the lines below to .gitignore file to avoid this.\n.DS_Store **/.DS_Store .DS_Store? ","date":1714089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714089600,"objectID":"2d957f04dd33744c01494659f3949d35","permalink":"https://dante-su.github.io/notes/shell/git/","publishdate":"2024-04-26T00:00:00Z","relpermalink":"/notes/shell/git/","section":"notes","summary":"Usage and debug experience of ‘Git’\n","tags":["git"],"title":"Git","type":"book"},{"authors":null,"categories":null,"content":"Numpy in Python\nInstallation conda install numpy\npip install numpy\nUsage np.array import numpy as np a = np.array([[1,2,3],[4,5,6]]) cumsum # Obtain the cumulative sum value of whole array print(a.cumsum()) # [ 1 3 6 10 15 21] # Obtain the cumulative sum value along given axis print(a.cumsum(axis=0)) # [[1 2 3] [5 7 9]] print(a.cumsum(axis=1)) # [[ 1 3 6] [ 4 9 15]] max/min # Obatin the max/min item print(a.max()) # 6 print(a.min()) # 1 # Obtain the max/min row along given axis print(a.max(axis=0)) # [4 5 6] print(a.max(axis=1)) # [3 6] # Localize the max item print(a.argmax(axis=1)) # [2 2] mean # Obtain the mean value of whole array print(a.mean()) 3.5 # Obtain the mean value along given axis print(a.mean(axis=0)) # [ 2.5 3.5 4.5] print(a.mean(axis=1)) # [ 2. 5.] median # Obtain the median value of whole array print(np.median(x)) # 3.5 # Obtain the median value along given axis print(np.median(x,axis=0)) # [ 2.5 3.5 4.5] print(np.median(x,axis=1)) # [ 2. 5.] std std() is equal to sqrt(mean(abs(x - x.mean())**2)) or sqrt(x.var())\n# Obtain the standard deviation value of whole array print(a.std()) # 1.70782512766 # Obtain the standard deviation value along given axis print(a.std(axis=0)) # [ 1.5 1.5 1.5] print(a.std(axis=1)) # [ 0.81649658 0.81649658] sum # Obtain the sum value of whole array print(a.sum()) # 21 # Obtain the sum value along given axis print(a.sum(axis=0)) # [5 7 9] print(a.sum(axis=1)) # [ 6 15] var # Obtain the variance value of whole array print(a.var()) # 2.91666666667 # Obtain the variance value along given axis print(a.var(axis=0)) # [ 2.25 2.25 2.25] print(a.var(axis=1)) # [ 0.66666667 0.66666667] np.append import numpy as np # for a list [] a = [] a.append([1,2,3]) # for a np.ndarray b = np.asarray([]) b = np.append(b, [1,2,3], axis=0) np.asarray import numpy as np a = list() b = np.asarray(a) # type(b) = np.ndarray np.max import numpy as np a = np.arange(9).reshape(3,-1) b = np.max(a, axis=0) c = np.max(a, axis=1) print(a,\u0026#39;\\n\u0026#39;,b,\u0026#39;\\n\u0026#39;,c) np.power(x1, x2) x1 = range(6) print(x1) # [0, 1, 2, 3, 4, 5] print(np.power(x1, 3)) # array([ 0, 1, 8, 27, 64, 125]) x2 = [1.0, 2.0, 3.0, 3.0, 2.0, 1.0] print(np.power(x1, x2)) # array([ 0., 1., 8., 27., 16., 5.]) x2 = np.array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) print(x2) # array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) print(np.power(x1, x2)) # array([[ 0, 1, 8, 27, 16, 5], [ 0, 1, 8, 27, 16, 5]]) np.set_printoptions import numpy as np np.set_printoptions(threshold=np.inf) np.shape import numpy as np a = np.array([[1,1,3],[4,5,6]]) print(\u0026#39;a.shape = \u0026#39;, a. shape) np.sum np.sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue)\nimport numpy as np a = np.random.randint(-5, 5, (1, 10)) print (str(a)) # [[ 2 -3 -5 -4 3 -5 0 -1 4 3]] c=np.sum(a) # Obtain the sum of all items in an array print (str(c)) # -6 c=np.sum(a\u0026gt;=1) # Obtain the number of qualified items in an array print (str(c)) # 4 np.where import numpy as np a = np.arange(9).reshape(3,-1) b = np.where(a ==7) print(b) Others Matrix multiplication import numpy as np a = np.array([[1,2], [3,4]]) b = np.array([[5,6], [7,8]]) print(a*b) # array([[ 5, 12], [21, 32]]) print(a.dot(b)) # array([[19, 22], [43, 50]]) print(np.dot(a,b)) # array([[19, 22], [43, 50]]) print(np.dot(b,a)) # array([[23, 34], [31, 46]]) ","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"6a2c139ebf1fbf73d19a3607e9e355c6","permalink":"https://dante-su.github.io/notes/python/numpy/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/python/numpy/","section":"notes","summary":"Numpy in Python\nInstallation conda install numpy\npip install numpy\nUsage np.array import numpy as np a = np.array([[1,2,3],[4,5,6]]) cumsum # Obtain the cumulative sum value of whole array print(a.cumsum()) # [ 1 3 6 10 15 21] # Obtain the cumulative sum value along given axis print(a.","tags":["Python","Numpy"],"title":"Numpy","type":"book"},{"authors":null,"categories":null,"content":"Notes\nPython Move multipie lines right/left Left Select the needed content and press Tab\nRight Select the needed content and press Shift and Tab at the same time\nColab https://colab.research.google.com/github/iErics/gd-utils/blob/master/Colab_gd_utils.ipynb\nfunction ConnectButton(){ console.log(\u0026#34;Connect pushed\u0026#34;); document.querySelector(\u0026#34;#connect\u0026#34;).click() } setInterval(ConnectButton,60000); Use visdom over remote server This note is for those who need run their codes on remote server but finding that they could NOT be able to get access to visdom’s monitor as before. So we need to mapping the service of visdom to our local workspace over the remote server.\nSteps:\nOpen the remote server and type tmux new -s \u0026lt;session-name\u0026gt; to open a new backstage process (screen could does this too) Activate the specific conda env you are using (if your code runs on conda env) and type python -m visdom.server to open a local visdom server Open the terminal of local device and type ssh -L 8097:127.0.0.1:8097 \u0026lt;username\u0026gt;@\u0026lt;server_address\u0026gt; or ssh -L 8097:localhost:8097 \u0026lt;username\u0026gt;@\u0026lt;server_address\u0026gt; while 8097 is as an example of port id. When you successfully get access to your remote server, open the page 127.0.0.1:8097 or localhost:8097 When you want to terminate the visdom’s mapping, just kill the process of visdom on the remote server, e.g. tmux kill-session -t \u0026lt;session-name\u0026gt;\nWindows Set clock into UTC mode Make Windows 10’s BIOS hardware time treat Coordinated Universal Time (UTC) by changing the registry value RealTimeIsUniversal key\nWith Regedit Press Win + R at the same time Input regedit and press Enter Find the path \\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation Set RealTimeIsUniversal to 1 if this value already exists. New a QWORD(for system of 32-bit, use DWORD instead) variable with a name of RealTimeIsUniversal and whose value could also be set as 1 With PowerShell Open terminal with Administrator rights Input reg add \u0026#34;HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TimeZoneInformation\u0026#34; /v RealTimeIsUniversal /d 1 /t REG_QWORD /f (for system of 32-bit, use DWORD instead) Press Enter Using multi-moniter to view same project in VS Code Ctrl + Shift + P and input the content below:\nWorkspace: Duplicate As Workspace in New Window\nThe installation of Windows11 is stuck by connecting to network Press Shift+F10 to open a terminal. Input oobe\\bypassnro The computer will restart soon and there will be an option for ‘I haven’t Interest to connect’\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"403ac75c41d2810d1ba3d680df5a18e2","permalink":"https://dante-su.github.io/notes/others/messy/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/messy/","section":"notes","summary":"Notes\n","tags":["windows","python"],"title":"Messy","type":"book"},{"authors":null,"categories":null,"content":"The Annual Conference on Neural Information Processing System\n2023","date":1711324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711324800,"objectID":"d437909b880e8981c20dc12ebef08aa7","permalink":"https://dante-su.github.io/notes/paper_reading/neurips/","publishdate":"2024-03-25T00:00:00Z","relpermalink":"/notes/paper_reading/neurips/","section":"notes","summary":"The Annual Conference on Neural Information Processing System\n","tags":["neurips","paper"],"title":"NeurIPS","type":"book"},{"authors":null,"categories":null,"content":"OS package in Python\nos.access() import os if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.F_OK): print \u0026#34;Given file path is exist.\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.R_OK): print \u0026#34;File is accessible to read\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.W_OK): print \u0026#34;File is accessible to write\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.X_OK): print \u0026#34;File is accessible to execute\u0026#34; os.listdir import os path = \u0026#39;/home/dante/file\u0026#39; file_list = os.listdir(path) # list print(file_list) os.path.exists() For folder\nimport os os.path.exists(test_dir) #True os.path.exists(no_exist_dir) #False For file\nimport os os.path.exists(test_file.txt) #True os.path.exists(no_exist_file.txt) #False os.path.isfile() To check a file exists or not when there is a folder with the same name.\nimport os os.path.isfile(\u0026#34;test-data\u0026#34;) os.path.join import os path = \u0026#39;/home/dante\u0026#39; file_name = \u0026#39;example.txt\u0026#39; file_path = os.path.join(path, file_name) print(file_path) os.makedirs import os folder_name = \u0026#39;home/dante/example\u0026#39; os.makedirs(folder_name, mode=511, exist_ok=True) os.rename import os old_name = \u0026#39;/home/dante/old_file.txt\u0026#39; new_name = \u0026#39;/home/dante/new_file.txt\u0026#39; os.rename(old_name, new_name) %06d \u0026#34;/{}\u0026#34;.format(\u0026#39;%06d\u0026#39; % (i)) or\n\u0026#34;/{0:06d}\u0026#34;.format(i) ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"8941e8a6379900a9cbacebb42d1275fa","permalink":"https://dante-su.github.io/notes/python/os/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/python/os/","section":"notes","summary":"OS package in Python\nos.access() import os if os.access(\"/file/path/foo.txt\", os.F_OK): print \"Given file path is exist.\" if os.access(\"/file/path/foo.txt\", os.R_OK): print \"File is accessible to read\" if os.access(\"/file/path/foo.txt\", os.W_OK): print \"File is accessible to write\" if os.","tags":["Python","OS"],"title":"OS","type":"book"},{"authors":null,"categories":null,"content":"ArXiv\n2023","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711497600,"objectID":"cdbed13a7e46ef3f80f2a42a500bec8a","permalink":"https://dante-su.github.io/notes/paper_reading/arxiv/","publishdate":"2024-03-27T00:00:00Z","relpermalink":"/notes/paper_reading/arxiv/","section":"notes","summary":"ArXiv\n","tags":["arxiv","paper"],"title":"ArXiv","type":"book"},{"authors":null,"categories":null,"content":"Other Conference/Journal\nACM MM Proceedings of the ACM International Conference on Multimedia\n2023 MICCAI International Conference in Medical Image Computing and Computer-Assisted Intervention\n2022 Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery [ homepage | paper | code ]\nKeywords: 3D Reconstruction, Neural Rendering, Robotic Surgery\nAim:\nContribution:\nMotivation:\nArchitecture:\nComparison models: Cetin et al.@STACOM\u0026#39;17,\nFront. Inf. Technol. Electron. Eng. Frontiers of Information Technology \u0026amp; Electronic Engineering\n2022 Visual recognition of cardiac pathology based on 3D parametric model reconstruction [ homepage | paper ]\nKeywords: Cardiac, 3D parametric model, Cardiac pathology diagnosis\nAim: Construct and use 3D parametric model as an augmentation to generate heart data for better training a classifier of cardiac pathology.\nContribution:\nConstruct 3D cardiac parametric model for each pathology and apply cardiac visual knowledge of different cardiac pathologies as parameters to generate reasonable 3D cardiac model. Sample 3D cardiac data with changing parameters of 3D cardiac parametric model as an augmentation to avoid class imbalance. Exract cardiac disease-based features and use it to make prediction. Motivation: Almost all the existing method use 2D slices of heart to extract features and make prediction. However, these 2D slices are collected from 3D imaging data, so using 2D slices may largely ignore geometric information characterizing adjacency in the 3D neighbourhood. Besides, after constructing 3D cardiac parametric model, generating reasonable cardiac data by changing the parameters of 3D cardiac model is a good way as data augmentation.\nArchitecture:\nFirst, they reconstruct 3D model from labeled 2D images, based on which they employ Statistical Shape Model(SSM) to obtain 3D cardiac parametric model. Then, after using PCA to determine the bases of the category, they use parameter variation to make prediction. Besides above, they could also random sample the parameters to generate reasonable cardiac data as an augmentation to train a better model for cardiac pathology’s classification.\nComparison models: Cetin et al.@STACOM\u0026#39;17, Isensee et al.@STACOM\u0026#39;17, Khened et al.@STACOM\u0026#39;17, Wolterink@STACOM‘17, Zheng et al.@MedIA\u0026#39;19, Chang and Jun@NeuroComputing\u0026#39;20, Ammar et al.@Comput Med Imag Graph\u0026#39;21, Thermos@MICCAI\u0026#39;21\n","date":1714003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714003200,"objectID":"c26045854aa18f4bcb0b768f540bf1eb","permalink":"https://dante-su.github.io/notes/paper_reading/others/","publishdate":"2024-04-25T00:00:00Z","relpermalink":"/notes/paper_reading/others/","section":"notes","summary":"Other Conference/Journal\n","tags":["paper"],"title":"Others","type":"book"},{"authors":null,"categories":null,"content":"Other useful package.\nassert a = 1 assert a = 2 # AssertionError: assert a = 2, \u0026#39;a is not equal to 2\u0026#39; # AssertionError: a is not equal to 2 cv2 pip install opencv-python\nhasattr() Check whether a property is in the given class or not\nUsage hasattr(object, name)\nExample #!/usr/bin/python # -*- coding: UTF-8 -*- class Coordinate: x = 10 y = -5 z = 0 point1 = Coordinate() print(hasattr(point1, \u0026#39;x\u0026#39;)) # True print(hasattr(point1, \u0026#39;y\u0026#39;)) # True print(hasattr(point1, \u0026#39;z\u0026#39;)) # True print(hasattr(point1, \u0026#39;no\u0026#39;)) # 没有该属性 False icrawler https://pypi.org/project/icrawler/0.2.2/\nio StringIO Example\nfrom io import StringIO f=StringIO() #创建变量指向对象 f.write(\u0026#39;hello,\u0026#39;) #写入数据 f.write(\u0026#39; \u0026#39;) f.write(\u0026#39;world.\u0026#39;) print(f.getvalue()) #依次打印获得的数据 from io import StringIO #载入模块 f=StringIO(\u0026#39;hello\\nworld\u0026#39;) #初始化String while True: #创造循环条件 s=f.readline() #对f指向的对象记性逐行读取 if s==\u0026#39;\u0026#39;: #指定退出循环条件，即读取的行数为空 break #退出循环 print(s.strip()) #strip()方法用于移除字符串头尾指定的字符（默认为空格）。 BytesIO Example\nfrom io import BytesIO f=BytesIO() f.write(\u0026#39;中文\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) print(f.getvalue()) \u0026gt;\u0026gt;\u0026gt; b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39; isinstance 类似type\n区分：\ntype() 不会认为子类是一种父类类型，不考虑继承关系。\nisinstance() 会认为子类是一种父类类型，考虑继承关系。\nmath math.gamma Usage:\n$ math.gamma(n) = (n-1)! $\nmath.sqrt math.sqrt() pandas import pandas as pd dates = pd.date_range(\u0026#39;20130101\u0026#39;, periods=6) df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\u0026#39;ABCD\u0026#39;)) print(df.dtypes) print(df.head()) print(df.tail(3)) print(df.index) print(df.columns) print(df.to_numpy()) print(df.describe()) print(df.T) print(df.sort_index(axis=1, ascending=False)) print(df.sort_values(by=\u0026#39;B\u0026#39;)) print(df[\u0026#39;A\u0026#39;]) print(df[0:3]) print(df.loc[dates[0]]) print(df.loc[:,[\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;]]) print(df.loc[\u0026#39;20130102\u0026#39;:\u0026#39;20130104\u0026#39;,[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;]]) print(df.loc[\u0026#39;20130103\u0026#39;,[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;]]) print(df.loc[dates[0],\u0026#39;A\u0026#39;]) print(df.at[dates[0],\u0026#39;A\u0026#39;]) print(df.iloc[3]) print(df.iloc[3:5,0:2]) print(df.iloc[[1,2,4],[0,2]]) print(df.iloc[3:5,:]) print(df.iloc[3,2]) print(df.iat[3,2]) print(df[df.A \u0026gt; 0]) print(df[df \u0026gt; 0]) df2 = df.copy() df2[\u0026#39;E\u0026#39;] = [\u0026#39;one\u0026#39;,\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;,\u0026#39;three\u0026#39;,\u0026#39;four\u0026#39;,\u0026#39;three\u0026#39;] print(df2[df2[\u0026#39;E\u0026#39;].isin([\u0026#39;two\u0026#39;, \u0026#39;four\u0026#39;])]) s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(\u0026#39;20130102\u0026#39;, periods=6)) df[\u0026#39;F\u0026#39;] = s1 df.at[dates[0], \u0026#39;A\u0026#39;] = 0 df.iat[0, 1] = 0 df.loc[:, \u0026#39;D\u0026#39;] = np.array([5] * len(df)) df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [\u0026#39;E\u0026#39;]) df1.loc[dates[0]:dates[1], \u0026#39;E\u0026#39;] = 1 print(df1) print(df1.dropna(how=\u0026#39;any\u0026#39;)) print(df1.fillna(value=5)) print(pd.isna(df1)) print(df.mean()) print(df.mean(1)) print(df.apply(np.cumsum)) print(df.apply(lambda x: x.max() - x.min())) print(pd.concat([df[:3], df[3,7], df[7:]])) pathlib import pathlib path = pathlib.Path(\u0026#34;path/file\u0026#34;) path.exist() # True/False path = pathlib.Path(\u0026#34;path/file\u0026#34;) path.is_file() round() Usage round( x [, n] )\nx – 数值表达式。\nn – 数值表达式，表示从小数点位数。\n返回浮点数x的四舍五入值\nSkLearn with conda\nconda install scikit-learn\nwith pip\npip3 install scikit-learn\nString operation Delete space in a string s = \u0026#39; a b c \u0026#39; s = s.lstrip() print(s) # This function wil delete the space in the left # Output: \u0026#39;a b c \u0026#39; s = \u0026#39; a b c \u0026#39; s = s.rstrip() print(s) # This function wil delete the space in the right # Output: \u0026#39; a b c\u0026#39; s = \u0026#39; a b c \u0026#39; s = s.strip() print(s) # This function wil delete the space in both left and right # Output: \u0026#39;a b c\u0026#39; s = \u0026#39; a b c \u0026#39; s = s.replace(\u0026#39; \u0026#39;,\u0026#39;\u0026#39;) print(s) # This function wil delete all the space in the string # Output: \u0026#39;abc\u0026#39; s = \u0026#39; a b c \u0026#39; s = \u0026#39;\u0026#39;.join(s.split()) print(s) # This method wil delete the space in the left # Output: \u0026#39;abc\u0026#39; tqdm conda install tqdm\npip install tqdm\nExample from time import sleep from tqdm import tqdm for i in tqdm(range(100)): sleep(0.1) try try: f =open() f.close() except FileNotFoundError: print \u0026#34;File is not found.\u0026#34; except PersmissionError: print \u0026#34;You don\u0026#39;t have permission to access this file.\u0026#34; or\ntry: f =open() f.close() except IOError: print \u0026#34;File is not accessible.\u0026#34; yield #!/usr/bin/python # -*- coding: UTF-8 -*- def fab(max): n, a, b = 0, 0, 1 while n \u0026lt; max: yield b # 使用 yield # print b a, b = b, a + b n = n + 1 for n in fab(5): print n Above code is equal to the below one.\n#!/usr/bin/python # -*- coding: UTF-8 -*- class Fab(object): def __init__(self, max): self.max = max self.n, self.a, self.b = 0, 0, 1 def __iter__(self): return self def next(self): if self.n \u0026lt; self.max: r = self.b self.a, self.b = self.b, self.a + self.b self.n = self.n + 1 return r raise StopIteration() for n in Fab(5): print n f.next() For generator with function ‘yield’, e.g. Fab() coule be used with f = fab(5), f.next()\nJudge a function is a generator or not from inspect import isgeneratorfunction isgeneratorfunction(fab) True import types isinstance(fab, types.GeneratorType) False isinstance(fab(5), types.GeneratorType) True from collections import Iterable isinstance(fab, Iterable) False isinstance(fab(5), Iterable) True ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"6158e3d0209c3389ec52b09c9256c213","permalink":"https://dante-su.github.io/notes/python/others/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/python/others/","section":"notes","summary":"Other useful package.\n","tags":[null],"title":"Others","type":"book"},{"authors":null,"categories":null,"content":"In the field of mathematics, we always need to use proper, suitable and standard written format to express our solution for the given mathematical question. The below are some frequently used written mathematical manners and formats.\nCited from https://www.zhihu.com/question/21793184\nLists of usually-used words 中文 English 解 SOLUTIONsol 证明 PROOFpf 因为 Since 所以 So 即 i.e.id est(Latin) 由此得知 Consequently/Therefore/Thus/Hence 使…满足 s.t.subject to/such that 假设 Suppose 当且仅当 iffIf and only if 令/设 Let 同理 Similarly 此外 Morever 且 And 这表明… This implies that… 综上所述 Summarizing 得出…的结论 We conclude that… 证毕证明完毕 Q.E.D.quod erat demonstrandum(Latin) Example from the book Calculus written by Prof. Michael Spivak ","date":1714089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714089600,"objectID":"4ec91ee1e38108f9beb410d79fae1a77","permalink":"https://dante-su.github.io/post/24-04-26-standard-math-format/","publishdate":"2024-04-26T00:00:00Z","relpermalink":"/post/24-04-26-standard-math-format/","section":"post","summary":"In the field of mathematics, we always need to use proper, suitable and standard written format to express our solution for the given mathematical question. The below are some frequently used written mathematical manners and formats.\n","tags":null,"title":"Standard written mathematical format","type":"post"},{"authors":null,"categories":null,"content":"In the field of mathematics, norms are defined for elements within a vector space. Specifically, when the vector space comprises matrices, such norms are referred to as matrix norms. Matrix norms differ from vector norms in that they must also interact with matrix multiplication.\nFrobenius norm Defination The Frobenius norm, sometimes also called the Euclidean norm (a term unfortunately also used for the vector $L^2$-norm), is matrix norm of an m×n matrix A defined as the square root of the sum of the absolute squares of its elements.\n$$ \\Vert A \\Vert_{F} = \\sqrt{\\sum_{i=1}^{m}{\\sum_{j=1}^{n}{\\vert a_{i,j} \\vert^{2}}}} $$\nhe Frobenius norm can also be considered as a vector norm.\nIt is also equal to the square root of the matrix trace of $AA^H$, where $A^H$ is the conjugate transpose, i.e.,\n$$ \\Vert A \\Vert_{F}=\\sqrt{Tr(AA^H)} $$\nThe Frobenius norm of a matrix m is implemented as Norm[m, “Frobenius”] and of a vector v as Norm[v, “Frobenius”].\n","date":1713916800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713916800,"objectID":"3288f452d4af04c0bf39eda6a96932c5","permalink":"https://dante-su.github.io/post/24-04-24-norm/","publishdate":"2024-04-24T00:00:00Z","relpermalink":"/post/24-04-24-norm/","section":"post","summary":"In the field of mathematics, norms are defined for elements within a vector space. Specifically, when the vector space comprises matrices, such norms are referred to as matrix norms. Matrix norms differ from vector norms in that they must also interact with matrix multiplication.\n","tags":null,"title":"Norms","type":"post"},{"authors":null,"categories":null,"content":"Fully-connected Layer 对于线性回归，每个输入都与每个输出相连，我们将这种变换成为全连接层（fully-connected layer）或称为稠密层（dense layer）。\nKey points in deeping learning 机器学习模型中的关键要素是训练数据、损失函数、优化算法，还有模型本身。\n简单性 简单性的另一个角度是平滑性，即函数不应该对其输入的微小变化敏感。 例如，当我们对图像进行分类时，我们预计向像素添加一些随机噪声应该是基本无影响的。 1995年，克里斯托弗·毕晓普证明了 具有输入噪声的训练等价于Tikhonov正则化 (Bishop, 1995)。 这项工作用数学证实了“要求函数光滑”和“要求函数对输入的随机噪声具有适应性”之间的联系。\nIndictors PSNR PSNR is short for ‘Peak Signal-to-Noise Ratio’,so the higher PSNR means the noise is less and the total performance is better. It is often used in examining image generation algorithm’s efficiency.\nSSIM SSIM is short for ‘Structural Similarity of Image Measures’, so the higher SSIM means generated image and initial image is more similar in structure and the performance is better. It is often used in examining image generation algorithm’s efficiency.\nLPIPS LPIPS is short for ‘Learned Perceptual Image Patch Similarity’. I some cases, higher LPIPS are suitable for evaluating the diversity of images generated by generative models like GANs, but if we are generating images or comparing images to see how different the original images are from the ones to be compared, lower LPIPS are suitable for that as well.\n","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711497600,"objectID":"636da76d40d4e0ed4dfacdd74689d629","permalink":"https://dante-su.github.io/post/23-12-18-deep-learning/","publishdate":"2024-03-27T00:00:00Z","relpermalink":"/post/23-12-18-deep-learning/","section":"post","summary":"","tags":null,"title":"Deep Learning study notes","type":"post"},{"authors":null,"categories":null,"content":"From ZhiHu\n类似”进程是资源分配的最小单位，线程是CPU调度的最小单位“这样的回答感觉太抽象，都不太容易让人理解。\n做个简单的比喻：进程=火车，线程=车厢\n线程在进程下行进（单纯的车厢无法运行） 一个进程可以包含多个线程（一辆火车可以有多个车厢） 不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘） 同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易） 进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源） 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢） 进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上） 进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－“互斥锁” 进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量” ","date":1695859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695859200,"objectID":"9c81f2630f36f1d5a41c4e3b0f2030f1","permalink":"https://dante-su.github.io/post/23-09-28-processed-and-threads/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/post/23-09-28-processed-and-threads/","section":"post","summary":"From ZhiHu\n","tags":null,"title":"Difference between processes and threads","type":"post"},{"authors":null,"categories":null,"content":"Congratulations to Dante(me) for contributing to construct this website!\nHappy to see a new version of this notes website. This time, I choose wowchemy’s webiste template to renew this notes instead of the old one which is built with the help of gitbook, as gitbook would be no longer updated from 2021, a great pity.\nThis notebook was oringinally set for recording some shell command used in Linux. After the content’s being gathered togehter, I started to think that I need a far more efficient way than search it in my massed\u0026amp;messy documents to consult it once I have something need to know when writing code or debugging. So, I construct this webiste for me and also for you, the potential reader who found this website by accidence.\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"9586085b5bf2fdd98cfb5a51890c124c","permalink":"https://dante-su.github.io/post/23-09-20-construction-this-website/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/post/23-09-20-construction-this-website/","section":"post","summary":"Congratulations to Dante(me) for contributing to construct this website!\n","tags":null,"title":"Congratulations to Dante(me) for contributing to construct this website!","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://dante-su.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]