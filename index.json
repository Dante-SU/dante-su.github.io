
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Nothing here\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dante-su.github.io/author/dante/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dante/","section":"authors","summary":"Nothing here","tags":null,"title":"Dante","type":"authors"},{"authors":null,"categories":null,"content":" Table of Contents Overview CCF recommended ranking TsingHua recommended ranking Lists of code category Overview Here I will record the papers I read and present them with a brief introduction and my notes.\nCCF recommended ranking CCF_2022\nTsingHua recommended ranking TH-CPL_2019\nLists of code category CVPR Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ICCV Proceedings of the IEEE/CVF International Conference on Computer Vision ECCV European Conference on Computer Vision SIGGRAPH Proceedings of ACM SIGGRAPHï¼ˆAsiaï¼‰/ ACM Transactions on Graphics NeurIPS The Annual Conference on Neural Information Processing System ArXiv ArXiv Others Other Conference/Journal ","date":1712534400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1712534400,"objectID":"94d6b94109d4c3e427433f2f18c4c446","permalink":"https://dante-su.github.io/notes/paper_reading/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/paper_reading/","section":"notes","summary":"Recordings of my paper reading","tags":["Papers"],"title":"ğŸ“œ Paper reading","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Lists of code category Overview Just a library for some code instances I collect.\nLists of code category Python Python code instances ","date":1695859200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695859200,"objectID":"f5bfef0e33fe956f35000265aa8c89e9","permalink":"https://dante-su.github.io/notes/code_instance/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/notes/code_instance/","section":"notes","summary":"Some code instance to use and modify","tags":["Code"],"title":"ğŸ§‘â€ğŸ’» Code Instance","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Chapters of notes Chapters of notes Math for Computer Graphics Greg Turk, August 2019 GAMES101 Notes for GAMES101 Related papers Related papers of Computer Graphics Useful links Useful links of Computer Graphics ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"9b137460ed9ef433b8d7825468ede77f","permalink":"https://dante-su.github.io/notes/computer_graphics/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/computer_graphics/","section":"notes","summary":"Notes for Computer Graphics","tags":["CG"],"title":"ğŸ‘¾ Computer Graphics","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Classes of links Overview This part is used to store the useful links to me, including those for work, those for learning and of course those for entertainment.entertainment.\nClasses of links Learning Links for learning Collection My Collection Others Links for dealing with specific situation when debugging. ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"c10b0367f4a064527fe2402ef4c01dce","permalink":"https://dante-su.github.io/notes/links/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/links/","section":"notes","summary":"Some useful links","tags":["Links"],"title":"ğŸ”— Links","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Lists of code category Overview Updating\nLists of code category Markdown Several markdownâ€™s rule and quick command code Gitbook Gitbookâ€™s installation and usage hugo Notes HTML Notes Messy Notes ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"e9b1243ace61ab43dbf401d3dccea7cf","permalink":"https://dante-su.github.io/notes/others/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/others/","section":"notes","summary":"Some messy notes","tags":["Code"],"title":"ğŸ—ï¸ Others","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Chapters here Overview Python is the the greatest program language in this world( I believe ). Infinite python packages make it be broader used than we could image. However, it also brings us a huge trouble that we could hardly be able to use all of them with only one brainâ€™s memory space, include Mr. Guido van Rossum, who has the honor to be the inventor of Python. So here is the way to help us get a better use of those annoying package and messy command. Notes!\nChapters here Anaconda Some shell command when using Anaconda Pip Some pip commands. Pytorch Pytorch documents Jupyter Intro of Jupyter notebook Installation pip install jupyter notebook Way to use Jupyter notebook from remote server on local device On server conda activate your_env_name pip install jupyter notebook jupyter notebook --generate-config\nNumpy Numpy in Python Installation conda install numpy pip install numpy Usage np.array import numpy as np a = np.array([[1,2,3],[4,5,6]]) cumsum # Obtain the cumulative sum value of whole array print(a.cumsum()) # [ 1 3 6 10 15 21] # Obtain the cumulative sum value along given axis print(a.\nOS OS package in Python os.access() import os if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.F_OK): print \u0026#34;Given file path is exist.\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.R_OK): print \u0026#34;File is accessible to read\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.W_OK): print \u0026#34;File is accessible to write\u0026#34; if os.\nOthers Other useful package. ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"6b16c2b0c26f4860e0ec1639413f8300","permalink":"https://dante-su.github.io/notes/python/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/python/","section":"notes","summary":"Python lib","tags":["Python"],"title":"ğŸ Python","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents Overview Notes in this part Overview This part is about the Shell command when using UNIX(Linux/MacOS) or Windows. And there are also some useful tools like Docker, WSL and so on.\nNotes in this part Linux Some shell command when using Anaconda Windows Powershell command in Windows Docker Some documents of docker WSL Installation method and usage of WSL on Windows Git Usage and debug experience of â€˜Gitâ€™ ","date":1695168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1695168000,"objectID":"9666556bf87dc548f717fcbd9706f519","permalink":"https://dante-su.github.io/notes/shell/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/shell/","section":"notes","summary":"Shell command's usual usage(include Anaconda)","tags":["Shell"],"title":"ğŸ¹ Shell","type":"book"},{"authors":null,"categories":null,"content":"Links for learning\nDocs è®¡ç®—æœºå›¾å½¢å­¦ä¸æ··åˆç°å®åœ¨çº¿å¹³å° https://games-cn.org/\nFoundational courses of Machine Learning @Google https://developers.google.com/machine-learning/foundational-courses\næ·±å…¥æµ…å‡ºPyTorch https://datawhalechina.github.io/thorough-pytorch/index.html\nPandas Document https://www.pypandas.cn/docs/getting_started/\nBaidu AI Paddle https://aistudio.baidu.com/aistudio/index\nåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  https://zh-v2.d2l.ai/index.html\nçˆ±å¯å¯çˆ±ç”Ÿæ´»çš„çŸ¥ä¹ https://www.zhihu.com/people/fly51fly\nå°å¤§æå®æ¯… https://speech.ee.ntu.edu.tw/~hylee/index.php\nhttps://www.youtube.com/watch?v=rTqmWlnwz_0\nè‹å‰‘æ—çš„åšå®¢ https://kexue.fm/\nè±†çº¦ç¿° https://www.jianshu.com/u/8b23f6864f5d\nDIY CPU https://gitee.com/totalcontrol/hustzc\nBULMA: A Modern CSS Framework https://bulma.io/\nthree.js https://threejs.org/\nFlask https://www.w3cschool.cn/flask/\nOpen3D https://www.open3d.org/docs/release/index.html\nProject Based Learning(C,Python,Java,OpenGL et al.) https://github.com/practical-tutorials/project-based-learning\nTools Research CCF deadline https://ccfddl.github.io/\npaperwithcode https://paperswithcode.com/\nconnected papers https://www.connectedpapers.com/\nCool Paper@Su Jianlin https://papers.cool/\npaperyyæŸ¥é‡ https://www.paperyy.cn/\nè¶…æ˜Ÿå¤§é›…æŸ¥é‡ http://user.dayainfo.com/show/login\nLLM ChatGPT@OpenAI https://chat.openai.com/\nPoe: a ChatGPT-powered assistant https://poe.com/\nPerplexity.ai https://www.perplexity.ai/\nKimi AI https://kimi.moonshot.cn/\nAI news https://www.unite.ai/\nOthers LaTeXå…¬å¼ç¼–è¾‘å™¨ https://www.latexlive.com/ https://www.latex-tables.com/ https://latex.vimsky.com/\nè¿œæ™¯è®ºå› https://bbs.pcbeta.com/\nv2ray https://github.com/freefq/tutorials\nhttps://github.com/wrfree/free\nJupyterLabï¼Œæå…¶å¼ºå¤§çš„ä¸‹ä¸€ä»£notebookï¼ https://zhuanlan.zhihu.com/p/87403131\nImage Extractor https://extract.pics/\nStable Diffusion web UI https://github.com/AUTOMATIC1111/stable-diffusion-webui\nIntel CPU Docs Search https://www.intel.com/content/www/us/en/search.html\nList of NVIDIA GPU Info https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units#Desktop_GPUs\nDisk Price(US) https://diskprices.com/\nNVIDIA Cuda Toolkit Download https://developer.nvidia.com/cuda-downloads?target_os=Linux\u0026amp;target_arch=x86_64\u0026amp;Distribution=WSL-Ubuntu\u0026amp;target_version=2.0\u0026amp;target_type=deb_local\nAutoDL: GPU Rent https://www.autodl.com/login?url=/home\nCS Authors https://www.csauthors.net/\nKMS æ¿€æ´» Windows \u0026amp; Office https://blog.angustar.com/archives/activate-windows-and-office-by-kms.html\nMacè½¯ä»¶ä¸‹è½½ https://www.macvk.com/\nAnydesk for linux https://anydesk.com/en/downloads/linux\nMeshlab https://www.meshlab.net/\nCOLMAP https://colmap.github.io/\nImageMagick https://imagemagick.org/\nEnglish Duolinguo English Test https://englishtest.duolingo.cn/home\nç™»ç™»å¤šé‚»å›½ https://det.91ddedu.com/#/\nSpeak\u0026amp;Improve https://speakandimprove.com/\nWrite\u0026amp;Improve https://writeandimprove.com/\nHow To Pronounce https://www.howtopronounce.com/\nCambridge Dictionary https://dictionary.cambridge.org/dictionary/english-chinese-simplified/\nRsearchers CUHK Dr. Qi Dou https://www.cse.cuhk.edu.hk/~qdou/index.html\nProf. Tien-Tsin WONG https://ttwong12.github.io/myself.html\nHKBU Dr. Jie Chen https://jchenhkg.github.io/\nHuawei Dr. Jiemin Fang https://jaminfong.cn/\nHUST Prof. Xinggang Wang https://xwcv.github.io/\nMPI Dr. Michael J. Black https://ps.is.mpg.de/person/black\nNTU Dr. Ziwei Liu https://liuziwei7.github.io/\nTHU Prof. Yebin Liu https://liuyebin.com/\nUCSB Dr. Lingqi Yan https://sites.cs.ucsb.edu/~lingqi/\nUniversity of Tubingen Prof. Andreas Geiger https://www.cvlibs.net/index.php\n","date":1713398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713398400,"objectID":"05766939cf167c27192e862f7182aeef","permalink":"https://dante-su.github.io/notes/links/learning/","publishdate":"2024-04-18T00:00:00Z","relpermalink":"/notes/links/learning/","section":"notes","summary":"Links for learning\n","tags":["Links"],"title":"Learning","type":"book"},{"authors":null,"categories":null,"content":"Some shell command when using Anaconda\nTable of Contents Basic command Clear the screen Permissions Copy Move Pathway Folder Search file kill touch Apt Install new package Update dict Update installed package NVIDIA GPU CUDA version GPU status GPU driver System info CPU Memory Storage Network interface controller/card Kernel Ubuntu version Offline program screen tumx Downloads \u0026amp; Upload wget curl scp Compression zip Execution .bin cmake nano .sh Basic command Clear the screen clear\nproblem When terminals database is inaccessible happened.\nAdd xport TERMINFO=/usr/share/terminfo to .bashrc\nPermissions Give read, write, and execute permissions for everyone chmod -R 777 \u0026lt;dir\u0026gt;/\u0026lt;folder_name\u0026gt;\nCopy cp \u0026lt;dir\u0026gt;/file_name\u0026gt; \u0026lt;dir\u0026gt;/\u0026lt;new_name\u0026gt; cp -r \u0026lt;dir\u0026gt;/* \u0026lt;dir\u0026gt;\nMove mv \u0026lt;dir\u0026gt;/\u0026lt;file_name\u0026gt; \u0026lt;dir\u0026gt;/\u0026lt;new_name\u0026gt;\nIt also could be used to change the name of file when two \u0026lt;dir\u0026gt; are same.\nPathway pwd\nFolder Create folder mkdir \u0026lt;dir\u0026gt;/\u0026lt;name\u0026gt;\ne.g. mkdir /home/user/new_folder\nCheck content of folder ls ls \u0026lt;dir\u0026gt;\nFiles count ls -l | grep \u0026#34;^-\u0026#34; | wc -l (Count files number in this path, NOT containing subpath) ls -lR| grep \u0026#34;^-\u0026#34; | wc -l (Count files number in this path, containing subpath) ls -lR | grep \u0026#34;^d\u0026#34; | wc -l (Count folders number in this path, containing subpath)\nSearch file locate \u0026lt;name\u0026gt; find \u0026lt;name\u0026gt;\nkill kill \u0026lt;pid\u0026gt; kill -9 \u0026lt;pid\u0026gt; (-9 stands for mandatory) killall \u0026lt;program_name\u0026gt; pkill \u0026lt;program_name\u0026gt; xkill (Available on graphical interface)\ntouch touch \u0026lt;file_name\u0026gt;\nCreate a new file(Do nothing if the file already exists)\nApt Please be kindly notified that apt-get could be short to apt when using Install new package sudo apt-get install \u0026lt;package_name\u0026gt;\nUpdate dict sudo apt-get update\nUpdate installed package sudo apt-get upgrade sudo apt-get upgrade --only-upgrade \u0026lt;package_name\u0026gt;\nNVIDIA GPU CUDA version nvcc -V nvcc --version\nGPU status nvidia-smi watch -n 1 -d nvidia-smi gpustat (install it with conda/pip install gpustat) gpustat -i nvtop\nGPU driver ubuntu-drivers devices glxinfo | grep rendering sudo apt search nvidia-driver | grep nvidia-driver\nSystem info CPU Whole info cat /proc/cpuinfo\nCPU model cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c\nCore number cat /proc/cpuinfo | grep physical | uniq -c\nBit width (32/64) getconf LONG_BIT\nMemory Whole info cat /proc/meminfo\nShort info free -h\nDynamic info top or htop\nProcess status ps \u0026lt;option\u0026gt;\n\u0026lt;option\u0026gt; could be one of below:\n-A (List all process) -w (Wider list) -au (List with more details) -aux (List all processes of all users) -ef (List of all process with terminal type info) -u root (List the processes run by root) -ef | grep \u0026lt;key_word\u0026gt; (List of processes with given key word)\nStorage Whole info df -h\nInfo of current device df -h \u0026lt;dir\u0026gt;\ne.g. df -h ./\nAllocated space du -sh \u0026lt;dir\u0026gt;\nAll folderâ€™s allocated space du -sh \u0026lt;dir\u0026gt;/*\nNetwork interface controller/card dmesg | grep -i eth\nKernel uname -a\nUbuntu version lsb_release -a\nOffline program screen Installation apt install screen\nCreate a new screen screen -S \u0026lt;name\u0026gt;\nCheck all screen screen -ls\nMake screen offline screen -d \u0026lt;name\u0026gt;\nRecover screen screen -r \u0026lt;name\u0026gt;\nBack to terminal ctrl+A+D\nDelete screen screen -X -S \u0026lt;name\u0026gt; quit screen kill \u0026lt;name\u0026gt; screen kill \u0026lt;id\u0026gt;\ntumx Zhihu Link\nDownloads \u0026amp; Upload wget wget [option] [url]\n[option] could be blanck\nChange file name wget -O \u0026lt;new_name\u0026gt; \u0026lt;url\u0026gt;\nChange file path wget -P \u0026lt;new_path\u0026gt; \u0026lt;url\u0026gt;\nContinute downloading after break wget -c \u0026lt;url\u0026gt;\nIncrease attempts wget -t \u0026lt;num\u0026gt; \u0026lt;url\u0026gt;\nThe default \u0026lt;num\u0026gt; is 40\nuse ftp wget --ftp-user=\u0026lt;username\u0026gt; --ftp-password=\u0026lt;password\u0026gt; \u0026lt;url\u0026gt;\nSimulate browser wget -U \u0026#39;\u0026lt;browser_name\u0026gt;\u0026#39; \u0026lt;url\u0026gt; \u0026lt;browser\u0026gt; could be one of {Mozilla/5.0 (Windows NT 10.0; Win64; x64), AppleWebKit/537.36 (KHTML, like Gecko), Chrome/81.0.4044.43, Safari/537.36}\nDownloads on background wget -b \u0026lt;url\u0026gt;\nCheck download log tail -f wget-log\nmulti-files download vim downloads.txt wget -i downloads.txt\ncurl This command could also be used on Windows/MacOS curl -o \u0026lt;name\u0026gt; \u0026lt;url\u0026gt;\nContinute downloading after break curl -C - -o \u0026lt;name\u0026gt; \u0026lt;url\u0026gt;\nIncrease attempts curl --retry 3 -o \u0026lt;name\u0026gt; \u0026lt;url\u0026gt;\nscp Download files from server to local scp username@servername:/remote_path/filename ~/local_destination\nUpload files from local to server scp ~/local_path/local_filename username@servername:/remote_path\nDownload whole directory from server to local scp -r username@servername:/remote_path/remote_dir/ ~/local_destination\nUpload whole directory from local to server scp -r ~/local_dir username@servername:/remote_path/remote_dir\nUse scp -P PortId ... instead if you need to specify a port to connect to the server Compression zip unzip [-cflptuvz][-agCjLMnoqsVX][-P \u0026lt;password\u0026gt;][.zip][file_name][-d \u0026lt;dir\u0026gt;][-x \u0026lt;file\u0026gt;]\nunzip [-Z]\nExample unzip test.zip unzip -n test.zip -d /tmp unzip -o test.zip -d tmp/\nDetailed info -c å°†è§£å‹ç¼©çš„ç»“æœæ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼Œå¹¶å¯¹å­—ç¬¦åšé€‚å½“çš„è½¬æ¢ã€‚\n-f æ›´æ–°ç°æœ‰çš„æ–‡ä»¶ã€‚\n-l æ˜¾ç¤ºå‹ç¼©æ–‡ä»¶å†…æ‰€åŒ…å«çš„æ–‡ä»¶ã€‚\n-p ä¸-cå‚æ•°ç±»ä¼¼ï¼Œä¼šå°†è§£å‹ç¼©çš„ç»“æœæ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼Œä½†ä¸ä¼šæ‰§è¡Œä»»ä½•çš„è½¬æ¢ã€‚\n-t æ£€æŸ¥å‹ç¼©æ–‡ä»¶æ˜¯å¦æ­£ç¡®ã€‚\n-u ä¸-få‚æ•°ç±»ä¼¼ï¼Œä½†æ˜¯é™¤äº†æ›´æ–°ç°æœ‰çš„æ–‡ä»¶å¤–ï¼Œä¹Ÿä¼šå°†å‹ç¼©æ–‡ä»¶ä¸­çš„å…¶ä»–æ–‡ä»¶è§£å‹ç¼©åˆ°ç›®å½•ä¸­ã€‚\n-v æ‰§è¡Œæ—¶æ˜¾ç¤ºè¯¦ç»†çš„ä¿¡æ¯ã€‚\n-z ä»…æ˜¾ç¤ºå‹ç¼©æ–‡ä»¶çš„å¤‡æ³¨æ–‡å­—ã€‚\n-a å¯¹æ–‡æœ¬æ–‡ä»¶è¿›è¡Œå¿…è¦çš„å­—ç¬¦è½¬æ¢ã€‚\n-b ä¸è¦å¯¹æ–‡æœ¬æ–‡ä»¶è¿›è¡Œå­—ç¬¦è½¬æ¢ã€‚\n-C å‹ç¼©æ–‡ä»¶ä¸­çš„æ–‡ä»¶åç§°åŒºåˆ† â€¦","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"988519889a49102d182f970721583247","permalink":"https://dante-su.github.io/notes/shell/linux/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/shell/linux/","section":"notes","summary":"Some shell command when using Anaconda\n","tags":["Linux"],"title":"Linux","type":"book"},{"authors":null,"categories":null,"content":"Some shell command when using Anaconda\nTable of Contents Installation Usage Check installed package Check virtual environment Update conda Create env Remove env Activate/Deactivate env Install package Remove package Clone env Clean conda Remove package Usage of environment.yaml Usage of requirements.txt Debug examples NoWritableEnvsDirError Installation Please search it on official website Usage Check installed package conda list\nCheck virtual environment conda env list or conda info -e\nUpdate conda conda update conda\nCreate env conda create -n \u0026lt;env_name\u0026gt; python=3.x\nRemove env conda remove -n \u0026lt;env_name\u0026gt; --all\nActivate/Deactivate env For Linux/MacOS source activate \u0026lt;env_name\u0026gt;\nsource deactivate \u0026lt;env_name\u0026gt;\nFor Windows/Linux/MacOS conda activate \u0026lt;env_name\u0026gt;\nconda deactivate \u0026lt;env_name\u0026gt;\nInstall package conda install \u0026lt;package_name\u0026gt;=\u0026lt;version\u0026gt;\ne.g. conda install numpy=1.22.0\nRemove package conda uninstall \u0026lt;package_name\u0026gt;\nClone env conda create -n \u0026lt;new_env\u0026gt; --clone \u0026lt;old_env\u0026gt;\nClean conda conda clean --all\nRemove package conda remove -n \u0026lt;env_name\u0026gt; \u0026lt;package_name\u0026gt;\nUsage of environment.yaml Export env into yaml file conda env export \u0026gt; environment.yaml\nCreate new env from yaml file conda env create -f environment.yaml\nUsage of requirements.txt conda install --yes --file requirements.txt\nDebug examples NoWritableEnvsDirError NoWritableEnvsDirError: No writeable envs directories configured. - /home/\u0026lt;username\u0026gt;/.conda/envs - /home/\u0026lt;username\u0026gt;/anaconda3/envs Find the root path of â€˜.condaâ€™ file and use â€˜cdâ€™ enter that path and run the below commmand.\nsudo chmod a+w .conda\nor enter the path of â€˜anacondaâ€™ folder and run the below command.\nsudo chown -R \u0026lt;username\u0026gt; anaconda\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"bfdd1c625cacbc36fd7e239565762b51","permalink":"https://dante-su.github.io/notes/python/anaconda/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/python/anaconda/","section":"notes","summary":"Some shell command when using Anaconda\n","tags":["Anaconda"],"title":"Anaconda","type":"book"},{"authors":null,"categories":null,"content":"Several markdownâ€™s rule and quick command code\nCode Highlight Use the below code in markdown to highlight the emphasizing code\n```shell code is set here ``` And for different kind of code languages, shell should be substituted by specific word listed below.\nKey of corresponding Code Language language key C c ActionScript actionscript Apache apache AppleScript applescript AsciiDoc asciidoc AspectJ asciidoc AutoHotkey autohotkey AVR Assembler avrasm Axapta axapta Bash bash BrainFuck brainfuck Capâ€™n Proto capnproto Clojure REPL clojure Clojure clojure CMake cmake CoffeeScript coffeescript C++ cpp C# cs CSS css D d Dart d Delphi delphi Diff diff Django django DOS.bat dos Dust dust Elixir elixir ERB(Embedded Ruby) erb Erlang REPL erlang-repl Erlang erlang FIX fix F# fsharp G-code(ISO 6983) gcode Gherkin gherkin GLSL glsl Go go Gradle gradle Groovy groovy Haml haml Handlebars handlebars Haskell haskell Haxe haxe HTML html HTTP http Ini file ini Java java JavaScript javascript JSON json Lasso lasso Less less Lisp lisp LiveCode livecodeserver LiveScript livescript Lua lua Makefile makefile Markdown markdown Mathematica mathematica Matlab matlab MEL (Maya Embedded Language) mel Mercury mercury Mizar mizar Monkey monkey Nginx nginx Nimrod nimrod Nix nix NSIS nsis Objective C objectivec OCaml ocaml Oxygene oxygene Parser 3 parser3 Perl perl PHP php PowerShell powershell Processing processing Pythonâ€™s profiler output profile Protocol Buffers protobuf Puppet puppet Python python Q q R r RenderMan RIB rib Roboconf roboconf RenderMan RSL rsl Ruby ruby Oracle Rules Language ruleslanguage Rust rust Scala scala Scheme scheme Scilab scilab SCSS scss Smali smali SmallTalk smalltalk SML sml SQL sql Stata stata STEP Part21(ISO 10303-21) step21 Stylus stylus Swift swift Tcl tcl Tex tex text text/plain Thrift thrift Twig twig TypeScript typescript Vala vala VB.NET vbnet VBScript in HTML vbscript-html VBScript vbscript Verilog verilog VHDL vhdl Vim Script vim Intel x86 Assembly x86asm XL xl XML xml YAML yml Links \u0026lt;span id=\u0026#34;jump\u0026#34;\u0026gt;address\u0026lt;/span\u0026gt; or\n[links](#jump) Maths symbols and functions Tag of functions To name the functions with tag like below, we could us \\tag{1.1} or \\begin{equation} \u0026amp; \\end{equation}\n$$ x = y \\tag{1.1} $$ Example:\n$$ x = y \\tag{1.1} $$\n$$ \\begin{equation} x = y \\end{equation} $$ Example:\n$$ \\begin{equation} x = y \\end{equation} $$\n(As this website is build by hugo and the style file has not listed this rule, so the effect couldnâ€™t be show well.)\nTable | Head_1 | Head_2 | Head_3 | | :- | :-: | -: | | Content_1 | Content_2 | Content_3 | Example:\nHead_1 Head_2 Head_3 Content_1 Content_2 Content_3 Line break within a cell With markdown language | Head_1 | Head_2 | | :-: | :-: | | Content_1 | Content_2 \u0026lt;br\u0026gt; Content_3 | Example:\nHead_1 Head_2 Content_1 Content_2 Content_3 With HTML language \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Head_1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_2\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td rowspan=\u0026#34;2\u0026#34;\u0026gt;Content_1\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Content_2-1\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Content_2-2\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; Example:\nHead_1 Head_2 Content_1 Content_2-1 Content_2-2 Special usage of HTML Change alignment \u0026lt;table\u0026gt; \u0026lt;tr align=\u0026#34;right\u0026#34;\u0026gt; \u0026lt;th\u0026gt;Head_1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_2\u0026lt;/th\u0026gt; \u0026lt;th align=\u0026#34;left\u0026#34;\u0026gt;Head_3\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td align=\u0026#34;right\u0026#34;\u0026gt;Content_1\u0026lt;/td\u0026gt; \u0026lt;td align=\u0026#34;center\u0026#34;\u0026gt;Content_2\u0026lt;/td\u0026gt; \u0026lt;td align=\u0026#34;left\u0026#34;\u0026gt;Content_3\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; Example:\nHead_1 Head_2 Head_3 Content_1 Content_2 Content_3 Tableâ€™s header \u0026lt;table\u0026gt; \u0026lt;caption\u0026gt; Header \u0026lt;/caption\u0026gt; \u0026lt;/table\u0026gt; Example:\nHeader Multipie columns within one grid \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Head_1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_2\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Head_3\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Content_1\u0026lt;/td\u0026gt; \u0026lt;td colspan=\u0026#34;2\u0026#34;\u0026gt;Content_2\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; Example:\nHead_1 Head_2 Head_3 Content_1 Content_2 ","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"fab9b605aac7aed8b2c5b792d4d1e104","permalink":"https://dante-su.github.io/notes/others/markdown/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/markdown/","section":"notes","summary":"Several markdownâ€™s rule and quick command code\n","tags":["markdown"],"title":"Markdown","type":"book"},{"authors":null,"categories":null,"content":"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\n2024 2023 CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion [ paper | code ]\nKeywords: multi-modality, image fusion, dual branch feature decomposition\nAim: Render fused images that maintain the merits of different modalities, e.g., functional highlight and detailed textures.\nContribution:\nWe propose a dual-branch Transformer-CNN framework for extracting and fusing global and local features, which better reflects the distinct modality-specific and modality-shared features. We refine the CNN and Transformer blocks for a better adaptation to the MMIF task. Specifically, we are the first to utilize the INN blocks for lossless information transmission and the LT blocks for trading-off fusion quality and computational cost. We propose a correlation-driven decomposition loss function to enforce the modality shared/specific feature decomposition, which makes the cross-modality base features correlated while decorrelates the detailed high-frequency features in different modalities. Our method achieves leading image fusion performance for both IVF and MIF. We also present a unified measurement benchmark to justify how the IVF fusion im- ages facilitate downstream MM object detection and semantic segmentation tasks. Motivation: Our assumption is that, in the MMIF task, the input features of the two modalities are correlated at low frequencies, representing the modality-shared information, while the high-frequency feature is irrelevant and represents the unique characteristics of the respective modalities.\nArchitecture:\nOur CDDFuse contains four modules, i.e., a dual-branch encoder for feature extraction and decomposition, a decoder for reconstructing original images (in training stage I) or generating fusion images (in training stage II), and the base/detail fusion layer to fuse the different frequency features, respectively. Within the dual-branch encoder, Base Transformer Encoder focus low-frequency global cross-modality information while the Detail CNN Encoder focus on high-frequency local inner-modality information. And a correlation-driven decomposition loss function is designed to reduce the local similarity of different modality, enlarge the global similarity of different modality.\nComparison models: DIDFuse@IJCAI\u0026#39;20, Sdnet@IJCV\u0026#39;21, U2fusion@TPAMI\u0026#39;22, Rfnet@CVPR\u0026#39;22, TarD@CVPR\u0026#39;22, DeFusion@ECCV\u0026#39;22, Reconet@ECCV\u0026#39;22\n2022 2021 D-NeRF: Neural Radiance Fields for Dynamic Scenes [ homepage | paper | code ]\nKeywords: NeRF, dynamic scene\nAim: Extend neural radiance fields to a dynamic domain, allowing to reconstruct and render novel images of objects under rigid and non-rigid motions from a single camera moving around the scene.\nContribution:\nProposed a new method: D-NeRF, which is the first approach able to generate a neural implicit representation for non-rigid and time-varying scenes, trained solely on monocular data without the need of 3D ground-truth supervision nor a multi-view camera setting. Sufficient experiments were done to demonstrate the effectiveness of proposed approach on scenes with objects under rigid, articulated and non-rigid motions. Motivation: Considering time as an additional input to the system, so we could split the learning process in two main stages: one that encodes the scene into a canon- ical space and another that maps this canonical representation into the deformed scene at a particular time.\nArchitecture:\nD-NeRF consists of two main neural network modules, Canonical Network and Deformation Network, which parameterize the mappings $Î¨_t$(from pointâ€™s position in time-varying scene to pointâ€™s position in canonical scene), $Î¨_x$(from pointâ€™s position \u0026amp; viewing direction to emitted color \u0026amp; volume density).\nComparison models: NeRF@ECCV\u0026#39;20, T-NeRF(Time-conditioned NeRF)@This paper\n","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711497600,"objectID":"b783698d6808787422481fe429d923ef","permalink":"https://dante-su.github.io/notes/paper_reading/cvpr/","publishdate":"2024-03-27T00:00:00Z","relpermalink":"/notes/paper_reading/cvpr/","section":"notes","summary":"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\n","tags":["cvpr","paper"],"title":"CVPR","type":"book"},{"authors":null,"categories":null,"content":"Greg Turk, August 2019\nTwenty-two years ago, I wrote an essay about what math is important for computer graphics. That document is now fairly dated, and I have decided that it is time to re-visit this question. I am writing this essay in part for college students who want to know what courses may be relevant to the study of computer graphics. For this reason, I will remark on the departments that are likely to offer courses in a given topic. Hopefully it is obvious that you do not need to be a college student to read this essay!\nComputer graphics draws upon many different areas of mathematics for tools that help accomplish various computational tasks. For as long as you want to pursue computer graphics, you should also plan to continue to learn more mathematical techniques. There are very few corners of computer graphics that do not make use of some form of mathematics.\nThe most important point that I want to convey in this essay is the following. The mathematical topics that are often the most useful to graphics are so-called Numerical Methods. These are the tools that take abstract mathematical concepts (differentiation, integration, matrix inversion, etc.) and turn them into concrete algorithms that we can use to find numerical results to the problem at hand. When you first learn in calculus class how to differentiate and integrate, you start by doing this symbolically. (For example, the derivative of the sine function is cosine.) In graphics, we need to be able to translate the symbolic answer to a given problem into a numerical technique that can be implemented on the computer. For this reason, it is most often the applied mathematics courses (not those in pure mathematics)that are the most relevant to graphics.\nThe numerical methods that are useful for graphics are frequently the same tools that various engineers use. This means that sometimes the most useful courses for graphics may not be in the math department. They may instead be found in other departments such as electrical engineering or mechanical engineering.\nIn this essay I am going to refer the four core areas of computer graphics. These areas are:\nModeling - creating 3D shape descriptions of objects Animation - making objects move Image Synthesis, also called Rendering - making pictures from 3D shapes Image and Video Manipulation I am going to visit the mathematics useful to graphics in an order that (approximately) lines up with the order of the four topics listed above. Note that modeling and animation often make use of similar mathematics. The same is true of the other pair â€” image synthesis and image/video manipulation often use similar math tools. Before I visit any of these topics, however, I am going to start with the math needed for a first course in graphics.\nMathematical Basics: Linear Algebra and Trigonometry The most important topics for starting out in graphics are Linear Algebra and Trigonometry. We usually describe the location of a 3D graphics object according to its x, y and z coordinates. We can then apply the following operations on a 3D object: translate (move), scale (change size), and rotate. Translation and scale are accomplished using addition and multiplication, respectively. Rotation is done using sine and cosine, hence the need for trigonometry. The x, y and z coordinates of an object can be conveniently represented as a 3D vector, and the translate, scale and rotate operations can be described as multiplication by a matrix (of size 3x3 or 4x4). This is one of the reasons that a background in linear algebra is important for starting in graphics. Several other concepts from linear algebra also are useful, including matrix inversion, dot product, and cross product.\nMultivariable Calculus Many of the more advanced topics in computer graphics make use of the tools of Multivariable Calculus. These topics are usually saved for a second or third course in calculus. Many of the representations that are used in computer graphics are functions of multiple variables, and thus require tools to reason about derivatives and integrals of such functions. If you want to study computer graphics beyond a first course in the area, I strongly recommend taking the full sequence of calculus classes that your school offers.\nDifferential Geometry Differential Geometry is the measurement of properties of curves and surfaces, and these techniques are very important for modeling in graphics. Common graphics-related tasks that fall under this domain include determining tangents, measuring curvature, evaluating lengths and areas, and finding shortest paths. Often differential geometry techniques are combined with optimization methods (more on this below). Fortunately, many math departments offer an undergraduate course in differential geometry.\nComputational Geometry Computational Geometry is the study of algorithms that efficiently and robustly solve geometric problems. Some common problems in this area include find convex hulls, finding â€¦","date":1695859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695859200,"objectID":"51efd94295384cf111b8730dc22ee835","permalink":"https://dante-su.github.io/notes/computer_graphics/math/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/notes/computer_graphics/math/","section":"notes","summary":"Greg Turk, August 2019\n","tags":["Math","Computer Graphics"],"title":"Math for Computer Graphics","type":"book"},{"authors":null,"categories":null,"content":"Python code instances\nimage format transfermation common import cv2 import os import glob def change_img_format(): # iterations path = input(r\u0026#34;Input the path of image to be processed(eg: D:\\picture\\1.jpg):\u0026#34;) print(\u0026#39;Path of image here is : \u0026#39;,path) path_rewrite = input(r\u0026#34;Input the path of restoring the image(eg: D:\\picture):\u0026#34;) img_format = input(r\u0026#34;Input the format you want(eg: jpg):\u0026#34;) for i in glob.glob(path): print(\u0026#39;I here is : \u0026#39;, i) im = cv2.imread(i) new_path = os.path.join(path_rewrite,\u0026#39;new_name\u0026#39;+\u0026#39;.\u0026#39;+img_format) cv2.imwrite(new_path,im) if __name__ == \u0026#39;__main__\u0026#39;: change_img_format() é’ˆå¯¹ ico ï¼ˆå›¾æ ‡ï¼‰æ–‡ä»¶ \u0026#39;\u0026#39;\u0026#39; å¸¸ç”¨å›¾æ ‡å¤§å°ï¼š [ (256, 256), (128, 128), (64, 64), (48, 48), (32, 32), (24, 24), (16, 16) ] \u0026#39;\u0026#39;\u0026#39; from PIL import Image def make_ico_file(src_image_file, dist_ico_file, size): size = [int(size), int(size)] image = Image.open(src_image_file) image_cropped = image.crop((0, 0, 256, 256)) image_cropped.save(dist_ico_file, sizes=size) if __name__ == \u0026#39;__main__\u0026#39;: make_ico_file(input(r\u0026#34;Input the path of the image(eg: D:\\picture\\1.jpg):\u0026#34;), input(r\u0026#39;Input the name of icon(eg: favicon):\u0026#39;), input(r\u0026#39;Input the same of icon(eg: 256):\u0026#39;)) image Portrait Matting from rembg import remove from PIL import Image in_path = \u0026#39;example.jpg\u0026#39; out_path = \u0026#39;output.jpg\u0026#39; image_in = Image.open(in_path) image_out = remove(image_in) image_out.save(out_path) image resize import cv2 import os import glob def img_resize(): # iterations path = input(r\u0026#34;Input the path of image to be processed(eg: D:\\picture\\1.jpg):\u0026#34;) print(\u0026#39;Path of image here is : \u0026#39;,path) path_rewrite = input(r\u0026#34;Input the path of restoring the image(eg: D:\\picture):\u0026#34;) for i in glob.glob(path): print(\u0026#39;I here is : \u0026#39;, i) im1 = cv2.imread(i) # print(\u0026#39;The original image data are: \u0026#39;, im1) im2 = cv2.resize(im1,(256,256)) # (256,256)æ˜¯ç¼©æ”¾åçš„åƒç´ æ•° # print(\u0026#39;The resized image data are: \u0026#39;, im2) cv2.imwrite(os.path.join(path_rewrite,\u0026#39;resized_\u0026#39; + os.path.basename(i)),im2) if __name__ == \u0026#39;__main__\u0026#39;: img_resize() point cloud visualizer import open3d as o3d import numpy as np raw_point = np.arange(3000).reshape(3,-1) #åˆ›å»ºçª—å£å¯¹è±¡ vis = o3d.visualization.Visualizer() #è®¾ç½®çª—å£æ ‡é¢˜ vis.create_window(window_name=\u0026#34;example\u0026#34;) #è®¾ç½®ç‚¹äº‘å¤§å° vis.get_render_option().point_size = 1 #è®¾ç½®é¢œè‰²èƒŒæ™¯ä¸ºé»‘è‰² opt = vis.get_render_option() opt.background_color = np.asarray([0, 0, 0]) #åˆ›å»ºç‚¹äº‘å¯¹è±¡ pcd=o3d.open3d.geometry.PointCloud() #å°†ç‚¹äº‘æ•°æ®è½¬æ¢ä¸ºOpen3då¯ä»¥ç›´æ¥ä½¿ç”¨çš„æ•°æ®ç±»å‹ pcd.points= o3d.open3d.utility.Vector3dVector(raw_point) #è®¾ç½®ç‚¹çš„é¢œè‰²ä¸ºç™½è‰² pcd.paint_uniform_color([1,1,1]) #å°†ç‚¹äº‘åŠ å…¥åˆ°çª—å£ä¸­ vis.add_geometry(pcd) vis.run() vis.destroy_window() meshlab ply2obj ä½¿ç”¨meshlab ç‰ˆæœ¬åº”è¯¥åœ¨2020.12ä¹‹å‰ï¼ˆæ­¤å¤„ç”¨2020.2ï¼‰ï¼Œæ–°å»ºply2obj.batå¹¶å°†å…¶æ”¾ç½®åœ¨meshlabserver.exeåŒçº§çš„æ–‡ä»¶å¤¹å†…ï¼ŒæŒ‰ç…§ä¸‹è¿°æ–‡å­—ä¿®æ”¹å€¼ï¼ŒåŒå‡»è¿è¡Œå³å¯\n@echo off set input_path=D:\\inputFolder set output_path=D:\\outputFolder dir %input_path%\\*.ply /b/od\u0026gt;%input_path%\\name.txt for /F %%i in (%input_path%\\name.txt) do ( meshlabserver -i %input_path%\\%%i -o %output_path%\\%%~ni.obj -m vc vn fn) rem ä¸Šé¢ç¬¬äºŒè¡Œ -m åçš„å‚æ•°è¯´æ˜ï¼ˆå‚æ•°æ ¹æ®éœ€è¦è‡ªè¡Œä¿®æ”¹ï¼‰vc é¡¶ç‚¹é¢œè‰²ï¼Œvf é¡¶ç‚¹æ ‡å¿—ï¼Œvq é¡¶ç‚¹è´¨é‡ï¼Œvn é¡¶ç‚¹æ³•çº¿ vt é¡¶ç‚¹çº¹ç†åæ ‡ï¼Œvr é¡¶ç‚¹åŠå¾„ï¼Œfc é¢è‰²ï¼Œff é¢æ ‡å¿—ï¼Œfq é¢éƒ¨è´¨é‡ï¼Œfn é¢éƒ¨æ³•çº¿ï¼Œwc æ¥”å½¢é¢œè‰²ï¼Œwn æ¥”å½¢æ³•çº¿ï¼Œwt æ¥”å½¢çº¹ç†ï¼Œmp å¤šè¾¹å½¢ç½‘æ ¼ä¿¡æ¯ obj2ply åŒä¸Š\n@echo off set input_path=D:\\inputFolder set output_path=D:\\outputFolder dir %input_path%\\*.obj /b/od\u0026gt;%input_path%\\name.txt for /F %%i in (%input_path%\\name.txt) do ( meshlabserver -i %input_path%\\%%i -o %output_path%\\%%~ni.ply -m vc vn fn) rem ä¸Šé¢ç¬¬äºŒè¡Œ -m åçš„å‚æ•°è¯´æ˜ï¼ˆå‚æ•°æ ¹æ®éœ€è¦è‡ªè¡Œä¿®æ”¹ï¼‰vc é¡¶ç‚¹é¢œè‰²ï¼Œvf é¡¶ç‚¹æ ‡å¿—ï¼Œvq é¡¶ç‚¹è´¨é‡ï¼Œvn é¡¶ç‚¹æ³•çº¿ vt é¡¶ç‚¹çº¹ç†åæ ‡ï¼Œvr é¡¶ç‚¹åŠå¾„ï¼Œfc é¢è‰²ï¼Œff é¢æ ‡å¿—ï¼Œfq é¢éƒ¨è´¨é‡ï¼Œfn é¢éƒ¨æ³•çº¿ï¼Œwc æ¥”å½¢é¢œè‰²ï¼Œwn æ¥”å½¢æ³•çº¿ï¼Œwt æ¥”å½¢çº¹ç†ï¼Œmp å¤šè¾¹å½¢ç½‘æ ¼ä¿¡æ¯ PyTorch train.py import time import click from datetime import datetime import torch # from torch import nn from torch.utils.data import DataLoader # from torch.utils.tensorboard import SummaryWriter # from sklearn.metrics import confusion_matrix from utils.loss import * from utils.model import * from utils.loader import * from utils.others import * def train(gpu_set, epoch, learning_rate, data_path, batch_size, loss, weight_decay=\u0026#39;0.00001\u0026#39;, model_name = \u0026#39;dp_cnn\u0026#39;, time_now = \u0026#39;fake time\u0026#39;): # Load train and val data print(\u0026#39;Loading data...\u0026#39;) trainset, valset = load_train_data(data_path) # Get and print useful settings print(\u0026#39;Getting settings...\u0026#39;) train_data_size,val_data_size,n_classes,input_lenghth = get_setting(trainset, valset) # Using DataLoader to load data print(\u0026#39;Setting dataloader...\u0026#39;) train_dataloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True ) val_dataloader = DataLoader(dataset=valset, batch_size=batch_size, shuffle=True ) # Set pytorch device print(\u0026#39;Setting device...\u0026#39;) device = get_device_name(gpu_set) # Create the model print(\u0026#39;Creating model network...\u0026#39;) model = model_set(model_name,n_classes, batch_size,input_lenghth).to(device) # Creat loss function print(\u0026#39;Creating loss function...\u0026#39;) loss_fn = loss_set(loss,device) # create optimizer print(\u0026#39;Creating optimizer...\u0026#39;) # optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False) # set some sets total_train_step = 0 # record training\u0026#39;s number # â€¦","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"8fcc841d388c336609360020d90907b1","permalink":"https://dante-su.github.io/notes/code_instance/python/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/code_instance/python/","section":"notes","summary":"Python code instances\n","tags":["example"],"title":"Python","type":"book"},{"authors":null,"categories":null,"content":"My Collection\nDaily Life çŸ¥ä¹ https://www.zhihu.com/\nBilibili https://www.bilibili.com/\nInfo HK GOV holiday https://www.gov.hk/tc/about/abouthk/holiday/\nHK Visa Online Application Status Enquiry https://www.gov.hk/en/residents/immigration/nonpermanent/appstatusenq.htm\nHK Visa Extension Online Application https://www.gov.hk/sc/residents/immigration/nonpermanent/applyextensionstay/othernpr.htm\nPolyU PolyU account https://adfs.polyu.edu.hk/adfs/ls/\nPolyU ELC Booking System https://elc.polyu.edu.hk/booking/main.php\nPolyU Payroll https://www.polyu.edu.hk/fo/staff/full-time-staff/payroll/\nPolyU Leave Online Application https://www40.polyu.edu.hk/hrchris/\nRecruit IBM https://www.ibm.com/cn-zh/employment/internship/\nMSRA https://www.msra.cn/zh-cn/jobs\nEntertainment ä½ç«¯å½±è§† https://ddrk.me/ https://ddys.love https://ddys.pro/ https://ddys.mov/\nç¾å‰§7 https://www.meiju7.cc/\néŸ©å‰§çœ‹çœ‹ https://www.hanjukankan.com/\nçˆ±å£¹å¸†å½±è§† https://www.aiyifan.tv/drama\nUntitled http://transition.vipray.cn/\nOthers æ–°åŠ å¡å·¥ä½œæŒ‡å— https://www.965work.in/archives/work-guide-for-singapore/\nç”³è¯·è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢ç”Ÿç‰©å­¦åšå£«éœ€è¦åšå“ªäº›å‡†å¤‡ï¼Ÿ https://www.zhihu.com/question/532997474/answer/2549675321\nä¸€ç¯‡CVPRè®ºæ–‡æ€èµ·ä¸šç•Œç ”ç©¶çƒ­æ½®ï¼Œè¿™ä½90åå´å°†ä»£ç å¼€æºï¼Œä¿ƒè¿›çŸ¥è¯†è’¸é¦ç ”ç©¶ | ä¸“è®¿ https://zhuanlan.zhihu.com/p/407941252\nWriting a SIGGRAPH paper (for fun) https://www.mattkeeter.com/projects/siggraph/\nå°éœ¸ç‹ æ¨¡æ‹Ÿå™¨ https://www.yikm.net/\nä¸­å›½å†å²æ—¶é—´è½´ https://www.lishiju.net/timeline.html\n","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"c2a757c1d745cf66f231f331237019ee","permalink":"https://dante-su.github.io/notes/links/collection/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/links/collection/","section":"notes","summary":"My Collection\n","tags":["Links"],"title":"Collection","type":"book"},{"authors":null,"categories":null,"content":"Proceedings of the IEEE/CVF International Conference on Computer Vision\n2023 Task-Oriented Multi-Modal Mutual Leaning for Vision-Language Models [ paper ]\nKeywords: **\nAim:\nContribution:\nMotivation:\nArchitecture:\nComparison models:\n","date":1711324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711324800,"objectID":"99afdbae7cf688a2fd21c485e0549bf5","permalink":"https://dante-su.github.io/notes/paper_reading/iccv/","publishdate":"2024-03-25T00:00:00Z","relpermalink":"/notes/paper_reading/iccv/","section":"notes","summary":"Proceedings of the IEEE/CVF International Conference on Computer Vision\n","tags":["iccv","paper"],"title":"ICCV","type":"book"},{"authors":null,"categories":null,"content":"Gitbookâ€™s installation and usage\nInstallation Nodejs å› ä¸ºGitbookä¾èµ–Nodejsï¼Œæ‰€ä»¥é¦–å…ˆè¦å®‰è£…Nodejsï¼Œè€Œä¸”å› ä¸ºgitbookåæ¥å¾ˆä¹…æœªæ›´æ–°ï¼Œæ‰€ä»¥å¯¹æ–°ç‰ˆçš„nodejså…¼å®¹æ€§ä¸å¥½ï¼Œå®¹æ˜“å‡ºbugï¼Œå»ºè®®æœ€å¤šä½¿ç”¨åˆ°ç¬¬10ç‰ˆçš„nodejs\nMac\nä» https://nodejs.org/en/ ä¸‹è½½å¹¶å®‰è£… Nodejs ï¼Œå®‰è£…å®Œåå¯é€šè¿‡ç»ˆç«¯å‘½ä»¤ node -v æ£€éªŒæ˜¯å¦å®‰è£…æˆåŠŸã€‚\nåé¢å¯èƒ½æŠ¥é”™ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥é€šè¿‡ brew å‘½ä»¤ä¸‹è½½ä½ç‰ˆæœ¬çš„ nodejsï¼š\nbrew install node@10 echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/node@10/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc\nCheck installation status\nnode -v npm -v\nå¦‚æœä¸Šè¿°æ–¹æ³•ä¸å¯ä»¥ç»§ç»­ä½¿ç”¨ï¼Œè¯·ç‚¹å‡»æ­¤å¤„\npwd cd source .bash_profile\nLinux\nUnder buildingâ€¦\nWindows\nUnder buildingâ€¦\nGitbook npm install gitbook-cli -g\ngitbook -V\nUsage Initialize a new book gitbook init\nBuild gitbook build\nè‹¥åªæ‰§è¡Œgitbook buildï¼Œä¼šç”Ÿæˆ_bookç›®å½•ï¼Œä½†ä¸èƒ½é¢„è§ˆã€‚\nåœ¨è¿™ä¸ªç›®å½•ä¸­ï¼Œå¯¹äºæ¯ä¸€ä¸ª markdown æ–‡ä»¶éƒ½ç”Ÿæˆäº†ä¸€ä¸ªç›¸åº”çš„ html æ–‡ä»¶ï¼ŒåŒæ—¶åœ¨ _book/gitbook æ–‡ä»¶å¤¹ä¸­å­˜æ”¾äº†ä¸€äº›ä¸»é¢˜ã€å­—ä½“ã€æ ·å¼ä¸å›¾åƒç­‰æ–‡ä»¶\nPreview gitbook serve ./{book_name} æœ€åä¸€ä¸ªå‚æ•°æŒ‡å®šè¾“å‡ºé™æ€ç½‘ç«™å†…å®¹çš„ç›®å½•ï¼Œå¯çœç•¥ï¼Œé»˜è®¤ä¼šåœ¨å½“å‰ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªå­ç›®å½•_book\n(base) dantesu@DanteSudeMacBook-Pro gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 14 explicitly listed info: loading plugin \u0026#34;splitter\u0026#34;... OK info: loading plugin \u0026#34;expandable-chapters-small\u0026#34;... OK info: loading plugin \u0026#34;anchors\u0026#34;... OK info: loading plugin \u0026#34;github\u0026#34;... OK info: loading plugin \u0026#34;github-buttons\u0026#34;... OK info: loading plugin \u0026#34;sharing-plus\u0026#34;... OK info: loading plugin \u0026#34;anchor-navigation-ex\u0026#34;... OK info: loading plugin \u0026#34;favicon\u0026#34;... OK info: loading plugin \u0026#34;livereload\u0026#34;... OK info: loading plugin \u0026#34;highlight\u0026#34;... OK info: loading plugin \u0026#34;search\u0026#34;... OK info: loading plugin \u0026#34;lunr\u0026#34;... OK info: loading plugin \u0026#34;fontsettings\u0026#34;... OK info: loading plugin \u0026#34;theme-default\u0026#34;... OK info: found 10 pages info: found 2 asset files info: \u0026gt;\u0026gt; generation finished with success in 1.1s ! Starting server ... Serving book on http://localhost:4000 Styles gitbook install\næ›´æ–°æ ·å¼ä¸­çš„æ’ä»¶åéœ€è¦ä½¿ç”¨æ­¤å‘½ä»¤æ¥å®‰è£…æ–°çš„æ’ä»¶ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼Œæ¯”å¦‚ï¼š\n(base) dantesu@DanteSudeMBP gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 16 explicitly listed Error: Couldn\u0026#39;t locate plugins \u0026#34;page-footer-ex\u0026#34;, Run \u0026#39;gitbook install\u0026#39; to install plugins from registry. Style example ä»¥ä¸‹æ˜¯æˆ‘æš‚æ—¶åœ¨ä½¿ç”¨çš„æ ·å¼\n{ \u0026#34;title\u0026#34;: \u0026#34;DanteSU\u0026#39;s House\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;DanteSU\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;All I know is here\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;zh-hans\u0026#34;, \u0026#34;gitbook\u0026#34;: \u0026#34;3.2.3\u0026#34;, \u0026#34;styles\u0026#34;: { \u0026#34;website\u0026#34;: \u0026#34;./styles/website.css\u0026#34; }, \u0026#34;structure\u0026#34;: { \u0026#34;readme\u0026#34;: \u0026#34;README.md\u0026#34; }, \u0026#34;links\u0026#34;: { \u0026#34;sidebar\u0026#34;: { \u0026#34;ä½†ä¸ä¸–ç•Œï¼ˆåœ¨å»ºï¼‰\u0026#34;: \u0026#34;https://dante-su.github.io/\u0026#34; } }, \u0026#34;plugins\u0026#34;: [ \u0026#34;-sharing\u0026#34;, \u0026#34;splitter\u0026#34;, \u0026#34;expandable-chapters-small\u0026#34;, \u0026#34;anchors\u0026#34;, \u0026#34;github\u0026#34;, \u0026#34;github-buttons\u0026#34;, \u0026#34;sharing-plus\u0026#34;, \u0026#34;anchor-navigation-ex\u0026#34;, \u0026#34;favicon\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;github\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/Dante-Su\u0026#34; }, \u0026#34;sharing\u0026#34;: { \u0026#34;douban\u0026#34;: false, \u0026#34;facebook\u0026#34;: false, \u0026#34;google\u0026#34;: false, \u0026#34;hatenaBookmark\u0026#34;: false, \u0026#34;instapaper\u0026#34;: false, \u0026#34;line\u0026#34;: false, \u0026#34;linkedin\u0026#34;: false, \u0026#34;messenger\u0026#34;: false, \u0026#34;pocket\u0026#34;: false, \u0026#34;qq\u0026#34;: false, \u0026#34;qzone\u0026#34;: false, \u0026#34;stumbleupon\u0026#34;: false, \u0026#34;twitter\u0026#34;: false, \u0026#34;viber\u0026#34;: false, \u0026#34;vk\u0026#34;: false, \u0026#34;weibo\u0026#34;: false, \u0026#34;whatsapp\u0026#34;: false, \u0026#34;all\u0026#34;: [ \u0026#34;google\u0026#34;, \u0026#34;facebook\u0026#34;, \u0026#34;weibo\u0026#34;, \u0026#34;twitter\u0026#34;, \u0026#34;qq\u0026#34;, \u0026#34;qzone\u0026#34;, \u0026#34;linkedin\u0026#34;, \u0026#34;pocket\u0026#34; ] }, \u0026#34;anchor-navigation-ex\u0026#34;: { \u0026#34;showLevel\u0026#34;: false }, \u0026#34;favicon\u0026#34;:{ \u0026#34;shortcut\u0026#34;: \u0026#34;./source/images/favicon.jpg\u0026#34;, \u0026#34;bookmark\u0026#34;: \u0026#34;./source/images/favicon.jpg\u0026#34;, \u0026#34;appleTouch\u0026#34;: \u0026#34;./source/images/apple-touch-icon.jpg\u0026#34;, \u0026#34;appleTouchMore\u0026#34;: { \u0026#34;120x120\u0026#34;: \u0026#34;./source/images/apple-touch-icon.jpg\u0026#34;, \u0026#34;180x180\u0026#34;: \u0026#34;./source/images/apple-touch-icon.jpg\u0026#34; } } } } Style website https://www.npmjs.com/search?q=gitbook-plugin-theme\u0026amp;ranking=quality\nDeploy with Github Page Updating\n","date":1695859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695859200,"objectID":"e339be0ee66c7ceb5bac85c0be6541e9","permalink":"https://dante-su.github.io/notes/others/gitbook/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/notes/others/gitbook/","section":"notes","summary":"Gitbookâ€™s installation and usage\n","tags":["gitbook","html"],"title":"Gitbook","type":"book"},{"authors":null,"categories":null,"content":"Notes for GAMES101\nOverview GAMES is short for â€˜Graphics And Mixed Environment Symposiumâ€™, which is a study platium designed for sharing knowledge about â€˜Computer Graphicsâ€™ for those who havenâ€™t or wonâ€™t have been enrolled in related course but have ambition and interest to learn it by themselves.\nAnd GAMES101 is one of them, at the same time, the basicest one. Itâ€™s taught by Dr. Lingqi YAN, an Assist. Prof. of UCSB.\nUpdating soon.","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"0b6be1bd42699716f811a9ed64bfc3aa","permalink":"https://dante-su.github.io/notes/computer_graphics/games101/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/computer_graphics/games101/","section":"notes","summary":"Notes for GAMES101\n","tags":["GAMES101"],"title":"GAMES101","type":"book"},{"authors":null,"categories":null,"content":"Some pip commands.\nUsage Install package pip install \u0026lt;package_name\u0026gt;\npip install \u0026lt;package_name\u0026gt;==\u0026lt;version\u0026gt;\nrequirements.txt Create a requirements.txt pip freeze \u0026gt; requirements.txt\nInstall packages from requirements.txt pip install -r requirements.txt\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"9bf9f19235b021fd6ca3b18d3cc8185c","permalink":"https://dante-su.github.io/notes/python/pip/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/python/pip/","section":"notes","summary":"Some pip commands.\n","tags":["Pip"],"title":"Pip","type":"book"},{"authors":null,"categories":null,"content":"Powershell command in Windows\nTable of Contents Clear the screen Info Files in current folder Current pathway Change path GPU status Memory chip Install anaconda on Powershell Clear the screen cls\nInfo Files in current folder dir\nCurrent pathway chdir\nChange path cd \u0026lt;dir\u0026gt;\nGPU status cd C:\\Program Files\\NVIDIA Corporation\\NVSMI nvidia-smi\nMemory chip wmic memorychip get /value\nInstall anaconda on Powershell","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"ec599c625f8528e2dc358fd51a81502f","permalink":"https://dante-su.github.io/notes/shell/windows/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/shell/windows/","section":"notes","summary":"Powershell command in Windows\n","tags":["Windows","Powershell"],"title":"Windows","type":"book"},{"authors":null,"categories":null,"content":"European Conference on Computer Vision\n2022 2020 NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis [ homepage | paper | code-TensorFlow | code-PyTorch ]\nKeywords: NeRF, image synthesis, volume rendering\nAim: Propose Neural Radiance Field to synthesize novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views and MLP.\nContribution:\nAn approach for representing continuous scenes with complex geometry and materials as 5D neural radiance fields, parameterized as basic MLP networks. A differentiable rendering procedure based on classical volume rendering techniques, which we use to optimize these representations from standard RGB images. This includes a hierarchical sampling strategy to allocate the MLPâ€™s capacity towards space with visible scene content. A positional encoding to map each input 5D coordinate into a higher dimensional space, which enables us to successfully optimize neural radiance fields to represent high-frequency scene content. Motivation: Using MLPs to represent objects and scenes as continuous functions is of many benefits. As volume rendering is naturally differentiable, if only using MLPs to memorize and calculate the color and volume density of emitted radiance, the architecture of MLP wonâ€™t be too complex, so the performance would be superior.\nArchitecture:\nNeRF takes x-y-z location in Cartesian coordinates of queried points and viewing direction as input. After passing a pure MLP, NeRF output the color of $RGB\\alpha$ and its volume density. And then, classical volume rendering techniques will be applied to accumulate those colors and densities into a 2D image.\nComparison models: LLFF@SIGGRAPH\u0026#39;19, SRN@NeurIPS\u0026#39;19, NV@SIGGRAPH\u0026#39;19\n","date":1714003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714003200,"objectID":"22257c0f062ca56b494e92060aa87490","permalink":"https://dante-su.github.io/notes/paper_reading/eccv/","publishdate":"2024-04-25T00:00:00Z","relpermalink":"/notes/paper_reading/eccv/","section":"notes","summary":"European Conference on Computer Vision\n","tags":["eccv","paper"],"title":"ECCV","type":"book"},{"authors":null,"categories":null,"content":"Links for dealing with specific situation when debugging.\nMirror æ¸…åæº https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/\nhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/\nAccepted Paper List MICCAI 2021 https://miccai2021.org/openaccess/paperlinks/index.html\nMICCAI 2022 https://conferences.miccai.org/2022/papers/\nMICCAI 2023 https://conferences.miccai.org/2023/papers/\nNeurIPSâ€˜2023 Accepted Paper List@PaperDigest https://www.paperdigest.org/data/neurips-2023-full.html\nCVPR 2023 https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers\nCVPR 2023 æœ€å…¨æ•´ç†@æå¸‚ https://www.cvmart.net/community/detail/7422#3DReconstruction\nMedcial Image Analysis batchgenerators by MIC@DKFZ (Data augmentation for 2D/3D image classification/segmentation) https://github.com/MIC-DKFZ/batchgenerators\nCardiac Imaging https://www.creatis.insa-lyon.fr/~bernard/research.html\nUltrasound, General@Embodi3D https://www.embodi3d.com/files/category/58-ultrasound-general/\nFetal, Pregnant Women and Infants Numerical Models http://femonum.telecom-paristech.fr/projects.html\nAwesome-Ultrasound-Standard-Plane-Detection https://github.com/Yulv-git/Awesome-Ultrasound-Standard-Plane-Detection\nDeep Learning ä½¿ç”¨Pytorchæ¡†æ¶è‡ªå·±åˆ¶ä½œåšæ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±» https://blog.csdn.net/zwy_697198/article/details/123561769 https://blog.csdn.net/zwy_697198/article/details/123587399 https://blog.csdn.net/zwy_697198/article/details/123584396\nä¸€æ–‡å¼„æ‡‚pytorchæ­å»ºç½‘ç»œæµç¨‹+å¤šåˆ†ç±»è¯„ä»·æŒ‡æ ‡ https://cloud.tencent.com/developer/article/1825669\nPytorch æ„å»ºç®€å•Neural Networks https://blog.csdn.net/weixin_42888638/article/details/121679700\npytorch åŠ è½½å¤§æ•°æ®é›† å†…å­˜ä¸å¤Ÿ çš„å¤„ç†æ–¹å¼ https://blog.csdn.net/cjs8348797/article/details/115708811\nhttps://www.cnblogs.com/aminor/p/14336767.html\nhttps://www.zhihu.com/question/386743819/answer/1989311050\nhttps://www.cnblogs.com/xiaosongshine/p/10750908.html\nAdaptivePoolingä¸Max/AvgPoolingç›¸äº’è½¬æ¢ https://www.cnblogs.com/xiaosongshine/p/10750908.html\nPythonä¸­ç”Ÿæˆå¹¶ç»˜åˆ¶æ··æ·†çŸ©é˜µ https://blog.csdn.net/kane7csdn/article/details/83756583\nPytorch å®Œæ•´çš„æ¨¡å‹è®­ç»ƒå¥—è·¯ https://blog.csdn.net/weixin_45468845/article/details/122971739\nhttps://zhuanlan.zhihu.com/p/464796719\nhttps://blog.csdn.net/FUTEROX/article/details/122724634\npytorchä¸­æ ¹æ®ç¥ç»ç½‘ç»œç»“æ„ç¡®å®šè¾“å…¥å›¾ç‰‡å°ºå¯¸/æ ¹æ®å›¾ç‰‡å°ºå¯¸ä¿®æ”¹ç¥ç»ç½‘ç»œç»“æ„ https://blog.csdn.net/weixin_43423455/article/details/99096580\ntorch.nn.AdaptiveAvgPool1d(N)å‡½æ•°è§£è¯» https://blog.csdn.net/qq_40178291/article/details/102699493\ntorch.view()è¯¦è§£åŠ-1å‚æ•°æ˜¯ä»€ä¹ˆæ„æ€ https://www.cnblogs.com/MartinLwx/p/10543604.html\nPytorchå¸¸ç”¨çš„äº¤å‰ç†µæŸå¤±å‡½æ•°CrossEntropyLoss()è¯¦è§£ https://zhuanlan.zhihu.com/p/98785902\nPyTorch å¤šåˆ†ç±»æŸå¤±å‡½æ•° https://blog.csdn.net/jacke121/article/details/104665912/\npytorchçš„å„ç§loss https://blog.csdn.net/qq_22764813/article/details/104867431\nPyTorch Bertæ–‡æœ¬åˆ†ç±» https://blog.csdn.net/weixin_44912902/article/details/123886825\näºŒåˆ†ç±»é—®é¢˜ï¼šåŸºäºBERTçš„æ–‡æœ¬åˆ†ç±»å®è·µï¼é™„å®Œæ•´ä»£ç  https://blog.csdn.net/Datawhale/article/details/104871803?spm=1001.2101.3001.6650.3\u0026amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-104871803-blog-123886825.pc_relevant_default\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-104871803-blog-123886825.pc_relevant_default\u0026amp;utm_relevant_index=6\nBERT-ä½¿ç”¨tfç”Ÿæˆpytorch_model.bin https://www.freesion.com/article/9725381185/\nPyTorchä¹‹nn.ReLUä¸F.ReLUçš„åŒºåˆ« https://blog.csdn.net/u011501388/article/details/86602275\nPytorchå…¥é—¨æ•™ç¨‹ï¼ˆåï¼‰ï¼šResNetå›¾ç‰‡åˆ†ç±»å®æˆ˜ https://blog.csdn.net/weixin_43472830/article/details/95871258?spm=1001.2101.3001.6650.3\u0026amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-95871258-blog-107028785.pc_relevant_default\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-95871258-blog-107028785.pc_relevant_default\u0026amp;utm_relevant_index=5\npytorchç‰ˆyolov3è®­ç»ƒè‡ªå·±æ•°æ®é›† https://www.cnblogs.com/pprp/p/10863496.html\nhttps://github.com/BobLiu20/YOLOv3_PyTorch\nhttps://github.com/cxjaicj/keras-yolo3\nhttps://github.com/pprp/yolov3.keras\nImportError:æ— æ³•ä»â€œtensorflowâ€å¯¼å…¥åç§°â€œSessionâ€ https://www.cnpython.com/qa/1297701\nAdamä¼˜åŒ–ç®—æ³•è¯¦ç»†è§£æ https://blog.csdn.net/luoxuexiong/article/details/90412213\nhttps://www.cnblogs.com/wuchengze/p/13610500.html\nç†è§£è¯­è¨€çš„ Transformer æ¨¡å‹ https://tensorflow.google.cn/tutorials/text/transformer\nCLIPè§£è¯»-åšå®¢å›­ https://www.cnblogs.com/lxmj/p/15945772.html\nä½¿ç”¨Pytorchæ¡†æ¶è‡ªå·±åˆ¶ä½œåšæ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ï¼ˆä¸€ï¼‰ https://blog.csdn.net/zwy_697198/article/details/123561769\nä½¿ç”¨Pytorchæ¡†æ¶è‡ªå·±åˆ¶ä½œåšæ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ï¼ˆäºŒï¼‰ https://blog.csdn.net/zwy_697198/article/details/123587399\nä½¿ç”¨Pytorchæ¡†æ¶è‡ªå·±åˆ¶ä½œåšæ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ï¼ˆä¸‰ï¼‰ https://blog.csdn.net/zwy_697198/article/details/123584396\nPytorch è¿è¡Œé”™è¯¯ ValueError: too many dimensions â€˜strâ€™ è§£å†³æ–¹æ¡ˆ https://www.cnblogs.com/ZhangHT97/p/13497169.html\nä¸€æ–‡å¼„æ‡‚pytorchæ­å»ºç½‘ç»œæµç¨‹+å¤šåˆ†ç±»è¯„ä»·æŒ‡æ ‡ https://cloud.tencent.com/developer/article/1825669\nPytorch åˆ›å»ºTensor https://blog.csdn.net/weicao1990/article/details/93495523\npapers Vision Transformer å¿…è¯»ç³»åˆ—ä¹‹å›¾åƒåˆ†ç±»ç»¼è¿°(ä¸€)ï¼šæ¦‚è¿° https://zhuanlan.zhihu.com/p/459828118\né¢å‘å¤šåœºæ™¯ä½èµ„æºåŠ å¯†æµé‡åˆ†ç±»çš„åŠ å¯†æµé‡é¢„è®­ç»ƒæŠ€æœ¯ https://zhuanlan.zhihu.com/p/483285843\nè·¨æ¨¡æ€æ£€ç´¢ Iterative Matching with Recurrent Attention Memory for Cross-Modal Image-Text Retrieval â€¦","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"029b0762cd79953e0d48cf025045c3f0","permalink":"https://dante-su.github.io/notes/links/others/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/links/others/","section":"notes","summary":"Links for dealing with specific situation when debugging.\n","tags":["Links"],"title":"Others","type":"book"},{"authors":null,"categories":null,"content":"Pytorch documents\nInstallation See more at Pytorch official website: link\nAn instance For CUDA 11.3\nconda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -c conda-forge If you are at Mainland of China, you may need TsingHuaâ€™s source\nAddress\nhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/\nhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/\ncommand\nconda install cudatoolkit=11.3 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/ conda install pytorch torchvision torchaudio -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ Be patient here to ensure the version of Pytorch to install is GPU. Check the status of installation Type python in command/bash.\nAnd input the command below.\nimport torch torch.cuda.is_available() torch.cuda.get_device_name() torch.__version__ torch.cuda.device_count() Usage torch.cuda.empty_cache() As there is cache in Pytorch, even when a tensor is set free, the thread wonâ€™t give the occupied GPU memory back to GPU but wait for next tensor to occupy this part of GPU memory, which could apparently affect the efficiency of GPU memoryâ€™s allocation.\nAs an example, it could be add like the below code instance.\nfor i, data in enumerate(data_loader): torch.cuda.empty_cache() img_meta = data[\u0026#39;img_meta\u0026#39;][0].data[0] img_name = img_meta[0][\u0026#39;filename\u0026#39;].split(\u0026#39;/\u0026#39;)[-1] with torch.no_grad(): result = model(return_loss=False, rescale=not show, **data) torch.flatten å±•å¹³ä¸€ä¸ªè¿ç»­èŒƒå›´çš„ç»´åº¦ï¼Œè¾“å‡ºç±»å‹ä¸ºTensor\nt = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]]) #å½“å¼€å§‹ç»´åº¦ä¸º0ï¼Œæœ€åç»´åº¦ä¸º-1ï¼Œå±•å¼€ä¸ºä¸€ç»´ torch.flatten(t) # output = tensor([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) #å½“å¼€å§‹ç»´åº¦ä¸º0ï¼Œæœ€åç»´åº¦ä¸º-1ï¼Œå±•å¼€ä¸º3x4ï¼Œä¹Ÿå°±æ˜¯è¯´ç¬¬ä¸€ç»´åº¦ä¸å˜ï¼Œåé¢çš„å‹ç¼© torch.flatten(t, start_dim=1) # tensor([[ 1, 2, 3, 4], # [ 5, 6, 7, 8], # [ 9, 10, 11, 12]]) #ä¸‹é¢çš„å’Œä¸Šé¢è¿›è¡Œå¯¹æ¯”åº”è¯¥å°±èƒ½çœ‹å‡ºæ˜¯ï¼Œå½“é”å®šæœ€åçš„ç»´åº¦çš„æ—¶å€™ #å‰é¢çš„å°±ä¼šåˆå¹¶ torch.flatten(t, start_dim=0, end_dim=1) # tensor([[ 1, 2], # [ 3, 4], # [ 5, 6], # [ 7, 8], # [ 9, 10], # [11, 12]]) start_dim: first dim to flatten (default = 1).\nend_dim: last dim to flatten (default = -1).\nå¦‚æ— æŒ‡å®šï¼Œè¯¥å±•å¹³å±‚ä¼šå°†é™¤äº†ç¬¬0ç»´åº¦ï¼ˆä¸€èˆ¬æ˜¯batch_sizeï¼‰ä»¥å¤–çš„æ‰€æœ‰ç»´åº¦å±•å¼€æˆä¸€ç»´çŸ©é˜µ\ntorch.grad # æ¸…é™¤ä»¥å‰çš„æ¢¯åº¦ x.grad.data.zero_() torch.matmul tensorçš„çŸ©é˜µä¹˜æ³•\ne.g.\nimport torch print(torch.matmul(torch.ones(3,4), torch.ones(4,2)).shape) torch.size([3,2])\ntensorç»´åº¦ä¸åŒæ—¶ï¼Œ ç»´åº¦å¤šå‡ºæ¥çš„çœ‹ä½œbatchï¼Œå…¶ä½™å†ç›¸ä¹˜ import torch print(torch.matmul(torch.ones(5,3,4), torch.ones(4,2)).shape) torch.size([5,3,2])\næ ¹æ®broadcaståŸåˆ™ï¼Œé¦–ä½ä¸åŒæ—¶ï¼Œåº”è¯¥å°†å°‘çš„broadcastæˆå¤šçš„ import torch print(torch.matmul(torch.ones(2,5,3), torch.ones(1,3,4)).shape) torch.size([2,5,4])\nç»´åº¦ä¸åŒ+æå‡ºbatchåé¦–ä½ä»ä¸åŒ import torch print(torch.matmul(torch.ones(2,1,3,4), torch.ones(5,4,2)).shape) torch.size([2,5,3,2])\ntorch.nn.Flatten ä¸€èˆ¬ç”¨äºnetworkçš„å®šä¹‰\ntorch.nn.module.apply å°†ä¸€ä¸ªå‡½æ•°fné€’å½’åœ°åº”ç”¨åˆ°æ¨¡å—è‡ªèº«ä»¥åŠè¯¥æ¨¡å—çš„æ¯ä¸€ä¸ªå­æ¨¡å—(å³åœ¨å‡½æ•°.children()ä¸­è¿”å›çš„å­æ¨¡å—).è¯¥æ–¹æ³•é€šå¸¸ç”¨æ¥åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹ä¸­çš„å‚æ•°(å¦è§torch-nn-initéƒ¨åˆ†çš„å†…å®¹).\nnet = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): print(m) if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights); torch.nn.module.parameters import torch import torch.nn as nn class mymodule(nn.Module): def __init__(self): super(mymodule,self).__init__() self.linear=nn.Linear(2,3) self.relu=nn.ReLU() def forward(self,x): x=self.linear(x) x=self.relu(x) return x model=mymodule() print(\u0026#34;æ¨¡å‹å‚æ•°ï¼š\u0026#34;,list((model.parameters()))) for param in model.parameters(): print(\u0026#34;å‚æ•°ç±»å‹ï¼š\u0026#34;,type(param),\u0026#34;å‚æ•°å¤§å°ï¼š\u0026#34;,param.size()) torch.numel æ˜¾ç¤ºtensorä¸­å…ƒç´ çš„ä¸ªæ•°\nimport torch a = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) print(a.numel()) # 6 torch.set_printoptions import torch torch.set_printoptions(profile=\u0026#34;full\u0026#34;) torch.shape import torch a = torch.rand(3,4) print(\u0026#39;a.shape = \u0026#39;, a.shape) print(\u0026#39;a.shape[0] = \u0026#39;, a.shape[0]) torch.tensor.flatten Equal to torch.flatten\nOthers Print nn.Module For a network as a class of nn.Module as below,\nimport torch from torch import nn class testModel(nn.Module): def __init__(self): super(testModel,self).__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, bias=False) self.relu1 = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, bias=False) self.relu2 = nn.ReLU(inplace=True) self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, bias=False) def forward(self, x): out = self.conv1(x) out = self.relu1(out) out = self.conv2(out) out = self.relu2(out) out = self.conv3(out) return out To print it out to check the structure of network, we could use code like below,\nmodel = testModel() print(model) Result will be:\ntestModel( (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), bias=False) (relu1): ReLU(inplace=True) (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), bias=False) (relu2): ReLU(inplace=True) (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False) ) Or using torch-summary to check, like below\npin install torch-summary\nfrom torchsummary import summary model = testModel() summary(model, (3, 224, 224)) Result will be: â€¦","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"0f3c42271133bb745150a332e1acf0fa","permalink":"https://dante-su.github.io/notes/python/pytorch/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/python/pytorch/","section":"notes","summary":"Pytorch documents\n","tags":["Pytorch","python"],"title":"Pytorch","type":"book"},{"authors":null,"categories":null,"content":"Some documents of docker\nTable of Contents Updating Bugs record Opencv ImportError Updating Bugs record Opencv ImportError ImportError: libGL.so.1: cannot open shared object file: No such file or directory If you install opencv by pip install opencv-python before, you could use the below method.\npip uninstall opencv-python\npip install opencv-python-headless\n","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"506892610f251070d8f0894a92eff1da","permalink":"https://dante-su.github.io/notes/shell/docker/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/shell/docker/","section":"notes","summary":"Some documents of docker\n","tags":["Docker"],"title":"Docker","type":"book"},{"authors":null,"categories":null,"content":"Notes\nUsage Static forwarding in LAN hugo server --bind 192.168.1.107 --baseURL http://192.168.1.107/\nLinks hugoä¸»é¢˜æ–‡æ¡£ https://www.cnblogs.com/brady-wang/p/13830156.html\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"53101f60ef55f0ca67350a7a83a0f14a","permalink":"https://dante-su.github.io/notes/others/hugo/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/hugo/","section":"notes","summary":"Notes\n","tags":["hugo","html"],"title":"hugo","type":"book"},{"authors":null,"categories":null,"content":"Related papers of Computer Graphics\n3DV Detailed Human Avatars from Monocular Video From: 3DV\u0026#39;2018\npaper | code\nWACV SMPLpix: Neural Avatars from 3D Human Models From: WACV\u0026#39;2021\nhomepage | paper | code\nICCV Tex2shape From: ICCV\u0026#39;2019\nhomepage | paper | code\nBackground Generate 3D human body model with details of garment from an RGB image(without depth information)\nMotivation Regression from image pixels directly to 3D mesh displacements is not so good:\nIgnoring the rich illumination and shading information contained in RGB values inputs and outputs are not aligned Novelity propose to regress shape as UV-space displacement and normal map turn a hard full-body shape reconstruction problem into an easier 3D pose-independent image-to-image translation problem Cons the photo must taken from the front pose is strictly to A pose Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis From: ICCV\u0026#39;2019\nhomepage | paper | code | dataset\nThe Power of Points for Modeling Humans in Clothing From: ICCV\u0026#39;2021\nhomepage | paper | code | dataset\nECCV Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image From: ECCV\u0026#39;2016\npaper or paper | code\nBodynet: Volumetric inference of 3D human bodyshapes From: ECCV\u0026#39;2018\nhomepage | paper | code\nCVPR Video Based Reconstruction of 3D People Models From: CVPR\u0026#39;2018\nhomepage | paper | code | dataset\nLearning to reconstruct people in clothing from a single RGB camera From: CVPR\u0026#39;2019\npaper | code\nIntro Max Planck Institute for Informatics, Germany\nOctopus, a learning-based model to infer the personalized 3D shape of people from a few frames (1-8) of a monocular video in which the person is moving with a reconstruction accuracy of 4 to 5mm\nHuman Representation While D here is free-form deformations\nDataset 163 scans fromÂ renderpeople.com 54 fromÂ axyzdesign.com 1826 scans fromÂ Twindom generate synthetic 3D data by non-rigidly registering SMPL+D to each of the scans Method Function4D: Real-time Human Volumetric Capture from Very Sparse Consumer RGBD Sensors From: CVPR\u0026#39;2021\nhomepage | paper | dataset\nHigh-Fidelity Human Avatars from a Single RGB Camera From: CVPR\u0026#39;2022\nhomepage | paper | code | dataset\nIntro A coarse-to-fine framework to reconstruct a personalized high-fidelity human avatar from a monocular video\nA single RGB camera A single video 300 frames A single person Rotate with A-pose relieve the misalignment caused by changed pose and shape in different frames Methods SIGGRAPH PoseVocab: Learning Joint-structured Pose Embeddings for Human Avatar Modeling From: SOGGRAPH\u0026#39;2023 (Conference Track)\nhomepage | paper | code\nICML GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models From: ICML\u0026#39;2022\nhomepage | paper | code\n","date":1702857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702857600,"objectID":"9b15843b5bbe26fbb6728e8dd9c01068","permalink":"https://dante-su.github.io/notes/computer_graphics/papers/","publishdate":"2023-12-18T00:00:00Z","relpermalink":"/notes/computer_graphics/papers/","section":"notes","summary":"Related papers of Computer Graphics\n","tags":["Computer Graphics"],"title":"Related papers","type":"book"},{"authors":null,"categories":null,"content":"Intro of Jupyter notebook\nInstallation pip install jupyter notebook\nWay to use Jupyter notebook from remote server on local device On server conda activate your_env_name\npip install jupyter notebook\njupyter notebook --generate-config\nipython\nfrom notebook.auth import passwd\npasswd()\nThen input the password you like and verify it by secondary input. After that, it will generate a hash file named â€˜jupyter_notebook_config.jsonâ€™. Open it and copy the hash code to your clipboard.\nnano ~/.jupyter/jupyter_notebook_config.py\n(If â€™nanoâ€™ does NOT exist, use â€˜vimâ€™ instead)\nAdd the following codes to the end of just opened â€˜jupyter_notebook_config.pyâ€™ and be aware to substitute the â€˜passwordâ€™ with your generated one in your clipboard.\nc.NotebookApp.ip = \u0026#39;*\u0026#39; # å…è®¸è®¿é—®æ­¤æœåŠ¡å™¨çš„ IPï¼Œæ˜Ÿå·è¡¨ç¤ºä»»æ„ IP c.NotebookApp.password = \u0026#39;argon2:$argon2id$v=19$m=10240,t=10,p=8$QplvWXtYUtp4TlXS1T1urQ$xulqNxrIqlJmCPrBHd7nGA\u0026#39; # ä¹‹å‰ç”Ÿæˆçš„å¯†ç  hash å­—ä¸², ç²˜è´´è¿›å» c.NotebookApp.open_browser = False # è¿è¡Œæ—¶ä¸æ‰“å¼€æœ¬æœºæµè§ˆå™¨ c.NotebookApp.port = 8890 # ä½¿ç”¨çš„ç«¯å£ï¼Œéšæ„è®¾ç½®ï¼Œä½†æ˜¯è¦è®°å¾—ä½ è®¾å®šçš„è¿™ä¸ªç«¯å£ c.NotebookApp.enable_mathjax = True # å¯ç”¨ MathJax c.NotebookApp.allow_remote_access = True #å…è®¸è¿œç¨‹è®¿é—® c.NotebookApp.allow_root = True After above all done, remember the port you set, input the below command to terminal and run. (It could also run in a window generating by â€˜screenâ€™ command)\njupyter notebook\nOn local device ssh -L \u0026lt;local_port\u0026gt;:localhost:\u0026lt;remote_port\u0026gt; user_name@server_ip -p server_port\n(\u0026lt;local_port\u0026gt; and \u0026lt;remote_port\u0026gt; could be set as you wish, e.g. 8890 as a default choice)\njupyter notebook\nThen open the browser and open localhost:\u0026lt;local_port\u0026gt;, e.g. localhost:8890. Input the password you set and you could use jupyter notebook from remote server on your local device.\n","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"6abed0fb078999af7823f5285130e2c6","permalink":"https://dante-su.github.io/notes/python/jupyter/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/python/jupyter/","section":"notes","summary":"Intro of Jupyter notebook\nInstallation pip install jupyter notebook\nWay to use Jupyter notebook from remote server on local device On server conda activate your_env_name\npip install jupyter notebook\njupyter notebook --generate-config","tags":["Python","jupyter"],"title":"Jupyter","type":"book"},{"authors":null,"categories":null,"content":"Notes\nJekyll Links HTMLã€JSä¸PHPä¹‹é—´çš„æ•°æ®ä¼ è¾“ https://juejin.cn/post/6844903684195762184\nhtmlé¡µé¢çš„æ•°æ®åˆ©ç”¨jsæˆ–è€…Ajaxä¼ è¾“åˆ°åå°javaã€php https://blog.csdn.net/tangsl388/article/details/49174083\nå¦‚ä½•ç”¨Htmlï¼Œåœ¨å›¾ç‰‡ä¸Šæ”¾æŒ‰é’® https://zhidao.baidu.com/question/1758081969339588748.html\nFEX https://fex-team.github.io/\nThe Minimal Light Theme of Jekyll https://github.com/yaoyao-liu/minimal-light\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"f2aef9a0ec7751f486919c2346d3ec4a","permalink":"https://dante-su.github.io/notes/others/html/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/html/","section":"notes","summary":"Notes\n","tags":["html"],"title":"HTML","type":"book"},{"authors":null,"categories":null,"content":"Proceedings of ACM SIGGRAPHï¼ˆAsiaï¼‰/ ACM Transactions on Graphics\n2023","date":1711324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711324800,"objectID":"f78c8ca89e2aae72386295f0836de637","permalink":"https://dante-su.github.io/notes/paper_reading/siggraph/","publishdate":"2024-03-25T00:00:00Z","relpermalink":"/notes/paper_reading/siggraph/","section":"notes","summary":"Proceedings of ACM SIGGRAPHï¼ˆAsiaï¼‰/ ACM Transactions on Graphics\n","tags":["siggraph","paper"],"title":"SIGGRAPH","type":"book"},{"authors":null,"categories":null,"content":"Useful links of Computer Graphics\nInfo Related Links SIGGRAPH 2021 https://www.neuralrender.com\nç¥ç»æ¸²æŸ“è¿›å±• SIGGRAPH 2021 Course https://www.bilibili.com/video/BV1dA4y1Q7Wf?spm_id_from=333.337.search-card.all.click\nInstant Neural Graphics Primitives https://github.com/NVlabs/instant-ngp\nç‰©ç†ä»¿çœŸä¸­çš„ç¬¦å·è·ç¦»åœºï¼ˆSDFï¼‰ https://zhuanlan.zhihu.com/p/390625164\nã€è¯‘ã€‘Signed Distance Fields(æœ‰ç¬¦å·çš„è·ç¦»åœº) https://zhuanlan.zhihu.com/p/357606643\nè§†ç½‘è†œRetinaæŠ€æœ¯ https://www.cnblogs.com/constantince/p/15475408.html\nä¸‰ç»´é‡å»ºï¼šåŸºäºRGB-Dç›¸æœºçš„ä¸‰ç»´é‡å»ºæ€»è§ˆ(é™æ€\u0026amp;åŠ¨æ€) https://yongqi.blog.csdn.net/article/details/124893084?spm=1001.2101.3001.6650.14\u0026amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-14-124893084-blog-122227671.pc_relevant_antiscanv3\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-14-124893084-blog-122227671.pc_relevant_antiscanv3\nåŸºäºSfM(Structure from motion)çš„ä¸‰ç»´é‡å»ºè¯¦è§£ https://zhuanlan.zhihu.com/p/29845703\nTaoYU Function4D http://www.liuyebin.com/Function4D/Function4D.html\nåŸºäºslamçš„ä¸‰ç»´é‡å»º_åŸºäºå›¾åƒçš„ä¸‰ç»´æ¨¡å‹é‡å»ºâ€”â€”åŸºç¡€ä»‹ç» https://blog.csdn.net/weixin_32236415/article/details/112173089\nSLAMå’Œä¸‰ç»´é‡å»ºæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ https://www.zhihu.com/question/64011093\nSLAMç³»åˆ—(ä¸€)ï¼šå…¥é—¨ä»‹ç» https://www.jianshu.com/p/a9579f469f84\nRigNetç¥ç»ç½‘ç»œæ¨¡å‹è‡ªåŠ¨ç»‘å®šéª¨éª¼ https://blog.csdn.net/u012863565/article/details/121585109\næ“çºµåŠ é²é²å…½çš„æœºä¼šï¼šSIGGRAPHè®ºæ–‡æå‡ºRigNetå¸®åŠ¨ç”»å¸ˆåšéª¨æ¶ç»‘å®š https://baijiahao.baidu.com/s?id=1666380413991389665\u0026amp;wfr=spider\u0026amp;for=pc\nCode for neuralbody https://github.com/zju3dv/neuralbody\nCode for humannerf https://github.com/chungyiweng/humannerf\nCode for easymocap https://github.com/zju3dv/EasyMocap\nå•¥æ˜¯KinectFusion https://zhuanlan.zhihu.com/p/39021659\nå•¥æ˜¯DynamicFusion https://zhuanlan.zhihu.com/p/39252239\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"b30f039c94c36498936fd1ecf4d9c23a","permalink":"https://dante-su.github.io/notes/computer_graphics/useful_links/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/computer_graphics/useful_links/","section":"notes","summary":"Useful links of Computer Graphics\n","tags":["links"],"title":"Useful links","type":"book"},{"authors":null,"categories":null,"content":"Installation method and usage of WSL on Windows\nTable of Contents Installation Usage See the installed Linux distribution See the available versions to install Install multipie Linux distribution Import the distribution Export the distribution Remove the distribution Change default Linux distribution Shut down all the distributions Shut down specific distribution Update wsl Check the status of wsl Check the version of wsl Check IP address Open help menu Start up from /home/user Exit the running wsl Open VS Code via WSL Adjust wsl version Mount the disk Unmount the disk Map USB device from Windows to Linux Installation on windows Installation on Liunx Usage Install multipie wsl distributions Install cuda in wsl Installation Mircosoft official document\nwsl --install\nUsage See the installed Linux distribution wsl --list --verbose or wsl -l -v\nSee the available versions to install wsl --list --online or wsl -l -v\nInstall multipie Linux distribution wsl --install -d \u0026lt;distribution_name\u0026gt;\nImport the distribution wsl --import \u0026lt;distribution_name\u0026gt; \u0026lt;install_location\u0026gt; \u0026lt;file_name\u0026gt;\nExport the distribution wsl --export \u0026lt;distribution_name\u0026gt; \u0026lt;file_name\u0026gt;\nRemove the distribution wsl --unregister \u0026lt;distribution_name\u0026gt;\nChange default Linux distribution wsl --set-default \u0026lt;distribution_name\u0026gt;\nShut down all the distributions wsl --shutdown\nShut down specific distribution wsl --terminate \u0026lt;distribution_name\u0026gt;\nUpdate wsl wsl --update\nCheck the status of wsl wsl --status\nCheck the version of wsl wsl --version\nCheck IP address The address of Linux\nwsl hostname -i\nThe address of Windows\ncat /etc/resolv.conf\nOpen help menu wsl --help\nStart up from /home/user wsl ~\nExit the running wsl Press Ctrl+A+D at the same time\nOpen VS Code via WSL code .\nAdjust wsl version wsl --set-version \u0026lt;distribution_name\u0026gt; \u0026lt;version_number\u0026gt;\n\u0026lt;version_number\u0026gt; here is 1 or 2\nMount the disk wsl --mount \u0026lt;disk_path\u0026gt;\nUnmount the disk wsl --unmount \u0026lt;disk_path\u0026gt;\nMap USB device from Windows to Linux Mircosoft Document\nCSDN link\nInstallation on windows Open usbipd-win and download the up-to-date released .msi file Install the downloaded file Installation on Liunx sudo apt install linux-tools-generic hwdata\nsudo update-alternatives --install /usr/local/bin/usbip usbip /usr/lib/linux-tools/*-generic/usbip 20\nUsage Open PowerShell and type in usbipd wsl list to check all the connected USB device Find the busid of needed device and type usbipd wsl attach --busid \u0026lt;busid\u0026gt; in PowerShell Open WSL and type in lsusb to check if the need device has connected to the wsl or not When we need to disconnect the needed device from wsl, type usbipd wsl detach --busid \u0026lt;busid\u0026gt; Install multipie wsl distributions Install wsl2 with wsl --install Open ubuntu wsl2 images and download an image of needed version Open PowerShell and type in wsl --import \u0026lt;Distribution Name\u0026gt; \u0026lt;Installation Folder\u0026gt; \u0026lt;Ubuntu WSL2 Image Tarball path\u0026gt; Type wsl -l -v to check if the installation is successful or not Use wsl -d \u0026lt;distribution_name\u0026gt; to login the distribution we just installed Type in NEW_USER=\u0026lt;USERNAME\u0026gt; to create a new account Input useradd -m -G sudo -s /bin/bash \u0026#34;$NEW_USER\u0026#34; + passwd \u0026#34;$NEW_USER\u0026#34; and set a password for our new account Input the code below to set our new user as the default one tee /etc/wsl.conf \u0026lt;\u0026lt;_EOF [user] default=${NEW_USER} _EOF Press Ctrl + A + D at the same time to exit the distribution Input wsl --terminate \u0026lt;distribution_name and wsl -d \u0026lt;distribution_name\u0026gt; to restart the installed distribution And find that we succeed in creating a new distribution Install cuda in wsl NVIDIA Documents\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.2.2/local_installers/cuda-repo-wsl-ubuntu-12-2-local_12.2.2-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-2-local_12.2.2-1_amd64.deb\nsudo cp /var/cuda-repo-wsl-ubuntu-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/\nsudo apt-get update\nsudo apt-get -y install cuda\nsudo ln -s /usr/lib/wsl/lib/libcuda.so.1 /usr/local/cuda/lib64/libcuda.so\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"b88825683d8fe137cf717a115aa8509f","permalink":"https://dante-su.github.io/notes/shell/wsl/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/notes/shell/wsl/","section":"notes","summary":"Installation method and usage of WSL on Windows\n","tags":["Windows","wsl"],"title":"WSL","type":"book"},{"authors":null,"categories":null,"content":"Usage and debug experience of â€˜Gitâ€™\nTable of Contents Installation Usage Clone push pull .gitignore Installation Usage Clone git clone \u0026lt;repo_address\u0026gt;\npush cd path/to/repo\ngit add .\ngit commit -m \u0026#39;\u0026lt;update_info\u0026gt;\u0026#39;\ngit push\npull cd path/to/repo\ngit push\n.gitignore cd path/to/repo touch .gitignore git rm --cached \u0026lt;file_name\u0026gt; # For those already in repo Example:\nFor repo used on Mac system, there is always a srange file called .DS_Store added. So we could add the lines below to .gitignore file to avoid this.\n.DS_Store **/.DS_Store .DS_Store? ","date":1714089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714089600,"objectID":"2d957f04dd33744c01494659f3949d35","permalink":"https://dante-su.github.io/notes/shell/git/","publishdate":"2024-04-26T00:00:00Z","relpermalink":"/notes/shell/git/","section":"notes","summary":"Usage and debug experience of â€˜Gitâ€™\n","tags":["git"],"title":"Git","type":"book"},{"authors":null,"categories":null,"content":"Numpy in Python\nInstallation conda install numpy\npip install numpy\nUsage np.array import numpy as np a = np.array([[1,2,3],[4,5,6]]) cumsum # Obtain the cumulative sum value of whole array print(a.cumsum()) # [ 1 3 6 10 15 21] # Obtain the cumulative sum value along given axis print(a.cumsum(axis=0)) # [[1 2 3] [5 7 9]] print(a.cumsum(axis=1)) # [[ 1 3 6] [ 4 9 15]] max/min # Obatin the max/min item print(a.max()) # 6 print(a.min()) # 1 # Obtain the max/min row along given axis print(a.max(axis=0)) # [4 5 6] print(a.max(axis=1)) # [3 6] # Localize the max item print(a.argmax(axis=1)) # [2 2] mean # Obtain the mean value of whole array print(a.mean()) 3.5 # Obtain the mean value along given axis print(a.mean(axis=0)) # [ 2.5 3.5 4.5] print(a.mean(axis=1)) # [ 2. 5.] median # Obtain the median value of whole array print(np.median(x)) # 3.5 # Obtain the median value along given axis print(np.median(x,axis=0)) # [ 2.5 3.5 4.5] print(np.median(x,axis=1)) # [ 2. 5.] std std() is equal to sqrt(mean(abs(x - x.mean())**2)) or sqrt(x.var())\n# Obtain the standard deviation value of whole array print(a.std()) # 1.70782512766 # Obtain the standard deviation value along given axis print(a.std(axis=0)) # [ 1.5 1.5 1.5] print(a.std(axis=1)) # [ 0.81649658 0.81649658] sum # Obtain the sum value of whole array print(a.sum()) # 21 # Obtain the sum value along given axis print(a.sum(axis=0)) # [5 7 9] print(a.sum(axis=1)) # [ 6 15] var # Obtain the variance value of whole array print(a.var()) # 2.91666666667 # Obtain the variance value along given axis print(a.var(axis=0)) # [ 2.25 2.25 2.25] print(a.var(axis=1)) # [ 0.66666667 0.66666667] np.append import numpy as np # for a list [] a = [] a.append([1,2,3]) # for a np.ndarray b = np.asarray([]) b = np.append(b, [1,2,3], axis=0) np.asarray import numpy as np a = list() b = np.asarray(a) # type(b) = np.ndarray np.max import numpy as np a = np.arange(9).reshape(3,-1) b = np.max(a, axis=0) c = np.max(a, axis=1) print(a,\u0026#39;\\n\u0026#39;,b,\u0026#39;\\n\u0026#39;,c) np.power(x1, x2) x1 = range(6) print(x1) # [0, 1, 2, 3, 4, 5] print(np.power(x1, 3)) # array([ 0, 1, 8, 27, 64, 125]) x2 = [1.0, 2.0, 3.0, 3.0, 2.0, 1.0] print(np.power(x1, x2)) # array([ 0., 1., 8., 27., 16., 5.]) x2 = np.array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) print(x2) # array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) print(np.power(x1, x2)) # array([[ 0, 1, 8, 27, 16, 5], [ 0, 1, 8, 27, 16, 5]]) np.set_printoptions import numpy as np np.set_printoptions(threshold=np.inf) np.shape import numpy as np a = np.array([[1,1,3],[4,5,6]]) print(\u0026#39;a.shape = \u0026#39;, a. shape) np.sum np.sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue)\nimport numpy as np a = np.random.randint(-5, 5, (1, 10)) print (str(a)) # [[ 2 -3 -5 -4 3 -5 0 -1 4 3]] c=np.sum(a) # Obtain the sum of all items in an array print (str(c)) # -6 c=np.sum(a\u0026gt;=1) # Obtain the number of qualified items in an array print (str(c)) # 4 np.where import numpy as np a = np.arange(9).reshape(3,-1) b = np.where(a ==7) print(b) Others Matrix multiplication import numpy as np a = np.array([[1,2], [3,4]]) b = np.array([[5,6], [7,8]]) print(a*b) # array([[ 5, 12], [21, 32]]) print(a.dot(b)) # array([[19, 22], [43, 50]]) print(np.dot(a,b)) # array([[19, 22], [43, 50]]) print(np.dot(b,a)) # array([[23, 34], [31, 46]]) ","date":1712620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712620800,"objectID":"6a2c139ebf1fbf73d19a3607e9e355c6","permalink":"https://dante-su.github.io/notes/python/numpy/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/notes/python/numpy/","section":"notes","summary":"Numpy in Python\nInstallation conda install numpy\npip install numpy\nUsage np.array import numpy as np a = np.array([[1,2,3],[4,5,6]]) cumsum # Obtain the cumulative sum value of whole array print(a.cumsum()) # [ 1 3 6 10 15 21] # Obtain the cumulative sum value along given axis print(a.","tags":["Python","Numpy"],"title":"Numpy","type":"book"},{"authors":null,"categories":null,"content":"Notes\nPython Move multipie lines right/left Left Select the needed content and press Tab\nRight Select the needed content and press Shift and Tab at the same time\nColab https://colab.research.google.com/github/iErics/gd-utils/blob/master/Colab_gd_utils.ipynb\nfunction ConnectButton(){ console.log(\u0026#34;Connect pushed\u0026#34;); document.querySelector(\u0026#34;#connect\u0026#34;).click() } setInterval(ConnectButton,60000); Use visdom over remote server This note is for those who need run their codes on remote server but finding that they could NOT be able to get access to visdomâ€™s monitor as before. So we need to mapping the service of visdom to our local workspace over the remote server.\nSteps:\nOpen the remote server and type tmux new -s \u0026lt;session-name\u0026gt; to open a new backstage process (screen could does this too) Activate the specific conda env you are using (if your code runs on conda env) and type python -m visdom.server to open a local visdom server Open the terminal of local device and type ssh -L 8097:127.0.0.1:8097 \u0026lt;username\u0026gt;@\u0026lt;server_address\u0026gt; or ssh -L 8097:localhost:8097 \u0026lt;username\u0026gt;@\u0026lt;server_address\u0026gt; while 8097 is as an example of port id. When you successfully get access to your remote server, open the page 127.0.0.1:8097 or localhost:8097 When you want to terminate the visdomâ€™s mapping, just kill the process of visdom on the remote server, e.g. tmux kill-session -t \u0026lt;session-name\u0026gt;\nWindows Set clock into UTC mode Make Windows 10â€™s BIOS hardware time treat Coordinated Universal Time (UTC) by changing the registry value RealTimeIsUniversal key\nWith Regedit Press Win + R at the same time Input regedit and press Enter Find the path \\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation Set RealTimeIsUniversal to 1 if this value already exists. New a QWORD(for system of 32-bit, use DWORD instead) variable with a name of RealTimeIsUniversal and whose value could also be set as 1 With PowerShell Open terminal with Administrator rights Input reg add \u0026#34;HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TimeZoneInformation\u0026#34; /v RealTimeIsUniversal /d 1 /t REG_QWORD /f (for system of 32-bit, use DWORD instead) Press Enter Using multi-moniter to view same project in VS Code Ctrl + Shift + P and input the content below:\nWorkspace: Duplicate As Workspace in New Window\nThe installation of Windows11 is stuck by connecting to network Press Shift+F10 to open a terminal. Input oobe\\bypassnro The computer will restart soon and there will be an option for â€˜I havenâ€™t Interest to connectâ€™\n","date":1712016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712016000,"objectID":"403ac75c41d2810d1ba3d680df5a18e2","permalink":"https://dante-su.github.io/notes/others/messy/","publishdate":"2024-04-02T00:00:00Z","relpermalink":"/notes/others/messy/","section":"notes","summary":"Notes\n","tags":["windows","python"],"title":"Messy","type":"book"},{"authors":null,"categories":null,"content":"The Annual Conference on Neural Information Processing System\n2023","date":1711324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711324800,"objectID":"d437909b880e8981c20dc12ebef08aa7","permalink":"https://dante-su.github.io/notes/paper_reading/neurips/","publishdate":"2024-03-25T00:00:00Z","relpermalink":"/notes/paper_reading/neurips/","section":"notes","summary":"The Annual Conference on Neural Information Processing System\n","tags":["neurips","paper"],"title":"NeurIPS","type":"book"},{"authors":null,"categories":null,"content":"OS package in Python\nos.access() import os if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.F_OK): print \u0026#34;Given file path is exist.\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.R_OK): print \u0026#34;File is accessible to read\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.W_OK): print \u0026#34;File is accessible to write\u0026#34; if os.access(\u0026#34;/file/path/foo.txt\u0026#34;, os.X_OK): print \u0026#34;File is accessible to execute\u0026#34; os.listdir import os path = \u0026#39;/home/dante/file\u0026#39; file_list = os.listdir(path) # list print(file_list) os.path.exists() For folder\nimport os os.path.exists(test_dir) #True os.path.exists(no_exist_dir) #False For file\nimport os os.path.exists(test_file.txt) #True os.path.exists(no_exist_file.txt) #False os.path.isfile() To check a file exists or not when there is a folder with the same name.\nimport os os.path.isfile(\u0026#34;test-data\u0026#34;) os.path.join import os path = \u0026#39;/home/dante\u0026#39; file_name = \u0026#39;example.txt\u0026#39; file_path = os.path.join(path, file_name) print(file_path) os.makedirs import os folder_name = \u0026#39;home/dante/example\u0026#39; os.makedirs(folder_name, mode=511, exist_ok=True) os.rename import os old_name = \u0026#39;/home/dante/old_file.txt\u0026#39; new_name = \u0026#39;/home/dante/new_file.txt\u0026#39; os.rename(old_name, new_name) %06d \u0026#34;/{}\u0026#34;.format(\u0026#39;%06d\u0026#39; % (i)) or\n\u0026#34;/{0:06d}\u0026#34;.format(i) ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"8941e8a6379900a9cbacebb42d1275fa","permalink":"https://dante-su.github.io/notes/python/os/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/python/os/","section":"notes","summary":"OS package in Python\nos.access() import os if os.access(\"/file/path/foo.txt\", os.F_OK): print \"Given file path is exist.\" if os.access(\"/file/path/foo.txt\", os.R_OK): print \"File is accessible to read\" if os.access(\"/file/path/foo.txt\", os.W_OK): print \"File is accessible to write\" if os.","tags":["Python","OS"],"title":"OS","type":"book"},{"authors":null,"categories":null,"content":"ArXiv\n2023","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711497600,"objectID":"cdbed13a7e46ef3f80f2a42a500bec8a","permalink":"https://dante-su.github.io/notes/paper_reading/arxiv/","publishdate":"2024-03-27T00:00:00Z","relpermalink":"/notes/paper_reading/arxiv/","section":"notes","summary":"ArXiv\n","tags":["arxiv","paper"],"title":"ArXiv","type":"book"},{"authors":null,"categories":null,"content":"Other Conference/Journal\nACM MM Proceedings of the ACM International Conference on Multimedia\n2023 MICCAI International Conference in Medical Image Computing and Computer-Assisted Intervention\n2022 Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery [ homepage | paper | code ]\nKeywords: 3D Reconstruction, Neural Rendering, Robotic Surgery\nAim:\nContribution:\nMotivation:\nArchitecture:\nComparison models: Cetin et al.@STACOM\u0026#39;17,\nFront. Inf. Technol. Electron. Eng. Frontiers of Information Technology \u0026amp; Electronic Engineering\n2022 Visual recognition of cardiac pathology based on 3D parametric model reconstruction [ homepage | paper ]\nKeywords: Cardiac, 3D parametric model, Cardiac pathology diagnosis\nAim: Construct and use 3D parametric model as an augmentation to generate heart data for better training a classifier of cardiac pathology.\nContribution:\nConstruct 3D cardiac parametric model for each pathology and apply cardiac visual knowledge of different cardiac pathologies as parameters to generate reasonable 3D cardiac model. Sample 3D cardiac data with changing parameters of 3D cardiac parametric model as an augmentation to avoid class imbalance. Exract cardiac disease-based features and use it to make prediction. Motivation: Almost all the existing method use 2D slices of heart to extract features and make prediction. However, these 2D slices are collected from 3D imaging data, so using 2D slices may largely ignore geometric information characterizing adjacency in the 3D neighbourhood. Besides, after constructing 3D cardiac parametric model, generating reasonable cardiac data by changing the parameters of 3D cardiac model is a good way as data augmentation.\nArchitecture:\nFirst, they reconstruct 3D model from labeled 2D images, based on which they employ Statistical Shape Model(SSM) to obtain 3D cardiac parametric model. Then, after using PCA to determine the bases of the category, they use parameter variation to make prediction. Besides above, they could also random sample the parameters to generate reasonable cardiac data as an augmentation to train a better model for cardiac pathologyâ€™s classification.\nComparison models: Cetin et al.@STACOM\u0026#39;17, Isensee et al.@STACOM\u0026#39;17, Khened et al.@STACOM\u0026#39;17, Wolterink@STACOMâ€˜17, Zheng et al.@MedIA\u0026#39;19, Chang and Jun@NeuroComputing\u0026#39;20, Ammar et al.@Comput Med Imag Graph\u0026#39;21, Thermos@MICCAI\u0026#39;21\n","date":1714003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714003200,"objectID":"c26045854aa18f4bcb0b768f540bf1eb","permalink":"https://dante-su.github.io/notes/paper_reading/others/","publishdate":"2024-04-25T00:00:00Z","relpermalink":"/notes/paper_reading/others/","section":"notes","summary":"Other Conference/Journal\n","tags":["paper"],"title":"Others","type":"book"},{"authors":null,"categories":null,"content":"Other useful package.\nassert a = 1 assert a = 2 # AssertionError: assert a = 2, \u0026#39;a is not equal to 2\u0026#39; # AssertionError: a is not equal to 2 cv2 pip install opencv-python\nhasattr() Check whether a property is in the given class or not\nUsage hasattr(object, name)\nExample #!/usr/bin/python # -*- coding: UTF-8 -*- class Coordinate: x = 10 y = -5 z = 0 point1 = Coordinate() print(hasattr(point1, \u0026#39;x\u0026#39;)) # True print(hasattr(point1, \u0026#39;y\u0026#39;)) # True print(hasattr(point1, \u0026#39;z\u0026#39;)) # True print(hasattr(point1, \u0026#39;no\u0026#39;)) # æ²¡æœ‰è¯¥å±æ€§ False icrawler https://pypi.org/project/icrawler/0.2.2/\nio StringIO Example\nfrom io import StringIO f=StringIO() #åˆ›å»ºå˜é‡æŒ‡å‘å¯¹è±¡ f.write(\u0026#39;hello,\u0026#39;) #å†™å…¥æ•°æ® f.write(\u0026#39; \u0026#39;) f.write(\u0026#39;world.\u0026#39;) print(f.getvalue()) #ä¾æ¬¡æ‰“å°è·å¾—çš„æ•°æ® from io import StringIO #è½½å…¥æ¨¡å— f=StringIO(\u0026#39;hello\\nworld\u0026#39;) #åˆå§‹åŒ–String while True: #åˆ›é€ å¾ªç¯æ¡ä»¶ s=f.readline() #å¯¹fæŒ‡å‘çš„å¯¹è±¡è®°æ€§é€è¡Œè¯»å– if s==\u0026#39;\u0026#39;: #æŒ‡å®šé€€å‡ºå¾ªç¯æ¡ä»¶ï¼Œå³è¯»å–çš„è¡Œæ•°ä¸ºç©º break #é€€å‡ºå¾ªç¯ print(s.strip()) #strip()æ–¹æ³•ç”¨äºç§»é™¤å­—ç¬¦ä¸²å¤´å°¾æŒ‡å®šçš„å­—ç¬¦ï¼ˆé»˜è®¤ä¸ºç©ºæ ¼ï¼‰ã€‚ BytesIO Example\nfrom io import BytesIO f=BytesIO() f.write(\u0026#39;ä¸­æ–‡\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) print(f.getvalue()) \u0026gt;\u0026gt;\u0026gt; b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39; isinstance ç±»ä¼¼type\nåŒºåˆ†ï¼š\ntype() ä¸ä¼šè®¤ä¸ºå­ç±»æ˜¯ä¸€ç§çˆ¶ç±»ç±»å‹ï¼Œä¸è€ƒè™‘ç»§æ‰¿å…³ç³»ã€‚\nisinstance() ä¼šè®¤ä¸ºå­ç±»æ˜¯ä¸€ç§çˆ¶ç±»ç±»å‹ï¼Œè€ƒè™‘ç»§æ‰¿å…³ç³»ã€‚\nmath math.gamma Usage:\n$ math.gamma(n) = (n-1)! $\nmath.sqrt math.sqrt() pandas import pandas as pd dates = pd.date_range(\u0026#39;20130101\u0026#39;, periods=6) df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\u0026#39;ABCD\u0026#39;)) print(df.dtypes) print(df.head()) print(df.tail(3)) print(df.index) print(df.columns) print(df.to_numpy()) print(df.describe()) print(df.T) print(df.sort_index(axis=1, ascending=False)) print(df.sort_values(by=\u0026#39;B\u0026#39;)) print(df[\u0026#39;A\u0026#39;]) print(df[0:3]) print(df.loc[dates[0]]) print(df.loc[:,[\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;]]) print(df.loc[\u0026#39;20130102\u0026#39;:\u0026#39;20130104\u0026#39;,[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;]]) print(df.loc[\u0026#39;20130103\u0026#39;,[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;]]) print(df.loc[dates[0],\u0026#39;A\u0026#39;]) print(df.at[dates[0],\u0026#39;A\u0026#39;]) print(df.iloc[3]) print(df.iloc[3:5,0:2]) print(df.iloc[[1,2,4],[0,2]]) print(df.iloc[3:5,:]) print(df.iloc[3,2]) print(df.iat[3,2]) print(df[df.A \u0026gt; 0]) print(df[df \u0026gt; 0]) df2 = df.copy() df2[\u0026#39;E\u0026#39;] = [\u0026#39;one\u0026#39;,\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;,\u0026#39;three\u0026#39;,\u0026#39;four\u0026#39;,\u0026#39;three\u0026#39;] print(df2[df2[\u0026#39;E\u0026#39;].isin([\u0026#39;two\u0026#39;, \u0026#39;four\u0026#39;])]) s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(\u0026#39;20130102\u0026#39;, periods=6)) df[\u0026#39;F\u0026#39;] = s1 df.at[dates[0], \u0026#39;A\u0026#39;] = 0 df.iat[0, 1] = 0 df.loc[:, \u0026#39;D\u0026#39;] = np.array([5] * len(df)) df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [\u0026#39;E\u0026#39;]) df1.loc[dates[0]:dates[1], \u0026#39;E\u0026#39;] = 1 print(df1) print(df1.dropna(how=\u0026#39;any\u0026#39;)) print(df1.fillna(value=5)) print(pd.isna(df1)) print(df.mean()) print(df.mean(1)) print(df.apply(np.cumsum)) print(df.apply(lambda x: x.max() - x.min())) print(pd.concat([df[:3], df[3,7], df[7:]])) pathlib import pathlib path = pathlib.Path(\u0026#34;path/file\u0026#34;) path.exist() # True/False path = pathlib.Path(\u0026#34;path/file\u0026#34;) path.is_file() round() Usage round( x [, n] )\nx â€“ æ•°å€¼è¡¨è¾¾å¼ã€‚\nn â€“ æ•°å€¼è¡¨è¾¾å¼ï¼Œè¡¨ç¤ºä»å°æ•°ç‚¹ä½æ•°ã€‚\nè¿”å›æµ®ç‚¹æ•°xçš„å››èˆäº”å…¥å€¼\nSkLearn with conda\nconda install scikit-learn\nwith pip\npip3 install scikit-learn\nString operation Delete space in a string s = \u0026#39; a b c \u0026#39; s = s.lstrip() print(s) # This function wil delete the space in the left # Output: \u0026#39;a b c \u0026#39; s = \u0026#39; a b c \u0026#39; s = s.rstrip() print(s) # This function wil delete the space in the right # Output: \u0026#39; a b c\u0026#39; s = \u0026#39; a b c \u0026#39; s = s.strip() print(s) # This function wil delete the space in both left and right # Output: \u0026#39;a b c\u0026#39; s = \u0026#39; a b c \u0026#39; s = s.replace(\u0026#39; \u0026#39;,\u0026#39;\u0026#39;) print(s) # This function wil delete all the space in the string # Output: \u0026#39;abc\u0026#39; s = \u0026#39; a b c \u0026#39; s = \u0026#39;\u0026#39;.join(s.split()) print(s) # This method wil delete the space in the left # Output: \u0026#39;abc\u0026#39; tqdm conda install tqdm\npip install tqdm\nExample from time import sleep from tqdm import tqdm for i in tqdm(range(100)): sleep(0.1) try try: f =open() f.close() except FileNotFoundError: print \u0026#34;File is not found.\u0026#34; except PersmissionError: print \u0026#34;You don\u0026#39;t have permission to access this file.\u0026#34; or\ntry: f =open() f.close() except IOError: print \u0026#34;File is not accessible.\u0026#34; yield #!/usr/bin/python # -*- coding: UTF-8 -*- def fab(max): n, a, b = 0, 0, 1 while n \u0026lt; max: yield b # ä½¿ç”¨ yield # print b a, b = b, a + b n = n + 1 for n in fab(5): print n Above code is equal to the below one.\n#!/usr/bin/python # -*- coding: UTF-8 -*- class Fab(object): def __init__(self, max): self.max = max self.n, self.a, self.b = 0, 0, 1 def __iter__(self): return self def next(self): if self.n \u0026lt; self.max: r = self.b self.a, self.b = self.b, self.a + self.b self.n = self.n + 1 return r raise StopIteration() for n in Fab(5): print n f.next() For generator with function â€˜yieldâ€™, e.g. Fab() coule be used with f = fab(5), f.next()\nJudge a function is a generator or not from inspect import isgeneratorfunction isgeneratorfunction(fab) True import types isinstance(fab, types.GeneratorType) False isinstance(fab(5), types.GeneratorType) True from collections import Iterable isinstance(fab, Iterable) False isinstance(fab(5), Iterable) True ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"6158e3d0209c3389ec52b09c9256c213","permalink":"https://dante-su.github.io/notes/python/others/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/notes/python/others/","section":"notes","summary":"Other useful package.\n","tags":[null],"title":"Others","type":"book"},{"authors":null,"categories":null,"content":"In the field of mathematics, we always need to use proper, suitable and standard written format to express our solution for the given mathematical question. The below are some frequently used written mathematical manners and formats.\nCited from https://www.zhihu.com/question/21793184\nLists of usually-used words ä¸­æ–‡ English è§£ SOLUTIONsol è¯æ˜ PROOFpf å› ä¸º Since æ‰€ä»¥ So å³ i.e.id est(Latin) ç”±æ­¤å¾—çŸ¥ Consequently/Therefore/Thus/Hence ä½¿â€¦æ»¡è¶³ s.t.subject to/such that å‡è®¾ Suppose å½“ä¸”ä»…å½“ iffIf and only if ä»¤/è®¾ Let åŒç† Similarly æ­¤å¤– Morever ä¸” And è¿™è¡¨æ˜â€¦ This implies thatâ€¦ ç»¼ä¸Šæ‰€è¿° Summarizing å¾—å‡ºâ€¦çš„ç»“è®º We conclude thatâ€¦ è¯æ¯•è¯æ˜å®Œæ¯• Q.E.D.quod erat demonstrandum(Latin) Example from the book Calculus written by Prof. Michael Spivak ","date":1714089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714089600,"objectID":"4ec91ee1e38108f9beb410d79fae1a77","permalink":"https://dante-su.github.io/post/24-04-26-standard-math-format/","publishdate":"2024-04-26T00:00:00Z","relpermalink":"/post/24-04-26-standard-math-format/","section":"post","summary":"In the field of mathematics, we always need to use proper, suitable and standard written format to express our solution for the given mathematical question. The below are some frequently used written mathematical manners and formats.\n","tags":null,"title":"Standard written mathematical format","type":"post"},{"authors":null,"categories":null,"content":"In the field of mathematics, norms are defined for elements within a vector space. Specifically, when the vector space comprises matrices, such norms are referred to as matrix norms. Matrix norms differ from vector norms in that they must also interact with matrix multiplication.\nFrobenius norm Defination The Frobenius norm, sometimes also called the Euclidean norm (a term unfortunately also used for the vector $L^2$-norm), is matrix norm of an mÃ—n matrix A defined as the square root of the sum of the absolute squares of its elements.\n$$ \\Vert A \\Vert_{F} = \\sqrt{\\sum_{i=1}^{m}{\\sum_{j=1}^{n}{\\vert a_{i,j} \\vert^{2}}}} $$\nhe Frobenius norm can also be considered as a vector norm.\nIt is also equal to the square root of the matrix trace of $AA^H$, where $A^H$ is the conjugate transpose, i.e.,\n$$ \\Vert A \\Vert_{F}=\\sqrt{Tr(AA^H)} $$\nThe Frobenius norm of a matrix m is implemented as Norm[m, â€œFrobeniusâ€] and of a vector v as Norm[v, â€œFrobeniusâ€].\n","date":1713916800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713916800,"objectID":"3288f452d4af04c0bf39eda6a96932c5","permalink":"https://dante-su.github.io/post/24-04-24-norm/","publishdate":"2024-04-24T00:00:00Z","relpermalink":"/post/24-04-24-norm/","section":"post","summary":"In the field of mathematics, norms are defined for elements within a vector space. Specifically, when the vector space comprises matrices, such norms are referred to as matrix norms. Matrix norms differ from vector norms in that they must also interact with matrix multiplication.\n","tags":null,"title":"Norms","type":"post"},{"authors":null,"categories":null,"content":"Fully-connected Layer å¯¹äºçº¿æ€§å›å½’ï¼Œæ¯ä¸ªè¾“å…¥éƒ½ä¸æ¯ä¸ªè¾“å‡ºç›¸è¿ï¼Œæˆ‘ä»¬å°†è¿™ç§å˜æ¢æˆä¸ºå…¨è¿æ¥å±‚ï¼ˆfully-connected layerï¼‰æˆ–ç§°ä¸ºç¨ å¯†å±‚ï¼ˆdense layerï¼‰ã€‚\nKey points in deeping learning æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„å…³é”®è¦ç´ æ˜¯è®­ç»ƒæ•°æ®ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–ç®—æ³•ï¼Œè¿˜æœ‰æ¨¡å‹æœ¬èº«ã€‚\nç®€å•æ€§ ç®€å•æ€§çš„å¦ä¸€ä¸ªè§’åº¦æ˜¯å¹³æ»‘æ€§ï¼Œå³å‡½æ•°ä¸åº”è¯¥å¯¹å…¶è¾“å…¥çš„å¾®å°å˜åŒ–æ•æ„Ÿã€‚ ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»æ—¶ï¼Œæˆ‘ä»¬é¢„è®¡å‘åƒç´ æ·»åŠ ä¸€äº›éšæœºå™ªå£°åº”è¯¥æ˜¯åŸºæœ¬æ— å½±å“çš„ã€‚ 1995å¹´ï¼Œå…‹é‡Œæ–¯æ‰˜å¼—Â·æ¯•æ™“æ™®è¯æ˜äº† å…·æœ‰è¾“å…¥å™ªå£°çš„è®­ç»ƒç­‰ä»·äºTikhonovæ­£åˆ™åŒ– (Bishop, 1995)ã€‚ è¿™é¡¹å·¥ä½œç”¨æ•°å­¦è¯å®äº†â€œè¦æ±‚å‡½æ•°å…‰æ»‘â€å’Œâ€œè¦æ±‚å‡½æ•°å¯¹è¾“å…¥çš„éšæœºå™ªå£°å…·æœ‰é€‚åº”æ€§â€ä¹‹é—´çš„è”ç³»ã€‚\nIndictors PSNR PSNR is short for â€˜Peak Signal-to-Noise Ratioâ€™,so the higher PSNR means the noise is less and the total performance is better. It is often used in examining image generation algorithmâ€™s efficiency.\nSSIM SSIM is short for â€˜Structural Similarity of Image Measuresâ€™, so the higher SSIM means generated image and initial image is more similar in structure and the performance is better. It is often used in examining image generation algorithmâ€™s efficiency.\nLPIPS LPIPS is short for â€˜Learned Perceptual Image Patch Similarityâ€™. I some cases, higher LPIPS are suitable for evaluating the diversity of images generated by generative models like GANs, but if we are generating images or comparing images to see how different the original images are from the ones to be compared, lower LPIPS are suitable for that as well.\n","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711497600,"objectID":"636da76d40d4e0ed4dfacdd74689d629","permalink":"https://dante-su.github.io/post/23-12-18-deep-learning/","publishdate":"2024-03-27T00:00:00Z","relpermalink":"/post/23-12-18-deep-learning/","section":"post","summary":"","tags":null,"title":"Deep Learning study notes","type":"post"},{"authors":null,"categories":null,"content":"From ZhiHu\nç±»ä¼¼â€è¿›ç¨‹æ˜¯èµ„æºåˆ†é…çš„æœ€å°å•ä½ï¼Œçº¿ç¨‹æ˜¯CPUè°ƒåº¦çš„æœ€å°å•ä½â€œè¿™æ ·çš„å›ç­”æ„Ÿè§‰å¤ªæŠ½è±¡ï¼Œéƒ½ä¸å¤ªå®¹æ˜“è®©äººç†è§£ã€‚\nåšä¸ªç®€å•çš„æ¯”å–»ï¼šè¿›ç¨‹=ç«è½¦ï¼Œçº¿ç¨‹=è½¦å¢\nçº¿ç¨‹åœ¨è¿›ç¨‹ä¸‹è¡Œè¿›ï¼ˆå•çº¯çš„è½¦å¢æ— æ³•è¿è¡Œï¼‰ ä¸€ä¸ªè¿›ç¨‹å¯ä»¥åŒ…å«å¤šä¸ªçº¿ç¨‹ï¼ˆä¸€è¾†ç«è½¦å¯ä»¥æœ‰å¤šä¸ªè½¦å¢ï¼‰ ä¸åŒè¿›ç¨‹é—´æ•°æ®å¾ˆéš¾å…±äº«ï¼ˆä¸€è¾†ç«è½¦ä¸Šçš„ä¹˜å®¢å¾ˆéš¾æ¢åˆ°å¦å¤–ä¸€è¾†ç«è½¦ï¼Œæ¯”å¦‚ç«™ç‚¹æ¢ä¹˜ï¼‰ åŒä¸€è¿›ç¨‹ä¸‹ä¸åŒçº¿ç¨‹é—´æ•°æ®å¾ˆæ˜“å…±äº«ï¼ˆAè½¦å¢æ¢åˆ°Bè½¦å¢å¾ˆå®¹æ˜“ï¼‰ è¿›ç¨‹è¦æ¯”çº¿ç¨‹æ¶ˆè€—æ›´å¤šçš„è®¡ç®—æœºèµ„æºï¼ˆé‡‡ç”¨å¤šåˆ—ç«è½¦ç›¸æ¯”å¤šä¸ªè½¦å¢æ›´è€—èµ„æºï¼‰ è¿›ç¨‹é—´ä¸ä¼šç›¸äº’å½±å“ï¼Œä¸€ä¸ªçº¿ç¨‹æŒ‚æ‰å°†å¯¼è‡´æ•´ä¸ªè¿›ç¨‹æŒ‚æ‰ï¼ˆä¸€åˆ—ç«è½¦ä¸ä¼šå½±å“åˆ°å¦å¤–ä¸€åˆ—ç«è½¦ï¼Œä½†æ˜¯å¦‚æœä¸€åˆ—ç«è½¦ä¸Šä¸­é—´çš„ä¸€èŠ‚è½¦å¢ç€ç«äº†ï¼Œå°†å½±å“åˆ°æ‰€æœ‰è½¦å¢ï¼‰ è¿›ç¨‹å¯ä»¥æ‹“å±•åˆ°å¤šæœºï¼Œè¿›ç¨‹æœ€å¤šé€‚åˆå¤šæ ¸ï¼ˆä¸åŒç«è½¦å¯ä»¥å¼€åœ¨å¤šä¸ªè½¨é“ä¸Šï¼ŒåŒä¸€ç«è½¦çš„è½¦å¢ä¸èƒ½åœ¨è¡Œè¿›çš„ä¸åŒçš„è½¨é“ä¸Šï¼‰ è¿›ç¨‹ä½¿ç”¨çš„å†…å­˜åœ°å€å¯ä»¥ä¸Šé”ï¼Œå³ä¸€ä¸ªçº¿ç¨‹ä½¿ç”¨æŸäº›å…±äº«å†…å­˜æ—¶ï¼Œå…¶ä»–çº¿ç¨‹å¿…é¡»ç­‰å®ƒç»“æŸï¼Œæ‰èƒ½ä½¿ç”¨è¿™ä¸€å—å†…å­˜ã€‚ï¼ˆæ¯”å¦‚ç«è½¦ä¸Šçš„æ´—æ‰‹é—´ï¼‰ï¼â€œäº’æ–¥é”â€ è¿›ç¨‹ä½¿ç”¨çš„å†…å­˜åœ°å€å¯ä»¥é™å®šä½¿ç”¨é‡ï¼ˆæ¯”å¦‚ç«è½¦ä¸Šçš„é¤å…ï¼Œæœ€å¤šåªå…è®¸å¤šå°‘äººè¿›å…¥ï¼Œå¦‚æœæ»¡äº†éœ€è¦åœ¨é—¨å£ç­‰ï¼Œç­‰æœ‰äººå‡ºæ¥äº†æ‰èƒ½è¿›å»ï¼‰ï¼â€œä¿¡å·é‡â€ ","date":1695859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695859200,"objectID":"9c81f2630f36f1d5a41c4e3b0f2030f1","permalink":"https://dante-su.github.io/post/23-09-28-processed-and-threads/","publishdate":"2023-09-28T00:00:00Z","relpermalink":"/post/23-09-28-processed-and-threads/","section":"post","summary":"From ZhiHu\n","tags":null,"title":"Difference between processes and threads","type":"post"},{"authors":null,"categories":null,"content":"Congratulations to Dante(me) for contributing to construct this website!\nHappy to see a new version of this notes website. This time, I choose wowchemyâ€™s webiste template to renew this notes instead of the old one which is built with the help of gitbook, as gitbook would be no longer updated from 2021, a great pity.\nThis notebook was oringinally set for recording some shell command used in Linux. After the contentâ€™s being gathered togehter, I started to think that I need a far more efficient way than search it in my massed\u0026amp;messy documents to consult it once I have something need to know when writing code or debugging. So, I construct this webiste for me and also for you, the potential reader who found this website by accidence.\n","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"9586085b5bf2fdd98cfb5a51890c124c","permalink":"https://dante-su.github.io/post/23-09-20-construction-this-website/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/post/23-09-20-construction-this-website/","section":"post","summary":"Congratulations to Dante(me) for contributing to construct this website!\n","tags":null,"title":"Congratulations to Dante(me) for contributing to construct this website!","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://dante-su.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]